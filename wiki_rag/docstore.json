{"docstore/metadata": {"1164": {"doc_hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428"}, "233488": {"doc_hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d"}, "32472154": {"doc_hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea"}, "76121942": {"doc_hash": "ce873510685e4d249b8ca1088239e2b5fbdff946b274452561cf3fcb00adcbdd"}, "40409788": {"doc_hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388"}, "21652": {"doc_hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1"}, "73291755": {"doc_hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740"}, "73248112": {"doc_hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747"}, "173354": {"doc_hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e"}, "2711317": {"doc_hash": "04358b3f0fc344060e5eb79f10fee69a96a62d4d2dc5e2eb0a84bbec5a905c9e"}, "938833": {"doc_hash": "01a114ebc7a0b555e902b806eed4268110b8b08be4f4185b76b5ce3e0ed87bf9"}, "15893057": {"doc_hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882"}, "4ab039c4-7959-4845-8fe9-19d045bfa757": {"doc_hash": "982092e299a398e0ceef0cae9eb2bc50521aab6e26eff1384c62680ccaf9f524", "ref_doc_id": "1164"}, "b52ab66c-4e98-4ae4-b1bc-e7a041461d4a": {"doc_hash": "209cc638816eb9378aebb52b86ba4caaf9f8f6f6055dff581f55619d86594eb5", "ref_doc_id": "1164"}, "8b61535f-d6d1-4c4b-ac6e-ddad0ade9720": {"doc_hash": "913450aa405587f7564525fd08dd96922f4deaac3b79aa1b24c7d41061fe8070", "ref_doc_id": "1164"}, "942bd085-b5c9-420e-b579-3690a466fc11": {"doc_hash": "b2f6abef76c643f5e959ed0619bc6e074164af693211d96a7ba6d49df0dc5bd8", "ref_doc_id": "1164"}, "49df6bdf-331d-40bc-aaa2-e185f23a1355": {"doc_hash": "198dfa08b9c7662985cb3887826e0da82b380963745d913f8fb9a82925ebdde3", "ref_doc_id": "1164"}, "f7ccd07f-4b8d-4b7f-b5b5-43751fde7d2e": {"doc_hash": "405b5ad569c77a9c6c19129acda78a06790b7806dcd7910481a526abe155f53a", "ref_doc_id": "1164"}, "eb4f047f-2d13-42f4-ba0b-6b7e9dc0694b": {"doc_hash": "6ebc5cdd8678ba7666f41ea9adcbe75dd2f5cbbe80dbe657441820dbd50ebda3", "ref_doc_id": "1164"}, "15c30b0c-221a-4b81-950d-57dfe70e3fd2": {"doc_hash": "aa7c4adf21282cdb12f6c12f6e590c33717938d6a291fbb891d6371d0408a391", "ref_doc_id": "1164"}, "328bd4e7-eb28-4469-86bc-f80dce24c6f0": {"doc_hash": "e2ae661e50d0e25486fbd389835caae2562bf952ff9a42e9dd5a87d226758162", "ref_doc_id": "1164"}, "b10d4ea0-65e0-4073-a614-55c06bfd2f9b": {"doc_hash": "4ead61a6d5fe967ecc3ea5f286df0a317bb14d808d126d25f25e9fead5c32625", "ref_doc_id": "1164"}, "aefd400a-538b-4499-a1d3-d017d70613c2": {"doc_hash": "e7d98fc8e12c14336af790dd1a5e31113a0e44f5f2851b02269ae983697ae8a7", "ref_doc_id": "1164"}, "f6747b15-d4a3-410a-88f8-e649ce76985f": {"doc_hash": "9e1227af9d3b67482855dbc7a2f98e4b8e3124f06331ba80416c67532a427d05", "ref_doc_id": "1164"}, "8396280b-a52d-4445-b217-efa5a1e08059": {"doc_hash": "256371a07578bc23e597d7f516f3e7f0272fbc7023f171740ce5e4684c32a177", "ref_doc_id": "1164"}, "514b7443-41bf-4c11-bfb6-debeaf5421e6": {"doc_hash": "4c0fcd117a231c0d9a77ba0b2640d3539d9668bb93cf6002c55e2c55a6865ecd", "ref_doc_id": "1164"}, "1e55e3a8-d017-4f4f-ad9e-8fbd09786241": {"doc_hash": "71cbfaa40c8636fceae4e1fe5bb6e00445b143c290ca66c373774e1faa17710a", "ref_doc_id": "1164"}, "449bfbce-9ec5-4336-ad08-10c4971325ad": {"doc_hash": "ee4b1d5f0ce19cd7a4a16b0425944f45e48fe9787421efe701ab0e5746cb9967", "ref_doc_id": "1164"}, "1374a695-2852-4d4e-b52d-ffb850d0a853": {"doc_hash": "82118279e8af7887157cb932a9be3b04ec81f436a1344ba951d100111860dc7f", "ref_doc_id": "1164"}, "84f828ab-1e16-4545-b622-bac519443665": {"doc_hash": "10eea03456e564d5cf65fcccb236fa929294372e3e5dda3ee77a1c148858e5c8", "ref_doc_id": "1164"}, "65d37f32-d07d-45a5-973f-134a15bca219": {"doc_hash": "00400c3c68ac3ac4bfb154193362f74a9c725fbf605c218a19237989c19bf4e5", "ref_doc_id": "1164"}, "f4c21acf-7b2d-4eed-ad56-489e7d634a7f": {"doc_hash": "5e1bc737e3f3dd88887892d1a6b735bf704d69f3de1a467a1646c05b84e26b39", "ref_doc_id": "1164"}, "c02e6d01-a5e4-4fab-b4d3-1e45bd33cfc8": {"doc_hash": "c0bbd548a2175382d7148e960e3661adf7cf9e76aa17b5af9cb9f2bd39ed68f0", "ref_doc_id": "1164"}, "841c4567-a53f-4573-880b-d1866702a721": {"doc_hash": "2a3c9ca8d179ab9c31627a6adc9606b6e502388da15cf0aecf448d41b37685d1", "ref_doc_id": "1164"}, "e571a374-3eff-4770-8f33-3f464457c9b2": {"doc_hash": "a32c6e6418d99fbe0390d3e68a98d8a78249edcde77f59580683c56de7e63dae", "ref_doc_id": "233488"}, "07db5142-e837-4c44-82ca-66fa6f5b0a8c": {"doc_hash": "6c1b73a39dcc5f14a810e8aa7e0e0af1dfada7c39a93a80fef62b14027f0852d", "ref_doc_id": "233488"}, "6fb7e81c-e518-4f40-afd9-851547334fe8": {"doc_hash": "83511b761af202f82e7d8b52354150f8b242203513d58530f48a3d3e93ffce48", "ref_doc_id": "233488"}, "2d69cae6-e450-4542-a647-c31ca069d7da": {"doc_hash": "9a0c7171cc47b73fc76f6c7aa073c8f2c20f61a6cf8ed8174493b8d9ea87d6e4", "ref_doc_id": "233488"}, "535bd41b-2096-4dcf-8b12-7bfac5d6cbc7": {"doc_hash": "66e5d151c42e890f2eeb2fd6c47e9f07d2fbaa45326fe68730c1b3a7e2061b54", "ref_doc_id": "233488"}, "2bee5fd6-1cf2-42e4-84e4-b657973dd793": {"doc_hash": "b34717786220a0887c24cfaa2d6710db96795ade1833c7c4fc3d78842231cbbc", "ref_doc_id": "233488"}, "4fa2024f-cfd6-4696-8a88-14509984b5b3": {"doc_hash": "38493ce3c337dbf140869bf6a40770a001021913960477a18fe3208928e53671", "ref_doc_id": "233488"}, "8335c64a-35da-4cef-82ff-97340256d954": {"doc_hash": "5f064d7f0cdbf86d5135a1514be46a74712a14cb06a57a6fb4f0df6dc7eb6980", "ref_doc_id": "233488"}, "3cfcf0d7-d3ed-4b09-b8d6-48e32d306428": {"doc_hash": "b22d5eed987498f971f46e6fb5e912991327cd1fcbe7413c0d8405afa9f13352", "ref_doc_id": "233488"}, "82e0490b-42aa-408b-b954-ed9f67e759c8": {"doc_hash": "d261f12302f075c79305f7a688d9acb6b9a6ef6550adf6f7d09ff99c5d53529a", "ref_doc_id": "233488"}, "355b74b3-8b63-403a-ad6e-9267d4f2a8dd": {"doc_hash": "bbefd6f6935096165fbbebac2921c94ecaa22e479153937367bc5c2606932f09", "ref_doc_id": "233488"}, "c5d4dced-0b7e-438d-999a-1429b1c269a1": {"doc_hash": "62f5185104176193d8eab772729ce26f9bca8cd58d6dd4c5a3a226c1c65124a3", "ref_doc_id": "233488"}, "8eb652ea-9d53-41fb-8599-340cfcba5ef8": {"doc_hash": "d654f0bc50c82970a3f365d441ba63e91ccaceb1452a39a0fc85e6b59cd70f9e", "ref_doc_id": "233488"}, "dd4ed30e-05dc-48f1-9e00-48d947a2f6ca": {"doc_hash": "4cde19ba01cc0a9e20abbeccb4cd41b87ec64e73a2eefaf41412e7ab3100420c", "ref_doc_id": "32472154"}, "f754c521-3b6b-4476-9b94-a4a877da0a59": {"doc_hash": "4bf9dfccd7057f5a02f776719451af5627382c4cb7f7b1e54f6c5e8bd3c992fe", "ref_doc_id": "32472154"}, "91e6728e-a2f2-4654-9be7-7c0284cb6539": {"doc_hash": "537c5796da87ae540ba2e03b32e396286003b297e24d963aeae2a7f7d41299a9", "ref_doc_id": "32472154"}, "4ad5b872-5b44-49b3-98f4-58af80444881": {"doc_hash": "1a876a6433a4ceb4f227ed73d3d0df2be988f475dbf7efa05d522c50b592319f", "ref_doc_id": "32472154"}, "478819ee-e4fc-42f4-9432-fbbbe150709d": {"doc_hash": "ccfe96d9636bb7759877586291f84de38e3b57ec75e3cc93acb7fcec4b2e7956", "ref_doc_id": "32472154"}, "b7055dc2-6cbc-4fd1-962a-4faa6c5459ea": {"doc_hash": "294e5445d58454abb293add53c64d260d9f8a1deeac58188ed5a28225bcd85b8", "ref_doc_id": "32472154"}, "550a2340-a66c-4052-b96d-c416a3724a03": {"doc_hash": "09dcfab3f907be974a5ba060117d52df97863955c6c3ffc67f168027ea1caddf", "ref_doc_id": "32472154"}, "bfd2f854-7427-4153-81f9-a4ae9e862617": {"doc_hash": "7630e998aa14d81f893183b1559984cece1a66bf939352ed23985b2bd24bb01f", "ref_doc_id": "32472154"}, "58a6957f-df83-4fd3-abc8-5f7014d58b2a": {"doc_hash": "bbcd61324f8329f2301b6b48fa9da21d0856791ddcf50b5b017e00c844c5a7ad", "ref_doc_id": "32472154"}, "fde0c038-d905-45bf-9445-6c7407b628ce": {"doc_hash": "70b739311b55a76ac5f691bec58deeb1d0bae2a055cf32cba449473d9df71c81", "ref_doc_id": "32472154"}, "d2b217d1-9186-4f6b-9842-d85be4f76a6e": {"doc_hash": "203d799683eb9588c44580e498fcc0da5ec133394c65f1fdf1570d9e78483c8a", "ref_doc_id": "32472154"}, "25622a5b-8aa9-4568-8022-2b8af6de1eb5": {"doc_hash": "a86d7c31655b78cd073763d5410367f0fe709ed56783e29415eb14c577f1bff7", "ref_doc_id": "32472154"}, "79a75544-d43e-4c53-8545-216d56255688": {"doc_hash": "07197a4c6e7e85e9f2db07f93efd7a4cb7a3823a841964eb13151a0365a52a7e", "ref_doc_id": "32472154"}, "5be4cf5b-cf07-4416-84e2-499b3f65c7e7": {"doc_hash": "9c76554fdab68bbdc01d1af2e1090a3ed4195376e50f8a6390c87adff51c7f74", "ref_doc_id": "32472154"}, "1e19a71b-dc20-4e68-8330-08c490e51d33": {"doc_hash": "913913afb2f972943cc490a30414fc7f973942e374642567afccd2fc0a9cfab6", "ref_doc_id": "76121942"}, "811bf8fe-a762-4f76-b782-979f7f567277": {"doc_hash": "bff1ffc7829a4df7a9f0a99b2f40bab260abe2c38a7698cb8ce9c77184b12417", "ref_doc_id": "40409788"}, "160e3bca-e219-42c8-b0b6-733cb8a71b58": {"doc_hash": "ec25a31db27e14def7d2876f2be3b484fc90731068663d84ebc1819cc9e8425f", "ref_doc_id": "40409788"}, "0da08d6f-b6c4-4bc8-97cb-5ee9095e6ae1": {"doc_hash": "bda2ebb583c9a8b676b2ed17a0659b8ce0f799f84dc1716f9625a1c6cfa61bf1", "ref_doc_id": "40409788"}, "82ef047d-e8bd-4c93-b915-c27a5f027d1a": {"doc_hash": "2f251fa8d7d1e0c52028303717f9715af1e44bb4769fe1d5722d9947c7d65a16", "ref_doc_id": "40409788"}, "3875a3a4-1787-456a-b028-2aae29743af1": {"doc_hash": "007afd1be5de0db82730cee4e08eac3223697ed7d8cc657a2c6d95ec54e373d9", "ref_doc_id": "40409788"}, "a2d42081-6470-4bba-9948-dee2abda04bd": {"doc_hash": "d7f3665ce0568050df9042dc14d2b20f266f9ef4d639df8277fe5fe3db1dbed7", "ref_doc_id": "40409788"}, "2344fc41-a542-485e-800c-fb4de34f79fd": {"doc_hash": "d669ab12718c1502c2854ed11cc11c14f95f65bf81edfce7bd40333927f7f4f4", "ref_doc_id": "40409788"}, "1142e6e0-0f91-4318-a894-2130ab3b6cb9": {"doc_hash": "702551c10d7f7170d374907a743e0776b4cac616b46e25a4ecdbd88ed8f4d3b0", "ref_doc_id": "40409788"}, "84d0ad74-5b58-47db-9c0c-fd81ed88be69": {"doc_hash": "caa1afbf2cacc6b06ab77bf006b420a4edd36df99d7ef35f3a3512cb05ba4052", "ref_doc_id": "40409788"}, "c25a7e50-10e3-46d3-88e8-f899fbb4d9fd": {"doc_hash": "d90c2cbdf4d09b492ee2ea267befbd3b36de85f40b3864c323fbca0c255ecfaf", "ref_doc_id": "40409788"}, "f2c1ae07-686f-4f6a-9190-3efa7ef621f3": {"doc_hash": "252de977c7e4754b3005c9a4608b805345e90dc118908f8e879ee2798f2693e2", "ref_doc_id": "40409788"}, "bae32750-1e0b-4f3c-97f6-bbd3cdea4f0c": {"doc_hash": "aaad958f2a02f0aa6beb7bced4a98b5ef621274e5424304d2c7647d42313945c", "ref_doc_id": "40409788"}, "3065e88e-5f7a-4319-aec7-964d3ea86f59": {"doc_hash": "f914196a2f4d0f4742ac2d2ddd83556efd8581746726cf79c286bd968cd8fb19", "ref_doc_id": "40409788"}, "b7a2a0e5-bb31-4765-b782-5a4df75bdbac": {"doc_hash": "703a30f66fb0b7dd4496e96fa97e0b800bd3ea1454d47c3e5508816479c50854", "ref_doc_id": "40409788"}, "36f36bc1-8a69-4bcf-a36a-3097c1952edf": {"doc_hash": "b163152590e9ffbcb338e2d964e03e99ff4c9fddb445dfaf4b7c100ea6f0af1f", "ref_doc_id": "40409788"}, "f4045224-b123-4c58-82b0-7f7b6ea1d98a": {"doc_hash": "0cfa6b15c6a0b00307622d53db5d7d8dc3caca30abfd65393dbc14d76215e434", "ref_doc_id": "40409788"}, "b6780513-e950-4e89-90bd-08554676dcf9": {"doc_hash": "52c992e9cb923aaf5cee0aca8819eed9c8a036ffacd4aecc5ead7dd923f53bf3", "ref_doc_id": "40409788"}, "1dd41de2-bdad-4989-8ba3-16e5dce73351": {"doc_hash": "105ab3b5bc45d3a13f20c32fdc7681f44dfd18496e349f110826987a8222b624", "ref_doc_id": "21652"}, "5c62f167-7dbc-4b76-8fbb-4fd35ee4263a": {"doc_hash": "a395b9d1efa18315c37497f551dd362d1cc568ea2319f1efc71e8c7fb86136a0", "ref_doc_id": "21652"}, "55baec5d-f219-4d86-8d6d-2e6575f80bd7": {"doc_hash": "5fc55e741fccdcb5d99a32bb1003efa3f41348538dba744109ffb0eb9f6250e2", "ref_doc_id": "21652"}, "317f134a-8f9f-4c9c-b16a-82900d3fa03b": {"doc_hash": "43017ebed3ab6cb435709e28ff43c306bdf02e2f6fc47891779b57b97f363482", "ref_doc_id": "21652"}, "34c6ce7a-41fd-4449-a0fb-fc3e4484c4ef": {"doc_hash": "fadf772f3e0b9f36538e8d67a972b138eedad412f2686a334f0e95f208f450ad", "ref_doc_id": "21652"}, "ea5ee3ce-0629-403d-ae59-7d5b5025bdae": {"doc_hash": "7a7eed47972ad9047135d03780ae888ef99e9e2bdacbf5cf2ba94770eeb31afd", "ref_doc_id": "21652"}, "c1a60dfd-2964-45a2-8bac-9b66549be437": {"doc_hash": "a94a9a8d874f80e0abeaa351faee8b2cba8f854d9ffc0b112e61ae757e407af5", "ref_doc_id": "21652"}, "4723263f-2090-46e7-be96-d0b44bb72c6b": {"doc_hash": "093ee75a8d1f8b75f75ea98e4c6eb08e099e4cf9639732fe735546ac573775f7", "ref_doc_id": "21652"}, "5d5d7710-34f3-4a7d-ba46-76ac34a29038": {"doc_hash": "30671dddf41c41ebe5b01089827bbddb1763a9c7f27f60dcc408bfdaedbf252e", "ref_doc_id": "21652"}, "a8e00bba-ce6c-4e7a-bdee-23ccb3369cbf": {"doc_hash": "2f875300cbf09e7bcbb10c671becfb85948c6841ad7322473167b12fd6a15b03", "ref_doc_id": "73291755"}, "eb06471e-7fe8-484f-aca8-418f5c0a9f2a": {"doc_hash": "5a51e5132d8d421e3d6edcfc4850e00358d87b4efc30b76388a80931991a799f", "ref_doc_id": "73291755"}, "788240d0-bb49-4a6e-a0cf-ddbdc62f8765": {"doc_hash": "e1a4fed407a0d7309d43684f1a3e0bbf3f61118ccb058696cc966f802e9d5e7c", "ref_doc_id": "73291755"}, "6b187125-22ec-4c42-abab-67e0d206092d": {"doc_hash": "55939be9f839810e5fbc5546e629fb1c0b805c871c49519397c7d5ef9b1fd81d", "ref_doc_id": "73291755"}, "33307083-a862-47c2-9027-c3ac9f843895": {"doc_hash": "e31d163e261ff502e3524111b74e4a4835d7e47d52a5bb1e7bbc0b9b33d333a8", "ref_doc_id": "73291755"}, "9c533f28-97f1-420b-896d-bd0b9afe0478": {"doc_hash": "5ad3f3ea3afed8fc9afd41ff4479a116b908505c21ceba04a371603a9f85f912", "ref_doc_id": "73291755"}, "e0d19347-bbbd-4dc5-b34c-09ba3749b867": {"doc_hash": "1d324771060f7aae8cdf54717004214d49046ce69bdc1bc7c465ebccbe70416c", "ref_doc_id": "73291755"}, "06d37da8-2020-4c50-856a-58f4c4595575": {"doc_hash": "4b5a686ed62ef6dd34fc7483b359f868e3289a3c7409d2128fa8d840a6ee4dc3", "ref_doc_id": "73291755"}, "52812ff0-f0bc-482c-b06e-f5998df25a36": {"doc_hash": "60f9f841f52af37ef3042177dfd0a0dc1b9e139e0a133bb3eaeb237ddaf96833", "ref_doc_id": "73291755"}, "96028078-62c0-460a-b467-10ce5140dee0": {"doc_hash": "0ce24842ce22970e81ec5df3c6284e30d02abfdf0c6c0448967f834e862324ea", "ref_doc_id": "73291755"}, "957102fc-ecb3-4c77-b017-b0c6a13b209e": {"doc_hash": "567f9912e9e740140719ce8bb87d5ace632b029f8e2746d0495036b7cb6f3e37", "ref_doc_id": "73248112"}, "4a4b6e99-211c-48d2-9523-4aa420d8a709": {"doc_hash": "f982611ed8a9f5198fa9fbe17f914dcd51a772437f089cfe86468f142c22d4be", "ref_doc_id": "73248112"}, "d8b6b633-9068-4a77-8156-9a3dc2198948": {"doc_hash": "4681df97e18a954222e5ef855bf62b3c97545ee5fe522669cf327a5b6722dbb4", "ref_doc_id": "73248112"}, "e94da11d-2325-4e76-a929-1b5304970b03": {"doc_hash": "6f2bb1f4452feca33652515c52152a74cef27b5797ec01d613fa5e334e849b40", "ref_doc_id": "73248112"}, "8061e96d-1391-44f8-b8d4-de22afa68c44": {"doc_hash": "80fc91df66398f4b7ba4cfa6efffb01c3791a955a55fd0b483c341d3e0278b5a", "ref_doc_id": "73248112"}, "bc1354c6-c026-47db-99ef-24ee0bd02244": {"doc_hash": "a6b5f2d2d2d336e2878ead8872c695df9b2a30caf13fdb589d22fff57fb8f859", "ref_doc_id": "73248112"}, "ef8185ca-1b6c-42af-a491-c91870195d07": {"doc_hash": "b693c81085f701ae94920cd909fc870b500683dc1cf2d5a502e87ece5cb8e578", "ref_doc_id": "73248112"}, "888871dd-08b3-42cf-8f10-61fcca99fe97": {"doc_hash": "88117e3874a450e2ded6cec1bca3e9de1f2baa9cf9417a81605159ab35b39f8a", "ref_doc_id": "73248112"}, "a3a135db-6b90-4bb5-b59f-6728cb7e4100": {"doc_hash": "e1a71c52c193414305ac74c91e18dc4b9febd551133d9b1be6e01133e4cc833b", "ref_doc_id": "73248112"}, "63efa929-4aec-4f21-909a-cda2f85664aa": {"doc_hash": "e0800c5f31028da24117a3218f2b899b72a94f3494f699708589351dbd353c94", "ref_doc_id": "73248112"}, "7f251bf0-1193-4189-9da1-4b8632f5f19a": {"doc_hash": "f821e538d79a19911c3f3c2f880c066b332da45c9ceb70722a5ff374a93e38f6", "ref_doc_id": "73248112"}, "ffc8cf32-ef4e-42ed-abc9-4623d393d8be": {"doc_hash": "5b54fc25a71a40254126160792b0e17687ccb97e30238e0de15f7d951a41f91e", "ref_doc_id": "73248112"}, "3d8ebb20-fda2-47d2-a479-977a27d1410e": {"doc_hash": "a2eab7abf8fe6da2452415599ef00dd1865ad8f78986cf281abd4d74a58f689d", "ref_doc_id": "73248112"}, "da1741a2-b54c-49f3-acba-cec69b1e92ec": {"doc_hash": "8dd1622119f047cafe2da77ba58988f121fea9268d0d51b038ff1625675d4bd5", "ref_doc_id": "173354"}, "c37f473e-5e04-40bd-bf6a-5ba605fb4970": {"doc_hash": "aa1d28d789f53ad5ac527840311ece98ad2437c2ebb4b816fb39ce7376b7eee0", "ref_doc_id": "173354"}, "8b61d906-4e2e-4658-8d5b-9ff4177981c9": {"doc_hash": "ebd93b58f12565d902d915cfd4efa9fa60ce920b0704b51c14e9a5ff7569d8a6", "ref_doc_id": "173354"}, "7fbcc181-b354-4e2f-a4c3-baf6f9281f95": {"doc_hash": "8bb3af1665891d0cb5a936450ca15f1aed3253deea73ecda5b16b6abf5ad63f4", "ref_doc_id": "173354"}, "113ec952-36d3-49d0-af83-b94234745e6a": {"doc_hash": "3bfc6ad9fc5504b3c722e5e5364847b33f0d1f17db1d125bd298c2b103aa0a9e", "ref_doc_id": "173354"}, "d274f457-dc3e-46d8-819a-b509dd0629ef": {"doc_hash": "410be4d996167fba7487dc17dadedb4ccb2028a1fa733495c0be69d01e16d89e", "ref_doc_id": "173354"}, "536c7a7e-3f3d-4bbf-96e3-bc81af8906fd": {"doc_hash": "53c49abab650cb6c6f8992eb5082f9a3d84538873fe0da15dc4ed01048028730", "ref_doc_id": "173354"}, "bf4ea3bf-1285-4a56-a604-cfa6a9126b3c": {"doc_hash": "bbdcc77f85ab419bfff19a6a1f80b4b80519395679cc56cbd2e0e008567dc750", "ref_doc_id": "173354"}, "a2685772-7b72-4fb0-86ae-6cb293074405": {"doc_hash": "2079c047071b5c75b76fe5a6c8b6c76475814471968c01de044fa8caacc68380", "ref_doc_id": "173354"}, "22b3999a-1bc1-49da-8031-a3c242dd765c": {"doc_hash": "5b7280f985493a4e8d1a2e1a35dc9890d94e3a30d2bfbee11ddb1dc46ba4d798", "ref_doc_id": "173354"}, "dd52ca4d-1e4f-4183-9aa3-8f0b8b0e444e": {"doc_hash": "feed1acf638f975defb15b77175ef9d994e8d41f193d9bc3482ef17f002bf2ec", "ref_doc_id": "173354"}, "f4fe29ec-0d43-4bb1-bafa-74d0d934ee44": {"doc_hash": "08c74cbe9622d10777692be54feaeeace33dcd47834c50b0adcb76af48dcc1ba", "ref_doc_id": "173354"}, "f11a9fcd-c26a-4109-ab06-fdb14a925544": {"doc_hash": "8aaa19230e5654f65ef3f6c6c62bc3cccdd6c9ed08b3adf37f604f23f47bc672", "ref_doc_id": "173354"}, "e20ecb3d-41f6-4ed1-b276-d096926b5175": {"doc_hash": "f4f08db6615fd3885660cc88d21219b34a9803372c85bba5cb2bbd405468c582", "ref_doc_id": "2711317"}, "79b9a4bf-d6bb-4325-9259-ff923cc952c8": {"doc_hash": "e041915a83e949f0699d6c6816cecc23b79f1cbd7e2a09e5bc0f66897a00c1a7", "ref_doc_id": "2711317"}, "bf048a52-23c8-45bf-aed2-c664aab4dd12": {"doc_hash": "f529192abb427d3cc30b6487ec76a7c8aea97ba94f1f85e7b957fa8d6af3140b", "ref_doc_id": "2711317"}, "b67c3f51-b117-4f05-a318-616a19a9d58c": {"doc_hash": "487b026d41efcb2002d83efd98c3fcbf513ed562d92c028b032d0ab69e6ebc78", "ref_doc_id": "2711317"}, "9950fe6d-3155-4f75-b1f5-37fab7e529c8": {"doc_hash": "f485647aadede85ce30d51e812a078294fb7c54585b96776af7d915c27a05fa3", "ref_doc_id": "2711317"}, "3c8a46ef-ecda-4c7e-a615-cb15bfe2d6f0": {"doc_hash": "9fe0c1aa9b83fc7cf584269879bfb14bc2ec3d74f0dfea051bcf3968b064f5d7", "ref_doc_id": "2711317"}, "e708ff84-4768-407a-a18c-b6f0ff14df2e": {"doc_hash": "7210191c9ae30829e958fae349d5f4448964fc32ec9ad963a752351ae8e02b9f", "ref_doc_id": "938833"}, "9de43aa1-9fa4-41e5-92c8-3e28858f830b": {"doc_hash": "82c522c9bcdf17ef17b8b090cdf0355fe07c32cc96ac8e9cc058edd3dfba97ae", "ref_doc_id": "938833"}, "2e3fa510-e4d3-4bf0-b190-f73aaba40932": {"doc_hash": "3cf6ae29702d6e75626bbe61537cb82b4120512ae71284e20720a2a3b6c35e50", "ref_doc_id": "938833"}, "617789a6-69ab-4920-8950-099df217baf8": {"doc_hash": "d6dd62544bcb0e6465da4fe7b46c9eb4bb226cf55a5e8259afd1bd8854474775", "ref_doc_id": "15893057"}, "08c57786-33f6-48c1-b70a-1dd6fc1836f1": {"doc_hash": "e99bc87ebf9804d68e2a8e76102b412d797ea3ff341ba3a197d066b3052dca0d", "ref_doc_id": "15893057"}, "bcd02966-ae82-4d7d-a0e7-0005f37e8992": {"doc_hash": "a15c5a1a8065c8215a0a7f5a35a7f80475b32e420766b81b390ddf99f3309211", "ref_doc_id": "15893057"}, "8065b322-4954-4378-a3b1-8e6997e75194": {"doc_hash": "3034060bfecb3ea7456dd1f9409a7ed764c70230f156d9e932d70c0f5eca076b", "ref_doc_id": "15893057"}, "08eb8e3f-7c51-4d98-91f6-d1a4ceab2bf2": {"doc_hash": "32ed3f0f368d297cd06d24645edf5e947349f2e61eddd7b58434d2ab4aaff6c2", "ref_doc_id": "15893057"}, "bfc28529-4549-480d-97a1-8fa8ef541660": {"doc_hash": "1114e387dbed719320a3b654aa22db67ec69843d4319be4ae85f3f1fefb1a829", "ref_doc_id": "15893057"}, "3192e549-ef5f-47a7-82e0-f49917e5f0db": {"doc_hash": "9e0860ab3cce3983f1d557a7579a378b73485c40d8b1e1f03da1943e79491065", "ref_doc_id": "15893057"}, "a76c50b8-f99e-4845-b34b-0fe8bd43f712": {"doc_hash": "d5d18e03da96cfd6024a343befefe41178ebd455158bc9b795836b6702cdbe37", "ref_doc_id": "15893057"}, "8e726a5c-bd57-48c7-aad1-47ce2f2fe28f": {"doc_hash": "0d9a6818c18729b13cb01542389760e2635eb86622184bc88c482d6191289a56", "ref_doc_id": "15893057"}, "50520759-22d8-4d1d-9350-c89f0465de72": {"doc_hash": "8ed5bad237d17fb4c6bbf8833ae1949763d7f66c383c2018616f123adaf644d6", "ref_doc_id": "15893057"}, "a7c4556e-aa79-4f25-9a58-d3be3d893752": {"doc_hash": "07d07fcb6a16b6eab1b6cc3770a062f2cb5d30165e97e0fcadee61f3dd025dc0", "ref_doc_id": "15893057"}, "9e901110-1958-476b-985a-1fc91bc494af": {"doc_hash": "28dda94c5d50b30109d1a32f8445abf7e08791882f2c49e8eaea5d445f2c87cd", "ref_doc_id": "15893057"}, "31b08a90-e3a2-4d6d-85f7-f1955efd0c73": {"doc_hash": "b7bfb2f4c90510dc3941cbecdbdef934dea746b76c73dbc910fe4082130ef1ab", "ref_doc_id": "15893057"}, "1cde0f9a-09c0-40b9-8393-32839fb102bd": {"doc_hash": "7e384d0209dbf69bb587755afac8675c531dab5f7bdc77b6604995b6e2c25c06", "ref_doc_id": "15893057"}, "27d31b73-af59-4aff-b145-31727c0f8c3a": {"doc_hash": "4a1901902c25f5e525e39d9f2f8c64050bceb31f7efb9c9a693811df54c73dc8", "ref_doc_id": "15893057"}, "223acab7-1dce-40c9-a88f-0c729912ac4a": {"doc_hash": "d6dd62544bcb0e6465da4fe7b46c9eb4bb226cf55a5e8259afd1bd8854474775", "ref_doc_id": "15893057"}, "2a6e6966-7060-4615-a5af-cd23b6ecfdd3": {"doc_hash": "e99bc87ebf9804d68e2a8e76102b412d797ea3ff341ba3a197d066b3052dca0d", "ref_doc_id": "15893057"}, "da0c5e38-5fa7-4b66-a3dc-fa8565755add": {"doc_hash": "a15c5a1a8065c8215a0a7f5a35a7f80475b32e420766b81b390ddf99f3309211", "ref_doc_id": "15893057"}, "fa422a2d-c243-4b55-b340-201884705c09": {"doc_hash": "3034060bfecb3ea7456dd1f9409a7ed764c70230f156d9e932d70c0f5eca076b", "ref_doc_id": "15893057"}, "96ab01fc-62c9-4a46-9764-ad68fb29167b": {"doc_hash": "32ed3f0f368d297cd06d24645edf5e947349f2e61eddd7b58434d2ab4aaff6c2", "ref_doc_id": "15893057"}, "13dc49c7-e119-46c5-941c-84ccdeba7f94": {"doc_hash": "1114e387dbed719320a3b654aa22db67ec69843d4319be4ae85f3f1fefb1a829", "ref_doc_id": "15893057"}, "423172c9-2253-41d3-93f0-1908930e5be1": {"doc_hash": "9e0860ab3cce3983f1d557a7579a378b73485c40d8b1e1f03da1943e79491065", "ref_doc_id": "15893057"}, "6f381a5f-715f-4727-95c6-f5bfe957f1b8": {"doc_hash": "d5d18e03da96cfd6024a343befefe41178ebd455158bc9b795836b6702cdbe37", "ref_doc_id": "15893057"}, "dc1138c1-9608-46c4-ab42-70e667f6976f": {"doc_hash": "0d9a6818c18729b13cb01542389760e2635eb86622184bc88c482d6191289a56", "ref_doc_id": "15893057"}, "cd419a6d-658c-42ec-9906-3f9917702809": {"doc_hash": "8ed5bad237d17fb4c6bbf8833ae1949763d7f66c383c2018616f123adaf644d6", "ref_doc_id": "15893057"}, "7b13baca-46f1-45e3-8f32-f1d497426fbd": {"doc_hash": "07d07fcb6a16b6eab1b6cc3770a062f2cb5d30165e97e0fcadee61f3dd025dc0", "ref_doc_id": "15893057"}, "556f032e-9ae9-4416-925e-56ddd1690032": {"doc_hash": "28dda94c5d50b30109d1a32f8445abf7e08791882f2c49e8eaea5d445f2c87cd", "ref_doc_id": "15893057"}, "dabcb935-1b26-4039-b32d-b0a40161d063": {"doc_hash": "b7bfb2f4c90510dc3941cbecdbdef934dea746b76c73dbc910fe4082130ef1ab", "ref_doc_id": "15893057"}, "85d07d24-db3b-4f26-8099-5d9071a63b42": {"doc_hash": "7e384d0209dbf69bb587755afac8675c531dab5f7bdc77b6604995b6e2c25c06", "ref_doc_id": "15893057"}, "f2b30bc5-8616-4475-afd3-9146789352f0": {"doc_hash": "4a1901902c25f5e525e39d9f2f8c64050bceb31f7efb9c9a693811df54c73dc8", "ref_doc_id": "15893057"}}, "docstore/data": {"4ab039c4-7959-4845-8fe9-19d045bfa757": {"__data__": {"id_": "4ab039c4-7959-4845-8fe9-19d045bfa757", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b52ab66c-4e98-4ae4-b1bc-e7a041461d4a", "node_type": "1", "metadata": {}, "hash": "209cc638816eb9378aebb52b86ba4caaf9f8f6f6055dff581f55619d86594eb5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence\u2014the ability to complete any task performed by a human on an at least equal level\u2014is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\n\n== Goals ==\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n\n\n=== Reasoning and problem-solving ===\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n\n\n=== Knowledge representation ===\n\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5382, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b52ab66c-4e98-4ae4-b1bc-e7a041461d4a": {"__data__": {"id_": "b52ab66c-4e98-4ae4-b1bc-e7a041461d4a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ab039c4-7959-4845-8fe9-19d045bfa757", "node_type": "1", "metadata": {}, "hash": "982092e299a398e0ceef0cae9eb2bc50521aab6e26eff1384c62680ccaf9f524", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b61535f-d6d1-4c4b-ac6e-ddad0ade9720", "node_type": "1", "metadata": {}, "hash": "913450aa405587f7564525fd08dd96922f4deaac3b79aa1b24c7d41061fe8070", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Planning and decision-making ===\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences\u2014there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.\nIn classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.\n\n\n=== Learning ===\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.\n\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n\n\n=== Natural language processing ===\nNatural language processing (NLP) allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\n\n\n=== Perception ===\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\nThe field includes speech recognition, image classification, facial recognition, object recognition,object tracking, and robotic perception.", "mimetype": "text/plain", "start_char_idx": 5385, "end_char_idx": 10473, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b61535f-d6d1-4c4b-ac6e-ddad0ade9720": {"__data__": {"id_": "8b61535f-d6d1-4c4b-ac6e-ddad0ade9720", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b52ab66c-4e98-4ae4-b1bc-e7a041461d4a", "node_type": "1", "metadata": {}, "hash": "209cc638816eb9378aebb52b86ba4caaf9f8f6f6055dff581f55619d86594eb5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "942bd085-b5c9-420e-b579-3690a466fc11", "node_type": "1", "metadata": {}, "hash": "b2f6abef76c643f5e959ed0619bc6e074164af693211d96a7ba6d49df0dc5bd8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Perception ===\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.\nThe field includes speech recognition, image classification, facial recognition, object recognition,object tracking, and robotic perception.\n\n\n=== Social intelligence ===\n\nAffective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood. For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human\u2013computer interaction.\nHowever, this tends to give na\u00efve users an unrealistic conception of the intelligence of existing computer agents. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject.\n\n\n=== General intelligence ===\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\n\n\n== Techniques ==\nAI research uses a wide variety of techniques to accomplish the goals above.\n\n\n=== Search and optimization ===\nAI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\n\n\n==== State space search ====\nState space search searches through a tree of possible states to try to find a goal state. For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.\nSimple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.\n\n\n==== Local search ====\n Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.\nGradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks, through the backpropagation algorithm.\nAnother type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).\n\n\n=== Logic ===\nFormal logic is used for reasoning and knowledge representation.\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\") and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").\nDeductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises). Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules.\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem. In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.\nInference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.\nFuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.\nNon-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning. Other specialized versions of logic have been developed to describe many complex domains.", "mimetype": "text/plain", "start_char_idx": 10068, "end_char_idx": 15367, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "942bd085-b5c9-420e-b579-3690a466fc11": {"__data__": {"id_": "942bd085-b5c9-420e-b579-3690a466fc11", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b61535f-d6d1-4c4b-ac6e-ddad0ade9720", "node_type": "1", "metadata": {}, "hash": "913450aa405587f7564525fd08dd96922f4deaac3b79aa1b24c7d41061fe8070", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "49df6bdf-331d-40bc-aaa2-e185f23a1355", "node_type": "1", "metadata": {}, "hash": "198dfa08b9c7662985cb3887826e0da82b380963745d913f8fb9a82925ebdde3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Probabilistic methods for uncertain reasoning ===\n\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.\nBayesian networks are a tool that can be used for reasoning (using the Bayesian inference algorithm), learning (using the expectation\u2013maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks).\nProbabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).\n\n\n=== Classifiers and statistical learning methods ===\nThe simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.\nThere are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\nThe naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.\nNeural networks are also used as classifiers.\n\n\n=== Artificial neural networks ===\n\nAn artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm. Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.\nIn feedforward neural networks the signal passes in only one direction. Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks. Perceptrons use only a single layer of neurons; deep learning uses multiple layers. Convolutional neural networks strengthen the connection between neurons that are \"close\" to each other\u2014this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.\n\n\n=== Deep learning ===\n\nDeep learning uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.\nDeep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification, and others. The reason that deep learning performs so well in so many applications is not known as of 2021. The sudden success of deep learning in 2012\u20132015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s) but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.", "mimetype": "text/plain", "start_char_idx": 15370, "end_char_idx": 20410, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "49df6bdf-331d-40bc-aaa2-e185f23a1355": {"__data__": {"id_": "49df6bdf-331d-40bc-aaa2-e185f23a1355", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "942bd085-b5c9-420e-b579-3690a466fc11", "node_type": "1", "metadata": {}, "hash": "b2f6abef76c643f5e959ed0619bc6e074164af693211d96a7ba6d49df0dc5bd8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f7ccd07f-4b8d-4b7f-b5b5-43751fde7d2e", "node_type": "1", "metadata": {}, "hash": "405b5ad569c77a9c6c19129acda78a06790b7806dcd7910481a526abe155f53a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== GPT ===\nGenerative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pretrained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems. Such systems are used in chatbots, which allow people to ask a question or request a task in simple text.\nCurrent models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.\n\n\n=== Hardware and software ===\n\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training. Specialized programming languages such as Prolog were used in early AI research, but general-purpose programming languages like Python have become predominant.\nThe transistor density in integrated circuits has been observed to roughly double every 18 months\u2014a trend known as Moore's law, named after the Intel co-founder Gordon Moore, who first identified it. Improvements in GPUs have been even faster, a trend sometimes called Huang's law, named after Nvidia co-founder and CEO Jensen Huang.\n\n\n== Applications ==\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok). The deployment of AI may be overseen by a Chief automation officer (CAO).\n\n\n=== Health and medicine ===\n\nThe application of AI in medicine and medical research has the potential to increase patient care and quality of life. Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\nFor medical research, AI is an important tool for processing and integrating big data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research. New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein. In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria. In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.", "mimetype": "text/plain", "start_char_idx": 20413, "end_char_idx": 24601, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f7ccd07f-4b8d-4b7f-b5b5-43751fde7d2e": {"__data__": {"id_": "f7ccd07f-4b8d-4b7f-b5b5-43751fde7d2e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49df6bdf-331d-40bc-aaa2-e185f23a1355", "node_type": "1", "metadata": {}, "hash": "198dfa08b9c7662985cb3887826e0da82b380963745d913f8fb9a82925ebdde3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb4f047f-2d13-42f4-ba0b-6b7e9dc0694b", "node_type": "1", "metadata": {}, "hash": "6ebc5cdd8678ba7666f41ea9adcbe75dd2f5cbbe80dbe657441820dbd50ebda3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Games ===\n\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world. Other programs handle imperfect-information games, such as the poker-playing program Pluribus. DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games. In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map. In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning. In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.\n\n\n=== Mathematics ===\nLarge language models, such as GPT-4, Gemini, Claude, LLaMa or Mistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections. A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data. One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result. The Alibaba Group developed a version of its Qwen models called Qwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems. In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53% of the AIME 2024 and 90% of the MATH benchmark problems.\nAlternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor, AlphaGeometry and AlphaProof all from Google DeepMind, Llemma from EleutherAI or Julius.\nWhen natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks.\nSome models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.\nTopological deep learning integrates various topological approaches.\n\n\n=== Finance ===\nFinance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.\nAccording to Nicolas Firzli, director of the World Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"\n\n\n=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human operated and autonomous.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n=== Generative AI ===", "mimetype": "text/plain", "start_char_idx": 24604, "end_char_idx": 29597, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "eb4f047f-2d13-42f4-ba0b-6b7e9dc0694b": {"__data__": {"id_": "eb4f047f-2d13-42f4-ba0b-6b7e9dc0694b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f7ccd07f-4b8d-4b7f-b5b5-43751fde7d2e", "node_type": "1", "metadata": {}, "hash": "405b5ad569c77a9c6c19129acda78a06790b7806dcd7910481a526abe155f53a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "15c30b0c-221a-4b81-950d-57dfe70e3fd2", "node_type": "1", "metadata": {}, "hash": "aa7c4adf21282cdb12f6c12f6e590c33717938d6a291fbb891d6371d0408a391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human operated and autonomous.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n=== Generative AI ===\n\n\n=== Agents ===\nArtificial intelligent (AI) agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.\n\n\n=== Sexuality ===\nApplications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer prediction, AI-integrated sex toys (e.g., teledildonics), AI-generated sexual education content, and AI agents that simulate sexual and romantic partners (e.g., Replika).  AI is also used for the production of non-consensual deepfake pornography, raising significant ethical and legal concerns.\nAI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.\n\n\n=== Other industry-specific tasks ===\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\nAI applications for evacuation and disaster management are growing. AI has been used to investigate if and how people evacuated in large scale and small scale evacuations using historical data from GPS, videos or social media. Further, AI can provide real time information on the real time evacuation conditions.\nIn agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\nDuring the 2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.\n\n\n== Ethics ==\n\nAI has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified. In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.\n\n\n=== Risks and harm ===", "mimetype": "text/plain", "start_char_idx": 28879, "end_char_idx": 33871, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "15c30b0c-221a-4b81-950d-57dfe70e3fd2": {"__data__": {"id_": "15c30b0c-221a-4b81-950d-57dfe70e3fd2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb4f047f-2d13-42f4-ba0b-6b7e9dc0694b", "node_type": "1", "metadata": {}, "hash": "6ebc5cdd8678ba7666f41ea9adcbe75dd2f5cbbe80dbe657441820dbd50ebda3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "328bd4e7-eb28-4469-86bc-f80dce24c6f0", "node_type": "1", "metadata": {}, "hash": "e2ae661e50d0e25486fbd389835caae2562bf952ff9a42e9dd5a87d226758162", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Ethics ==\n\nAI has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified. In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.\n\n\n=== Risks and harm ===\n\n\n==== Privacy and copyright ====\n\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\nAI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.\nSensitive user data collected may include online activity records, geolocation data, video, or audio. For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them. Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.\nAI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy. Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\"\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file. In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI. Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.\n\n\n==== Dominance by tech giants ====\nThe commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft. Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.\n\n\n==== Power needs and environmental impacts ====\n\nIn January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use. This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.\nProdigious power consumption by AI is responsible for the growth of fossil fuels use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources \u2013 from nuclear energy to geothermal to fusion. The tech firms argue that \u2013 in the long view \u2013 AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.\nA 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.", "mimetype": "text/plain", "start_char_idx": 33318, "end_char_idx": 38523, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "328bd4e7-eb28-4469-86bc-f80dce24c6f0": {"__data__": {"id_": "328bd4e7-eb28-4469-86bc-f80dce24c6f0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "15c30b0c-221a-4b81-950d-57dfe70e3fd2", "node_type": "1", "metadata": {}, "hash": "aa7c4adf21282cdb12f6c12f6e590c33717938d6a291fbb891d6371d0408a391", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b10d4ea0-65e0-4073-a614-55c06bfd2f9b", "node_type": "1", "metadata": {}, "hash": "4ead61a6d5fe967ecc3ea5f286df0a317bb14d808d126d25f25e9fead5c32625", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources \u2013 from nuclear energy to geothermal to fusion. The tech firms argue that \u2013 in the long view \u2013 AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.\nA 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means. Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.\nIn 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for $650 Million (US). Nvidia CEO Jen-Hsun Huang said nuclear power is a good option for the data centers.\nIn September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power \u2013 enough for 800,000 homes \u2013 of energy will be produced. The cost for re-opening and upgrading is estimated at $1.6 billion (US) and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act. The US government and the state of Michigan are investing almost $2 billion (US) to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon spinoff of Constellation.\nAfter the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages. Taiwan aims to phase out nuclear power by 2025. On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.\nAlthough most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near nuclear power plant for a new data center for generative AI. Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.\nOn 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center. \nAccording to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.\nIn 2025 a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300-500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people will pass from public transport to autonomous cars) can reduce it.", "mimetype": "text/plain", "start_char_idx": 37681, "end_char_idx": 42010, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b10d4ea0-65e0-4073-a614-55c06bfd2f9b": {"__data__": {"id_": "b10d4ea0-65e0-4073-a614-55c06bfd2f9b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "328bd4e7-eb28-4469-86bc-f80dce24c6f0", "node_type": "1", "metadata": {}, "hash": "e2ae661e50d0e25486fbd389835caae2562bf952ff9a42e9dd5a87d226758162", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aefd400a-538b-4499-a1d3-d017d70613c2", "node_type": "1", "metadata": {}, "hash": "e7d98fc8e12c14336af790dd1a5e31113a0e44f5f2851b02269ae983697ae8a7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "On 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center. \nAccording to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.\nIn 2025 a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300-500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people will pass from public transport to autonomous cars) can reduce it.\n\n\n==== Misinformation ====\n\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.\nIn 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films, or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda. One such potential malicious use is deepfakes for computational propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\nAI researchers at Microsoft, OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models.", "mimetype": "text/plain", "start_char_idx": 41087, "end_char_idx": 43600, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "aefd400a-538b-4499-a1d3-d017d70613c2": {"__data__": {"id_": "aefd400a-538b-4499-a1d3-d017d70613c2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b10d4ea0-65e0-4073-a614-55c06bfd2f9b", "node_type": "1", "metadata": {}, "hash": "4ead61a6d5fe967ecc3ea5f286df0a317bb14d808d126d25f25e9fead5c32625", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f6747b15-d4a3-410a-88f8-e649ce76985f", "node_type": "1", "metadata": {}, "hash": "9e1227af9d3b67482855dbc7a2f98e4b8e3124f06331ba80416c67532a427d05", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Algorithmic bias and fairness ====\n\nMachine learning applications will be biased if they learn from biased data. The developers may not be aware that the bias exists. Bias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination. The field of fairness studies how to prevent harms from algorithmic biases.\nOn June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different\u2014the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\". Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"\nCriticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.\nThere are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.\nAt its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery, in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.", "mimetype": "text/plain", "start_char_idx": 43603, "end_char_idx": 48092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f6747b15-d4a3-410a-88f8-e649ce76985f": {"__data__": {"id_": "f6747b15-d4a3-410a-88f8-e649ce76985f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aefd400a-538b-4499-a1d3-d017d70613c2", "node_type": "1", "metadata": {}, "hash": "e7d98fc8e12c14336af790dd1a5e31113a0e44f5f2851b02269ae983697ae8a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8396280b-a52d-4445-b217-efa5a1e08059", "node_type": "1", "metadata": {}, "hash": "256371a07578bc23e597d7f516f3e7f0272fbc7023f171740ce5e4684c32a177", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Lack of transparency ====\n\nMany AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.\nIt is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.\nPeople who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.\nDARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.\nSeveral approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output. LIME can locally approximate a model's outputs with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning. For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.\n\n\n==== Bad actors and weaponized AI ====\n\nArtificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction. Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed. By 2015, over fifty countries were reported to be researching battlefield robots.\nAI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware. All these technologies have been available since 2020 or earlier\u2014AI facial recognition systems are already being used for mass surveillance in China.\nThere many other ways that AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.", "mimetype": "text/plain", "start_char_idx": 48095, "end_char_idx": 52769, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8396280b-a52d-4445-b217-efa5a1e08059": {"__data__": {"id_": "8396280b-a52d-4445-b217-efa5a1e08059", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6747b15-d4a3-410a-88f8-e649ce76985f", "node_type": "1", "metadata": {}, "hash": "9e1227af9d3b67482855dbc7a2f98e4b8e3124f06331ba80416c67532a427d05", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "514b7443-41bf-4c11-bfb6-debeaf5421e6", "node_type": "1", "metadata": {}, "hash": "4c0fcd117a231c0d9a77ba0b2640d3539d9668bb93cf6002c55e2c55a6865ecd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Technological unemployment ====\n\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies. In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.\nFrom the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.", "mimetype": "text/plain", "start_char_idx": 52772, "end_char_idx": 54814, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "514b7443-41bf-4c11-bfb6-debeaf5421e6": {"__data__": {"id_": "514b7443-41bf-4c11-bfb6-debeaf5421e6", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8396280b-a52d-4445-b217-efa5a1e08059", "node_type": "1", "metadata": {}, "hash": "256371a07578bc23e597d7f516f3e7f0272fbc7023f171740ce5e4684c32a177", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1e55e3a8-d017-4f4f-ad9e-8fbd09786241", "node_type": "1", "metadata": {}, "hash": "71cbfaa40c8636fceae4e1fe5bb6e00445b143c290ca66c373774e1faa17710a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Existential risk ====\n\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\nFirst, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are built on language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk, as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI.\nIn May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\". He notably mentioned risks of an AI takeover, and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.\nIn 2023, many leading AI experts endorsed the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".\nSome other researchers were more optimistic. AI pioneer J\u00fcrgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\" While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\" Andrew Ng also argued that \"it's a mistake to fall for the doomsday hype on AI\u2014and that regulators who do will only benefit vested interests.\" Yann LeCun \"scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\" In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine. However, after 2016, the study of current and future risks and possible solutions became a serious area of research.\n\n\n=== Ethical machines and alignment ===\n\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\nThe field of machine ethics is also called computational morality,\nand was founded at an AAAI symposium in 2005.\nOther approaches include Wendell Wallach's \"artificial moral agents\" and Stuart J. Russell's three principles for developing provably beneficial machines.", "mimetype": "text/plain", "start_char_idx": 54817, "end_char_idx": 59246, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e55e3a8-d017-4f4f-ad9e-8fbd09786241": {"__data__": {"id_": "1e55e3a8-d017-4f4f-ad9e-8fbd09786241", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "514b7443-41bf-4c11-bfb6-debeaf5421e6", "node_type": "1", "metadata": {}, "hash": "4c0fcd117a231c0d9a77ba0b2640d3539d9668bb93cf6002c55e2c55a6865ecd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "449bfbce-9ec5-4336-ad08-10c4971325ad", "node_type": "1", "metadata": {}, "hash": "ee4b1d5f0ce19cd7a4a16b0425944f45e48fe9787421efe701ab0e5746cb9967", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Ethical machines and alignment ===\n\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\nThe field of machine ethics is also called computational morality,\nand was founded at an AAAI symposium in 2005.\nOther approaches include Wendell Wallach's \"artificial moral agents\" and Stuart J. Russell's three principles for developing provably beneficial machines.\n\n\n=== Open source ===\nActive organizations in the AI open-source community include Hugging Face, Google, EleutherAI and Meta. Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight, meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case. Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.\n\n\n=== Frameworks ===\nArtificial Intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows:\n\nRespect the dignity of individual people\nConnect with other people sincerely, openly, and inclusively\nCare for the wellbeing of everyone\nProtect social values, justice, and the public interest\nOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others; however, these principles are not without criticism, especially regards to the people chosen to contribute to these frameworks.\nPromotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\nThe UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under a MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.", "mimetype": "text/plain", "start_char_idx": 58385, "end_char_idx": 61806, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "449bfbce-9ec5-4336-ad08-10c4971325ad": {"__data__": {"id_": "449bfbce-9ec5-4336-ad08-10c4971325ad", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1e55e3a8-d017-4f4f-ad9e-8fbd09786241", "node_type": "1", "metadata": {}, "hash": "71cbfaa40c8636fceae4e1fe5bb6e00445b143c290ca66c373774e1faa17710a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1374a695-2852-4d4e-b52d-ffb850d0a853", "node_type": "1", "metadata": {}, "hash": "82118279e8af7887157cb932a9be3b04ec81f436a1344ba951d100111860dc7f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Regulation ===\n\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone. Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI. Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia. The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI. In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics. In 2024, the Council of Europe created the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity. In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".\nIn November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks. 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence. In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.\n\n\n== History ==\n\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning. This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\". They developed several areas of research that would become part of AI, such as McCullouch and Pitts design for \"artificial neurons\" in 1943, and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that \"machine intelligence\" was plausible.\nThe field of AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field. In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\". In 1967 Marvin Minsky agreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\". They had, however, underestimated the difficulty of the problem. In 1974, both the U.S.", "mimetype": "text/plain", "start_char_idx": 61809, "end_char_idx": 66626, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1374a695-2852-4d4e-b52d-ffb850d0a853": {"__data__": {"id_": "1374a695-2852-4d4e-b52d-ffb850d0a853", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "449bfbce-9ec5-4336-ad08-10c4971325ad", "node_type": "1", "metadata": {}, "hash": "ee4b1d5f0ce19cd7a4a16b0425944f45e48fe9787421efe701ab0e5746cb9967", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "84f828ab-1e16-4545-b622-bac519443665", "node_type": "1", "metadata": {}, "hash": "10eea03456e564d5cf65fcccb236fa929294372e3e5dda3ee77a1c148858e5c8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field. In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\". In 1967 Marvin Minsky agreed, writing that \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\". They had, however, underestimated the difficulty of the problem. In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.\nIn the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.\nUp to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition, and began to look into \"sub-symbolic\" approaches. Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics). By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the AI effect).\nHowever, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\nFor many specific tasks, other methods were abandoned.\nDeep learning's success was based on both hardware improvements (faster computers, graphics processing units, cloud computing) and access to large amounts of data (including curated datasets, such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI. The amount of machine learning research (measured by total publications) increased by 50% in the years 2015\u20132019.\n\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself.", "mimetype": "text/plain", "start_char_idx": 65743, "end_char_idx": 70591, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "84f828ab-1e16-4545-b622-bac519443665": {"__data__": {"id_": "84f828ab-1e16-4545-b622-bac519443665", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1374a695-2852-4d4e-b52d-ffb850d0a853", "node_type": "1", "metadata": {}, "hash": "82118279e8af7887157cb932a9be3b04ec81f436a1344ba951d100111860dc7f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "65d37f32-d07d-45a5-973f-134a15bca219", "node_type": "1", "metadata": {}, "hash": "00400c3c68ac3ac4bfb154193362f74a9c725fbf605c218a19237989c19bf4e5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Deep learning's success led to an enormous increase in interest and funding in AI. The amount of machine learning research (measured by total publications) increased by 50% in the years 2015\u20132019.\n\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text. ChatGPT, launched on November 30, 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months. It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness. These programs, and others, inspired an aggressive AI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about $50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\". About 800,000 \"AI\"-related U.S. job openings existed in 2022. According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies.\n\n\n== Philosophy ==\n\nPhilosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines. Another major focus has been whether machines can be conscious, and the associated ethical implications. Many other topics in philosophy are relevant to AI, such as epistemology and free will. Rapid advancements have intensified public discussions on the philosophy and ethics of AI.\n\n\n=== Defining artificial intelligence ===\n\nAlan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\" He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\". He devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"\n\nRussell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure. However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\". Another AI founder, Marvin Minsky, similarly describes it as \"the ability to solve hard problems\". The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals. These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine\u2014and no other philosophical discussion is required, or may not even be possible.\nAnother definition has been adopted by Google, a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\nSome authors have suggested in practice, that the definition of AI is vague and difficult to define, with contention as to whether classical algorithms should be categorised as AI, with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".\n\n\n=== Evaluating approaches to AI ===\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.", "mimetype": "text/plain", "start_char_idx": 69825, "end_char_idx": 74858, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "65d37f32-d07d-45a5-973f-134a15bca219": {"__data__": {"id_": "65d37f32-d07d-45a5-973f-134a15bca219", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "84f828ab-1e16-4545-b622-bac519443665", "node_type": "1", "metadata": {}, "hash": "10eea03456e564d5cf65fcccb236fa929294372e3e5dda3ee77a1c148858e5c8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f4c21acf-7b2d-4eed-ad56-489e7d634a7f", "node_type": "1", "metadata": {}, "hash": "5e1bc737e3f3dd88887892d1a6b735bf704d69f3de1a467a1646c05b84e26b39", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Evaluating approaches to AI ===\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\n\n\n==== Symbolic AI and its limits ====\nSymbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult. Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge. Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\n\n\n==== Neat vs. scruffy ====\n\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s, but eventually was seen as irrelevant. Modern AI has elements of both.\n\n\n==== Soft vs. hard computing ====\n\nFinding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\n\n\n==== Narrow vs. general AI ====\n\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals. General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\n\n\n=== Machine consciousness, sentience, and mind ===\n\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.", "mimetype": "text/plain", "start_char_idx": 74321, "end_char_idx": 78836, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4c21acf-7b2d-4eed-ad56-489e7d634a7f": {"__data__": {"id_": "f4c21acf-7b2d-4eed-ad56-489e7d634a7f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "65d37f32-d07d-45a5-973f-134a15bca219", "node_type": "1", "metadata": {}, "hash": "00400c3c68ac3ac4bfb154193362f74a9c725fbf605c218a19237989c19bf4e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c02e6d01-a5e4-4fab-b4d3-1e45bd33cfc8", "node_type": "1", "metadata": {}, "hash": "c0bbd548a2175382d7148e960e3661adf7cf9e76aa17b5af9cb9f2bd39ed68f0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Machine consciousness, sentience, and mind ===\n\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\n\n\n==== Consciousness ====\n\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\n\n\n==== Computationalism and functionalism ====\n\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind\u2013body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.\n\n\n==== AI welfare and rights ====\nIt is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree. But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals. Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights. Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.\nIn 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities. Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part to society on their own.\nProgress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.\n\n\n== Future ==\n\n\n=== Superintelligence and the singularity ===\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.", "mimetype": "text/plain", "start_char_idx": 78058, "end_char_idx": 82765, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c02e6d01-a5e4-4fab-b4d3-1e45bd33cfc8": {"__data__": {"id_": "c02e6d01-a5e4-4fab-b4d3-1e45bd33cfc8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4c21acf-7b2d-4eed-ad56-489e7d634a7f", "node_type": "1", "metadata": {}, "hash": "5e1bc737e3f3dd88887892d1a6b735bf704d69f3de1a467a1646c05b84e26b39", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "841c4567-a53f-4573-880b-d1866702a721", "node_type": "1", "metadata": {}, "hash": "2a3c9ca8d179ab9c31627a6adc9606b6e502388da15cf0aecf448d41b37685d1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Future ==\n\n\n=== Superintelligence and the singularity ===\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\n\n\n=== Transhumanism ===\n\nRobot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger.\nEdward Fredkin argues that \"artificial intelligence is the next step in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.\n\n\n=== Decomputing ===\nArguments for decomputing have been raised by Dan McQuillan (Resisting AI: An Anti-fascist Approach to Artificial Intelligence, 2022), meaning an opposition to the sweeping application and expansion of artificial intelligence. Similar to degrowth, the approach criticizes AI as an outgrowth of the systemic issues and capitalist world we live in. It argues that a different future is possible, in which distance between people is reduced rather than increased through AI intermediaries.\n\n\n== In fiction ==\n\nThought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.\nA common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.\nIsaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel \u010capek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\n\n\n== See also ==\nArtificial consciousness \u2013 Field in cognitive science\nArtificial intelligence and elections \u2013 Use and impact of AI on political elections\nArtificial intelligence content detection \u2013 Software to detect AI-generated content\nBehavior selection algorithm \u2013 Algorithm that selects actions for intelligent agents\nBusiness process automation \u2013 Automation of business processes\nCase-based reasoning \u2013 Process of solving new problems based on the solutions of similar past problems\nComputational intelligence \u2013 Ability of a computer to learn a specific task from data or experimental observation\nDigital immortality \u2013 Hypothetical concept of storing a personality in digital form\nEmergent algorithm \u2013 Algorithm exhibiting emergent behavior\nFemale gendering of AI technologies \u2013 Gender biases in digital technologyPages displaying short descriptions of redirect targets\nGlossary of artificial intelligence \u2013 List of definitions of terms and concepts commonly used in the study of artificial intelligence\nIntelligence amplification \u2013 Use of information technology to augment human intelligence\nIntelligent agent \u2013 Software agent which acts autonomously\nIntelligent automation \u2013 Software process that combines robotic process automation and artificial intelligence\nMind uploading \u2013 Hypothetical process of digitally emulating a brain\nOrganoid intelligence \u2013 Use of brain cells and brain organoids for intelligent computing\nRobotic process automation \u2013 Form of business process automation technology\nThe Last Day \u2013 1967 Welsh science fiction novel\nWetware computer \u2013 Computer composed of organic material\n\n\n== Explanatory notes ==\n\n\n== References ==", "mimetype": "text/plain", "start_char_idx": 82074, "end_char_idx": 87121, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "841c4567-a53f-4573-880b-d1866702a721": {"__data__": {"id_": "841c4567-a53f-4573-880b-d1866702a721", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1164", "node_type": "4", "metadata": {}, "hash": "74f6b9519753028f23f8c6792fed9503eec8640d712dc809eda8222bd6012428", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c02e6d01-a5e4-4fab-b4d3-1e45bd33cfc8", "node_type": "1", "metadata": {}, "hash": "c0bbd548a2175382d7148e960e3661adf7cf9e76aa17b5af9cb9f2bd39ed68f0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Explanatory notes ==\n\n\n== References ==\n\n\n=== AI textbooks ===\nThe two most widely used textbooks in 2023 (see the Open Syllabus):\n\nRussell, Stuart J.; Norvig, Peter (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0-1346-1099-3. LCCN 20190474.\nRich, Elaine; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0-0700-8770-5.\nThe four most widely used AI textbooks in 2008:\n\nOther textbooks:\n\nErtel, Wolfgang (2017). Introduction to Artificial Intelligence (2nd ed.). Springer. ISBN 978-3-3195-8486-7.\nCiaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI (1st ed.). Intellisemantic Editions. ISBN 978-8-8947-8760-3.\n\n\n=== History of AI ===\n\n\n=== Other sources ===\n\n\n== Further reading ==\n\n\n== External links ==\n\n\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.", "mimetype": "text/plain", "start_char_idx": 87079, "end_char_idx": 88039, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e571a374-3eff-4770-8f33-3f464457c9b2": {"__data__": {"id_": "e571a374-3eff-4770-8f33-3f464457c9b2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07db5142-e837-4c44-82ca-66fa6f5b0a8c", "node_type": "1", "metadata": {}, "hash": "6c1b73a39dcc5f14a810e8aa7e0e0af1dfada7c39a93a80fef62b14027f0852d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\nStatistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning. \nFrom a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.\n\n\n== History ==\n\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used in this time period.\nAlthough the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes. In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data. Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.\nBy the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions. A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".\nModern-day machine learning has two objectives.  One is to classify data based on models which have been developed; the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.\n\n\n== Relationships to other fields ==", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4392, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "07db5142-e837-4c44-82ca-66fa6f5b0a8c": {"__data__": {"id_": "07db5142-e837-4c44-82ca-66fa6f5b0a8c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e571a374-3eff-4770-8f33-3f464457c9b2", "node_type": "1", "metadata": {}, "hash": "a32c6e6418d99fbe0390d3e68a98d8a78249edcde77f59580683c56de7e63dae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6fb7e81c-e518-4f40-afd9-851547334fe8", "node_type": "1", "metadata": {}, "hash": "83511b761af202f82e7d8b52354150f8b242203513d58530f48a3d3e93ffce48", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Relationships to other fields ==\n\n\n=== Artificial intelligence ===\n\nAs a scientific endeavour, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalised linear models of statistics. Probabilistic reasoning was also employed, especially in automated medical diagnosis.:\u200a488\u200a\nHowever, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.:\u200a488\u200a By 1980, expert systems had come to dominate AI, and statistics was out of favour. Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming(ILP), but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.:\u200a708\u2013710,\u200a755\u200a Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including John Hopfield, David Rumelhart, and Geoffrey Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.:\u200a25\u200a\nMachine learning (ML), reorganised and recognised as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.\n\n\n=== Data compression ===\n\n\n=== Data mining ===\nMachine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\nMachine learning also has intimate ties to optimisation: Many learning problems are formulated as minimisation of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples).\n\n\n=== Generalization ===\nCharacterizing the generalisation of various learning algorithms is an active topic of current research, especially for deep learning algorithms.\n\n\n=== Statistics ===\nMachine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalisable predictive patterns. According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics. He also suggested the term data science as a placeholder to call the overall field.\nConventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.\nLeo Breiman distinguished two statistical modelling paradigms: data model and algorithmic model, wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest.\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.", "mimetype": "text/plain", "start_char_idx": 4357, "end_char_idx": 9543, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6fb7e81c-e518-4f40-afd9-851547334fe8": {"__data__": {"id_": "6fb7e81c-e518-4f40-afd9-851547334fe8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07db5142-e837-4c44-82ca-66fa6f5b0a8c", "node_type": "1", "metadata": {}, "hash": "6c1b73a39dcc5f14a810e8aa7e0e0af1dfada7c39a93a80fef62b14027f0852d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2d69cae6-e450-4542-a647-c31ca069d7da", "node_type": "1", "metadata": {}, "hash": "9a0c7171cc47b73fc76f6c7aa073c8f2c20f61a6cf8ed8174493b8d9ea87d6e4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Statistical physics ===\nAnalytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyse the weight space of deep neural networks. Statistical physics is thus finding applications in the area of medical diagnostics.\n\n\n== Theory ==\n\nA core objective of a learner is to generalise from its experience. Generalisation in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\nThe computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning  model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias\u2013variance decomposition is one way to quantify generalisation error.\nFor the best performance in the context of generalisation, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalisation will be poorer.\nIn addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\n\n\n== Approaches ==\n\nMachine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\n\nSupervised learning: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\nUnsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\nReinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximise.\nAlthough each algorithm has advantages and limitations, no single algorithm works for all problems.\n\n\n=== Supervised learning ===\n\nSupervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs. The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimisation of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs. An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.\nTypes of supervised-learning algorithms include active learning, classification and regression. Classification algorithms are used when the outputs are restricted to a limited set of values, while regression algorithms are used when the outputs can take any numerical value within a range. For example, in a classification algorithm that filters emails, the input is an incoming email, and the output is the folder in which to file the email. In contrast, regression is used for tasks such as predicting a person's height based on factors like age and genetics or forecasting future temperatures based on historical data.\nSimilarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.", "mimetype": "text/plain", "start_char_idx": 9546, "end_char_idx": 14813, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2d69cae6-e450-4542-a647-c31ca069d7da": {"__data__": {"id_": "2d69cae6-e450-4542-a647-c31ca069d7da", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6fb7e81c-e518-4f40-afd9-851547334fe8", "node_type": "1", "metadata": {}, "hash": "83511b761af202f82e7d8b52354150f8b242203513d58530f48a3d3e93ffce48", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "535bd41b-2096-4dcf-8b12-7bfac5d6cbc7", "node_type": "1", "metadata": {}, "hash": "66e5d151c42e890f2eeb2fd6c47e9f07d2fbaa45326fe68730c1b3a7e2061b54", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Unsupervised learning ===\n\nUnsupervised learning algorithms find structures in data that has not been labelled, classified or categorised. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction, and density estimation.\nCluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.\nA special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.\n\n\n=== Semi-supervised learning ===\n\nSemi-supervised learning falls between unsupervised learning (without any labelled training data) and supervised learning (with completely labelled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabelled data, when used in conjunction with a small amount of labelled data, can produce a considerable improvement in learning accuracy.\nIn weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.\n\n\n=== Reinforcement learning ===\n\nReinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximise some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcement learning algorithms use dynamic programming techniques. Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\n\n\n=== Dimensionality reduction ===\nDimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables. In other words, it is a process of reducing the dimension of the feature set, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).\nThe manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularisation.\n\n\n=== Other types ===\nOther approaches have been developed which do not fit neatly into this three-fold categorisation, and sometimes more than one is used by the same machine learning system. For example, topic modelling, meta-learning.\n\n\n==== Self-learning ====\nSelf-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA). It gives a solution to the problem learning without any external reward, by introducing emotion as an internal reward. Emotion is used as state evaluation of a self-learning agent. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.\nThe self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine: \n\nin situation s perform action a\nreceive a consequence situation s'\ncompute emotion of being in the consequence situation v(s')\nupdate crossbar memory  w'(a,s) = w(a,s) + v(s')\nIt is a system with only one input, situation, and only one output, action (or behaviour) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioural environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behaviour, in an environment that contains both desirable and undesirable situations.", "mimetype": "text/plain", "start_char_idx": 14816, "end_char_idx": 20312, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "535bd41b-2096-4dcf-8b12-7bfac5d6cbc7": {"__data__": {"id_": "535bd41b-2096-4dcf-8b12-7bfac5d6cbc7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2d69cae6-e450-4542-a647-c31ca069d7da", "node_type": "1", "metadata": {}, "hash": "9a0c7171cc47b73fc76f6c7aa073c8f2c20f61a6cf8ed8174493b8d9ea87d6e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2bee5fd6-1cf2-42e4-84e4-b657973dd793", "node_type": "1", "metadata": {}, "hash": "b34717786220a0887c24cfaa2d6710db96795ade1833c7c4fc3d78842231cbbc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Feature learning ====\n\nSeveral learning algorithms aim at discovering better representations of the inputs provided during training. Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task.\nFeature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labelled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabelled input data.  Examples include dictionary learning, independent component analysis, autoencoders, matrix factorisation and various forms of clustering.\nManifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors. Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.\nFeature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\n\n\n==== Sparse dictionary learning ====\n\nSparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately. A popular heuristic method for sparse dictionary learning is the k-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.\n\n\n==== Anomaly detection ====\n\nIn data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.\nIn particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.\nThree broad categories of anomaly detection techniques exist. Unsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance to be generated by the model.\n\n\n==== Robot learning ====\nRobot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning, and finally meta-learning (e.g. MAML).", "mimetype": "text/plain", "start_char_idx": 20315, "end_char_idx": 25736, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2bee5fd6-1cf2-42e4-84e4-b657973dd793": {"__data__": {"id_": "2bee5fd6-1cf2-42e4-84e4-b657973dd793", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "535bd41b-2096-4dcf-8b12-7bfac5d6cbc7", "node_type": "1", "metadata": {}, "hash": "66e5d151c42e890f2eeb2fd6c47e9f07d2fbaa45326fe68730c1b3a7e2061b54", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4fa2024f-cfd6-4696-8a88-14509984b5b3", "node_type": "1", "metadata": {}, "hash": "38493ce3c337dbf140869bf6a40770a001021913960477a18fe3208928e53671", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Robot learning ====\nRobot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning, and finally meta-learning (e.g. MAML).\n\n\n==== Association rules ====\n\nAssociation rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".\nRule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction. Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.\nBased on the concept of strong rules, Rakesh Agrawal, Tomasz Imieli\u0144ski and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets. For example, the rule \n  \n    \n      \n        {\n        \n          o\n          n\n          i\n          o\n          n\n          s\n          ,\n          p\n          o\n          t\n          a\n          t\n          o\n          e\n          s\n        \n        }\n        \u21d2\n        {\n        \n          b\n          u\n          r\n          g\n          e\n          r\n        \n        }\n      \n    \n    {\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}}\n  \n found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.\nLearning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.\nInductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.\nInductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting. Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples. The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.\n\n\n== Models ==\nA machine learning model is a type of mathematical model that, once \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions. By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.\nVarious types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.", "mimetype": "text/plain", "start_char_idx": 25543, "end_char_idx": 30310, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4fa2024f-cfd6-4696-8a88-14509984b5b3": {"__data__": {"id_": "4fa2024f-cfd6-4696-8a88-14509984b5b3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2bee5fd6-1cf2-42e4-84e4-b657973dd793", "node_type": "1", "metadata": {}, "hash": "b34717786220a0887c24cfaa2d6710db96795ade1833c7c4fc3d78842231cbbc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8335c64a-35da-4cef-82ff-97340256d954", "node_type": "1", "metadata": {}, "hash": "5f064d7f0cdbf86d5135a1514be46a74712a14cb06a57a6fb4f0df6dc7eb6980", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Models ==\nA machine learning model is a type of mathematical model that, once \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions. By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.\nVarious types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.\n\n\n=== Artificial neural networks ===\n\nArtificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial neurons\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\nDeep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.\n\n\n=== Decision trees ===\n\nDecision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\n\n\n=== Random forest regression ===\nRandom forest regression (RFR) falls under umbrella of decision tree-based models. RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting.  To build decision trees, RFR uses bootstrapped sampling, for instance each decision tree is trained on random data of from training set. This random selection of RFR for training enables model to reduce bias predictions and achieve accuracy. RFR generates independent decision trees, and it can work on single output data as well multiple regressor task. This makes RFR compatible to be used in various application.\n\n\n=== Support-vector machines ===\n\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category. An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.", "mimetype": "text/plain", "start_char_idx": 29650, "end_char_idx": 34987, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8335c64a-35da-4cef-82ff-97340256d954": {"__data__": {"id_": "8335c64a-35da-4cef-82ff-97340256d954", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4fa2024f-cfd6-4696-8a88-14509984b5b3", "node_type": "1", "metadata": {}, "hash": "38493ce3c337dbf140869bf6a40770a001021913960477a18fe3208928e53671", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3cfcf0d7-d3ed-4b09-b8d6-48e32d306428", "node_type": "1", "metadata": {}, "hash": "b22d5eed987498f971f46e6fb5e912991327cd1fcbe7413c0d8405afa9f13352", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Support-vector machines ===\n\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category. An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n\n\n=== Regression analysis ===\n\nRegression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularisation methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.\nMultivariate linear regression extends the concept of linear regression to handle multiple dependent variables simultaneously. This approach estimates the relationships between a set of input variables and several output variables by fitting a multidimensional linear model. It is particularly useful in scenarios where outputs are interdependent or share underlying patterns, such as predicting multiple economic indicators or reconstructing images, which are inherently multi-dimensional.\n\n\n=== Bayesian networks ===\n\nA Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.\n\n\n=== Gaussian processes ===\n\nA Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.\nGiven a set of observed points, or input\u2013output examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point.\nGaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation.\n\n\n=== Genetic algorithms ===\n\nA genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s. Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.\n\n\n=== Belief functions ===\n\nThe theory of belief functions, also referred to as evidence theory or Dempster\u2013Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and  imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,  Dempster's rule of combination), just like how in a pmf-based Bayesian approach would combine probabilities. However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving. However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.\n\n\n=== Rule-based models ===\n\nRule-based machine learning (RBML) is a branch of machine learning that automatically discovers and learns 'rules' from data. It provides interpretable models, making it useful for decision-making in fields like healthcare, fraud detection, and cybersecurity. Key RBML techniques includes learning classifier systems, association rule learning, artificial immune systems, and other similar models. These methods extract patterns from data and evolve rules over time.", "mimetype": "text/plain", "start_char_idx": 34217, "end_char_idx": 40040, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3cfcf0d7-d3ed-4b09-b8d6-48e32d306428": {"__data__": {"id_": "3cfcf0d7-d3ed-4b09-b8d6-48e32d306428", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8335c64a-35da-4cef-82ff-97340256d954", "node_type": "1", "metadata": {}, "hash": "5f064d7f0cdbf86d5135a1514be46a74712a14cb06a57a6fb4f0df6dc7eb6980", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "82e0490b-42aa-408b-b954-ed9f67e759c8", "node_type": "1", "metadata": {}, "hash": "d261f12302f075c79305f7a688d9acb6b9a6ef6550adf6f7d09ff99c5d53529a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Rule-based models ===\n\nRule-based machine learning (RBML) is a branch of machine learning that automatically discovers and learns 'rules' from data. It provides interpretable models, making it useful for decision-making in fields like healthcare, fraud detection, and cybersecurity. Key RBML techniques includes learning classifier systems, association rule learning, artificial immune systems, and other similar models. These methods extract patterns from data and evolve rules over time.\n\n\n=== Training models ===\nTypically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably, becoming integrated within machine learning engineering teams.\n\n\n==== Federated learning ====\n\nFederated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralises the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralised server. This also increases efficiency by decentralising the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.\n\n\n== Applications ==\nThere are many applications for machine learning, including:\n\nIn 2006, the media-services provider Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million. Shortly after the prize was awarded, Netflix realised that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly. In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists. In 2019 Springer Nature published the first research book created using machine learning. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning was recently applied to predict the pro-environmental behaviour of travellers. Recently, machine learning technology was also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone. When applied correctly, machine learning algorithms (MLAs) can utilise a wide range of company characteristics to predict stock returns without overfitting. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS.\nRecent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.\nMachine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes. Other applications have been focusing on pre evacuation decisions in building fires. \nMachine learning is also emerging as a promising tool in geotechnical engineering, where it is used to support tasks such as ground classification, hazard prediction, and site characterization. Recent research emphasizes a move toward data-centric methods in this field, where machine learning is not a replacement for engineering judgment, but a way to enhance it using site-specific data and patterns.", "mimetype": "text/plain", "start_char_idx": 39547, "end_char_idx": 44651, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82e0490b-42aa-408b-b954-ed9f67e759c8": {"__data__": {"id_": "82e0490b-42aa-408b-b954-ed9f67e759c8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3cfcf0d7-d3ed-4b09-b8d6-48e32d306428", "node_type": "1", "metadata": {}, "hash": "b22d5eed987498f971f46e6fb5e912991327cd1fcbe7413c0d8405afa9f13352", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "355b74b3-8b63-403a-ad6e-9267d4f2a8dd", "node_type": "1", "metadata": {}, "hash": "bbefd6f6935096165fbbebac2921c94ecaa22e479153937367bc5c2606932f09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Limitations ==\nAlthough machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results. Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.\nThe \"black box theory\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data. The House of Lords Select Committee, which claimed that such an \"intelligence system\" that could have a \"substantial impact on an individual's life\" would not be considered acceptable unless it provided \"a full and satisfactory explanation for the decisions\" it makes.\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision. Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested. Microsoft's Bing Chat chatbot has been reported to produce hostile and offensive response against its users.\nMachine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.\n\n\n=== Explainability ===\n\nExplainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI. It contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision. By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.\n\n\n=== Overfitting ===\n\nSettling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is.\n\n\n=== Other limitations and vulnerabilities ===\nLearners can also disappoint by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses. A real-world example is that, unlike humans, current image classifiers often do not primarily make judgements from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.\nAdversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel. Machine learning models are often vulnerable to manipulation or evasion via adversarial machine learning.\nResearchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories \"spam\" and well-visible \"not spam\" of posts) machine learning models that are often developed or trained by third parties. Parties can change the classification of any input, including in cases for which a type of data/software transparency is provided, possibly including white-box access.\n\n\n== Model assessments ==\nClassification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.\nIn addition to overall accuracy, investigators frequently report sensitivity and specificity meaning true positive rate (TPR) and true negative rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. Receiver operating characteristic (ROC) along with the accompanying Area Under the ROC Curve (AUC) offer additional tools for classification model assessment. Higher AUC is associated with a better performing model.\n\n\n== Ethics ==", "mimetype": "text/plain", "start_char_idx": 44654, "end_char_idx": 49955, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "355b74b3-8b63-403a-ad6e-9267d4f2a8dd": {"__data__": {"id_": "355b74b3-8b63-403a-ad6e-9267d4f2a8dd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "82e0490b-42aa-408b-b954-ed9f67e759c8", "node_type": "1", "metadata": {}, "hash": "d261f12302f075c79305f7a688d9acb6b9a6ef6550adf6f7d09ff99c5d53529a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c5d4dced-0b7e-438d-999a-1429b1c269a1", "node_type": "1", "metadata": {}, "hash": "62f5185104176193d8eab772729ce26f9bca8cd58d6dd4c5a3a226c1c65124a3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Ethics ==\n\n\n=== Bias ===\n\nDifferent machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.\nSystems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices. For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly 60 candidates who were found to either be women or have non-European sounding names. Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants. Another example includes predictive policing company Geolitica's predictive algorithm that resulted in \"disproportionately high levels of over-policing in low-income and minority communities\" after being trained with historical crime data.\nWhile responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame lack of participation and representation of minority population in the field of AI for machine learning's vulnerability to biases. In fact, according to research carried out by the Computing Research Association (CRA) in 2021, \"female faculty merely make up 16.1%\" of all faculty members who focus on AI among several universities around the world. Furthermore, among the group of \"new U.S. resident AI PhD graduates,\" 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.\nLanguage models learned from data have been shown to contain human-like biases. Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases. In 2016, Microsoft tested Tay, a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.\nIn an experiment carried out by ProPublica, an investigative journalism organisation, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants\". In 2015, Google Photos once tagged a couple of black people as gorillas, which caused controversy. The gorilla label was subsequently removed, and in 2023, it still cannot recognise gorillas. Similar issues with recognising non-white people have been found in many other systems.\nBecause of such challenges, the effective use of machine learning may take longer to be adopted in other domains. Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who said that \"[t]here's nothing artificial about AI. It's inspired by people, it's created by people, and\u2014most importantly\u2014it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"\n\n\n=== Financial incentives ===\nThere are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.\n\n\n== Hardware ==\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units. By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.", "mimetype": "text/plain", "start_char_idx": 49943, "end_char_idx": 54795, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c5d4dced-0b7e-438d-999a-1429b1c269a1": {"__data__": {"id_": "c5d4dced-0b7e-438d-999a-1429b1c269a1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "355b74b3-8b63-403a-ad6e-9267d4f2a8dd", "node_type": "1", "metadata": {}, "hash": "bbefd6f6935096165fbbebac2921c94ecaa22e479153937367bc5c2606932f09", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8eb652ea-9d53-41fb-8599-340cfcba5ef8", "node_type": "1", "metadata": {}, "hash": "d654f0bc50c82970a3f365d441ba63e91ccaceb1452a39a0fc85e6b59cd70f9e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Hardware ==\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units. By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.\n\n\n=== Tensor Processing Units (TPUs) ===\nTensor Processing Units (TPUs) are specialised hardware accelerators developed by Google specifically for machine learning workloads. Unlike general-purpose GPUs and FPGAs, TPUs are optimised for tensor computations, making them particularly efficient for deep learning tasks such as training and inference. They are widely used in Google Cloud AI services and large-scale machine learning models like Google's DeepMind AlphaFold and large language models. TPUs leverage matrix multiplication units and high-bandwidth memory to accelerate computations while maintaining energy efficiency. Since their introduction in 2016, TPUs have become a key component of AI infrastructure, especially in cloud-based environments.\n\n\n=== Neuromorphic computing ===\nNeuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks. These systems may be implemented through software-based simulations on conventional hardware or through specialised hardware architectures.\n\n\n==== physical neural networks ====\nA physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials, such as memristors, to emulate the function of neural synapses. The term \"physical neural network\" highlights the use of physical hardware for computation, as opposed to software-based implementations. It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses.\n\n\n=== Embedded machine learning ===\nEmbedded machine learning is a sub-field of machine learning where models are deployed on embedded systems with limited computing resources, such as wearable computers, edge devices and microcontrollers. Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing, thereby reducing the risk of data breaches, privacy leaks and theft of intellectual property, personal data and business secrets. Embedded machine learning can be achieved through various techniques, such as hardware acceleration, approximate computing, and model optimisation. Common optimisation techniques include pruning, quantisation, knowledge distillation, low-rank factorisation, network architecture search, and parameter sharing.\n\n\n== Software ==\nSoftware suites containing a variety of machine learning algorithms include the following:\n\n\n=== Free and open-source software ===\n\n\n=== Proprietary software with free and open-source editions ===\nKNIME\nRapidMiner\n\n\n=== Proprietary software ===\n\n\n== Journals ==\nJournal of Machine Learning Research\nMachine Learning\nNature Machine Intelligence\nNeural Computation\nIEEE Transactions on Pattern Analysis and Machine Intelligence\n\n\n== Conferences ==\nAAAI Conference on Artificial Intelligence\nAssociation for Computational Linguistics (ACL)\nEuropean Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)\nInternational Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (CIBB)\nInternational Conference on Machine Learning (ICML)\nInternational Conference on Learning Representations (ICLR)\nInternational Conference on Intelligent Robots and Systems (IROS)\nConference on Knowledge Discovery and Data Mining (KDD)\nConference on Neural Information Processing Systems (NeurIPS)\n\n\n== See also ==\nAutomated machine learning \u2013 Process of automating the application of machine learning\nBig data \u2013 Extremely large or complex datasets\nDeep learning \u2014 branch of ML concerned with artificial neural networks\nDifferentiable programming \u2013 Programming paradigm\nList of datasets for machine-learning research\nM-theory (learning framework)\nMachine unlearning\nSolomonoff's theory of inductive inference \u2013 A mathematical theory\n\n\n== References ==", "mimetype": "text/plain", "start_char_idx": 54120, "end_char_idx": 58691, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8eb652ea-9d53-41fb-8599-340cfcba5ef8": {"__data__": {"id_": "8eb652ea-9d53-41fb-8599-340cfcba5ef8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "233488", "node_type": "4", "metadata": {}, "hash": "e4c959f8a0889bcb946c461af7bca8e948c83a9e826dd07a1af7715778c0ff7d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c5d4dced-0b7e-438d-999a-1429b1c269a1", "node_type": "1", "metadata": {}, "hash": "62f5185104176193d8eab772729ce26f9bca8cd58d6dd4c5a3a226c1c65124a3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Conferences ==\nAAAI Conference on Artificial Intelligence\nAssociation for Computational Linguistics (ACL)\nEuropean Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)\nInternational Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (CIBB)\nInternational Conference on Machine Learning (ICML)\nInternational Conference on Learning Representations (ICLR)\nInternational Conference on Intelligent Robots and Systems (IROS)\nConference on Knowledge Discovery and Data Mining (KDD)\nConference on Neural Information Processing Systems (NeurIPS)\n\n\n== See also ==\nAutomated machine learning \u2013 Process of automating the application of machine learning\nBig data \u2013 Extremely large or complex datasets\nDeep learning \u2014 branch of ML concerned with artificial neural networks\nDifferentiable programming \u2013 Programming paradigm\nList of datasets for machine-learning research\nM-theory (learning framework)\nMachine unlearning\nSolomonoff's theory of inductive inference \u2013 A mathematical theory\n\n\n== References ==\n\n\n== Sources ==\nDomingos, Pedro (22 September 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0465065707.\nNilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN 978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\nPoole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN 978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\nRussell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2.\n\n\n== Further reading ==\n\n\n== External links ==\nInternational Machine Learning Society\nmloss is an academic database of open-source machine learning software.", "mimetype": "text/plain", "start_char_idx": 57610, "end_char_idx": 59599, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd4ed30e-05dc-48f1-9e00-48d947a2f6ca": {"__data__": {"id_": "dd4ed30e-05dc-48f1-9e00-48d947a2f6ca", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f754c521-3b6b-4476-9b94-a4a877da0a59", "node_type": "1", "metadata": {}, "hash": "4bf9dfccd7057f5a02f776719451af5627382c4cb7f7b1e54f6c5e8bd3c992fe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Deep learning is a subset of machine learning that focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised.\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n\n\n== Overview ==\nMost modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.\nFundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face.\nImportantly, a deep learning process can learn which features to optimally place at which level on its own. Prior to deep learning, machine learning techniques often involved hand-crafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate on. In the deep learning approach, features are not hand-crafted and the model discovers useful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than two. CAP of depth two has been shown to be a universal approximator in the sense that it can emulate any function. Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > two) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\nDeep learning architectures can be constructed with a greedy layer-by-layer method. Deep learning helps to disentangle these abstractions and pick out which features improve performance.\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data is more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.\nThe term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986, and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons. Although the history of its appearance is apparently more complicated.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4879, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f754c521-3b6b-4476-9b94-a4a877da0a59": {"__data__": {"id_": "f754c521-3b6b-4476-9b94-a4a877da0a59", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dd4ed30e-05dc-48f1-9e00-48d947a2f6ca", "node_type": "1", "metadata": {}, "hash": "4cde19ba01cc0a9e20abbeccb4cd41b87ec64e73a2eefaf41412e7ab3100420c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "91e6728e-a2f2-4654-9be7-7c0284cb6539", "node_type": "1", "metadata": {}, "hash": "537c5796da87ae540ba2e03b32e396286003b297e24d963aeae2a7f7d41299a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Interpretations ==\nDeep neural networks are generally interpreted in terms of the universal approximation theorem or probabilistic inference.\nThe classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions. In 1989, the first proof was published by George Cybenko for sigmoid activation functions and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik. Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima's rectified linear unit.\nThe universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al. proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\nThe probabilistic interpretation derives from the field of machine learning. It features inference, as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function. The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.\n\n\n== History ==", "mimetype": "text/plain", "start_char_idx": 4882, "end_char_idx": 6609, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91e6728e-a2f2-4654-9be7-7c0284cb6539": {"__data__": {"id_": "91e6728e-a2f2-4654-9be7-7c0284cb6539", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f754c521-3b6b-4476-9b94-a4a877da0a59", "node_type": "1", "metadata": {}, "hash": "4bf9dfccd7057f5a02f776719451af5627382c4cb7f7b1e54f6c5e8bd3c992fe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ad5b872-5b44-49b3-98f4-58af80444881", "node_type": "1", "metadata": {}, "hash": "1a876a6433a4ceb4f227ed73d3d0df2be988f475dbf7efa05d522c50b592319f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== History ==\n\n\n=== Before 1980 ===\nThere are two types of artificial neural network (ANN): feedforward neural network (FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have cycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst Ising created the Ising model which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this architecture adaptive. His learning RNN was republished by John Hopfield in 1982. Other early recurrent neural networks were published by Kaoru Nakano in 1971. Already in 1948, Alan Turing produced work on \"Intelligent Machinery\"  that was not published in his lifetime, containing \"ideas related to artificial evolution and learning RNNs\".\nFrank Rosenblatt (1958) proposed the perceptron, an MLP with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. He later published a 1962 book that also introduced variants and computer experiments, including a version with four-layer perceptrons \"with adaptive preterminal networks\" where the last two layers have learned weights (here he credits H. D. Block and B. W. Knight).:\u200asection 16\u200a The book cites an earlier network by R. D. Joseph (1960) \"functionally equivalent to a variation of\" this four-layer system (the book mentions Joseph over 30 times). Should Joseph therefore be considered the originator of proper adaptive multilayer perceptrons with learning hidden units? Unfortunately, the learning algorithm was not a functional one, and fell into oblivion.\nThe first working deep learning algorithm was the Group method of data handling, a method to train arbitrarily deep neural networks, published by Alexey Ivakhnenko and Lapa in 1965. They regarded it as a form of polynomial regression, or a generalization of Rosenblatt's perceptron. A 1971 paper described a deep network with eight layers trained by this method, which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates\".\nThe first deep learning multilayer perceptron trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari. In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned  internal representations to classify non-linearily separable pattern classes. Subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\nIn 1969, Kunihiko Fukushima introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for deep learning.\nDeep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1979, though not trained by backpropagation. \nBackpropagation is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673 to networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt, but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation in 1960 in the context of control theory. The modern form of backpropagation was first published in Seppo Linnainmaa's master thesis (1970). G.M. Ostrovski et al. republished it in 1971. Paul Werbos applied backpropagation to neural networks in 1982 (his 1974 PhD thesis, reprinted in a 1994 book, did not yet describe the algorithm). In 1986, David E. Rumelhart et al. popularised backpropagation but did not cite the original work.\n\n\n=== 1980s-2000s ===\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.  In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition. \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days. In 1990, Wei Zhang implemented a CNN on optical computing hardware. In 1991, a CNN was applied to medical image object segmentation and breast cancer detection in mammograms.", "mimetype": "text/plain", "start_char_idx": 6596, "end_char_idx": 11111, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4ad5b872-5b44-49b3-98f4-58af80444881": {"__data__": {"id_": "4ad5b872-5b44-49b3-98f4-58af80444881", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "91e6728e-a2f2-4654-9be7-7c0284cb6539", "node_type": "1", "metadata": {}, "hash": "537c5796da87ae540ba2e03b32e396286003b297e24d963aeae2a7f7d41299a9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "478819ee-e4fc-42f4-9432-fbbbe150709d", "node_type": "1", "metadata": {}, "hash": "ccfe96d9636bb7759877586291f84de38e3b57ec75e3cc93acb7fcec4b2e7956", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== 1980s-2000s ===\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.  In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition. \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days. In 1990, Wei Zhang implemented a CNN on optical computing hardware. In 1991, a CNN was applied to medical image object segmentation and breast cancer detection in mammograms. LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.\nRecurrent neural networks (RNN) were further developed in the 1980s. Recurrence is used for sequence processing, and when a recurrent network is unrolled, it mathematically resembles a deep feedforward layer. Consequently, they have similar properties and issues, and their developments had mutual influences. In RNN, two early influential works were the Jordan network (1986) and the Elman network (1990), which applied RNN to study problems in cognitive psychology.\nIn the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, in 1991, J\u00fcrgen Schmidhuber proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning where each RNN tries to predict its own next input, which is the next unexpected input of the RNN below. This \"neural history compressor\" uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by  distilling a higher level chunker network into a lower level automatizer network. In 1993, a neural history compressor solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time. The \"P\" in ChatGPT refers to such pre-training.\nSepp Hochreiter's diploma thesis (1991) implemented the neural history compressor, and identified and analyzed the vanishing gradient problem.  Hochreiter proposed recurrent residual connections to solve the vanishing gradient problem. This led to the long short-term memory (LSTM), published in 1995. LSTM can learn \"very deep learning\" tasks with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. That LSTM was not yet the modern architecture, which required a \"forget gate\", introduced in 1999, which became the standard RNN architecture.\nIn 1991, J\u00fcrgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in generative adversarial networks (GANs).\nDuring 1985\u20131995, inspired by statistical mechanics, several architectures and methods were developed by Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including the Boltzmann machine, restricted Boltzmann machine, Helmholtz machine, and the wake-sleep algorithm. These were designed for unsupervised learning of deep generative models. However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p. 112 ). A 1988 network became state of the art in protein structure prediction, an early application of deep learning to bioinformatics.\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.\nMost speech recognition researchers moved away from neural nets to pursue generative modeling.", "mimetype": "text/plain", "start_char_idx": 10535, "end_char_idx": 15092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "478819ee-e4fc-42f4-9432-fbbbe150709d": {"__data__": {"id_": "478819ee-e4fc-42f4-9432-fbbbe150709d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ad5b872-5b44-49b3-98f4-58af80444881", "node_type": "1", "metadata": {}, "hash": "1a876a6433a4ceb4f227ed73d3d0df2be988f475dbf7efa05d522c50b592319f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7055dc2-6cbc-4fd1-962a-4faa6c5459ea", "node_type": "1", "metadata": {}, "hash": "294e5445d58454abb293add53c64d260d9f8a1deeac58188ed5a28225bcd85b8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p. 112 ). A 1988 network became state of the art in protein structure prediction, an early application of deep learning to bioinformatics.\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years. These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively. Key difficulties have been analyzed, including gradient diminishing and weak temporal correlation structure in neural predictive models. Additional difficulties were the lack of training data and limited computing power.\nMost speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government's NSA and DARPA, SRI researched in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 NIST Speaker Recognition benchmark. It was deployed in the Nuance Verifier, representing the first major industrial application of deep learning.\nThe principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s, showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.\n\n\n=== 2000s ===\nNeural networks entered a lull, and simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) became the preferred choices in the 1990s and 2000s, because of artificial neural networks' computational cost and a lack of understanding of how the brain wires its biological networks.\nIn 2003, LSTM became competitive with traditional speech recognizers on certain tasks. In 2006, Alex Graves, Santiago Fern\u00e1ndez, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC) in stacks of LSTMs. In 2009, it became the first RNN to win a pattern recognition contest, in connected handwriting recognition.\nIn 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh deep belief networks were developed for generative modeling. They are trained by training one restricted Boltzmann machine, then freezing it and training another one on top of the first one, and so on, then optionally fine-tuned using supervised backpropagation. They could model high-dimensional probability distributions, such as the distribution of MNIST images, but convergence was slow.\nThe impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around 2010.\nThe 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems. The nature of the recognition errors produced by the two types of systems was characteristically different, offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems. Analysis around 2009\u20132010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.  That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\nIn 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.", "mimetype": "text/plain", "start_char_idx": 14102, "end_char_idx": 18981, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b7055dc2-6cbc-4fd1-962a-4faa6c5459ea": {"__data__": {"id_": "b7055dc2-6cbc-4fd1-962a-4faa6c5459ea", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "478819ee-e4fc-42f4-9432-fbbbe150709d", "node_type": "1", "metadata": {}, "hash": "ccfe96d9636bb7759877586291f84de38e3b57ec75e3cc93acb7fcec4b2e7956", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "550a2340-a66c-4052-b96d-c416a3724a03", "node_type": "1", "metadata": {}, "hash": "09dcfab3f907be974a5ba060117d52df97863955c6c3ffc67f168027ea1caddf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Deep learning revolution ===\n\nThe deep learning revolution started around CNN- and GPU-based computer vision.\nAlthough CNNs trained by backpropagation had been around for decades and GPU implementations of NNs for years, including CNNs, faster implementations of CNNs on GPUs were needed to progress on computer vision. Later, as deep learning becomes widespread, specialized hardware and algorithm optimizations were developed specifically for deep learning.\nA key advance for the deep learning revolution was hardware advances, especially GPU. Some early work dated back to 2004. In 2009, Raina, Madhavan, and Andrew Ng reported a 100M deep belief network trained on 30 Nvidia GeForce GTX 280 GPUs, an early demonstration of GPU-based deep learning. They reported up to 70 times faster training.\nIn 2011, a CNN named DanNet by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and J\u00fcrgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3. It then won more contests. They also showed how max-pooling CNNs on GPU improved performance significantly.\nIn 2012, Andrew Ng and Jeff Dean created an FNN that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from YouTube videos.\nIn October 2012, AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and Andrew Zisserman and Google's Inceptionv3.\nThe success in image classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.\nIn 2014, the state of the art was training \u201cvery deep neural network\u201d with 20 to 30 layers. Stacking too many layers led to a steep reduction in training accuracy, known as the \"degradation\" problem. In 2015, two techniques were developed to train very deep networks: the Highway Network was published in May 2015, and the residual neural network (ResNet) in Dec 2015. ResNet behaves like an open-gated Highway Net.\nAround the same time, deep learning started impacting the field of art. Early examples included Google DeepDream (2015), and neural style transfer (2015), both of which were based on pretrained image classification neural networks, such as VGG-19.\nGenerative adversarial network (GAN) by (Ian Goodfellow et al., 2014) (based on  J\u00fcrgen Schmidhuber's principle of artificial curiosity)\nbecame state of the art in generative modeling during 2014-2018 period. Excellent image quality is achieved by Nvidia's StyleGAN (2018) based on the Progressive GAN by Tero Karras et al. Here the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning deepfakes.  Diffusion models (2015) eclipsed GANs in generative modeling since then, with systems such as DALL\u00b7E 2 (2022) and Stable Diffusion (2022).\nIn 2015, Google's speech recognition improved by 49% by an LSTM-based model, which they made available through Google Voice Search on smartphone.\nDeep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks were superseded for ASR by LSTM. but are more successful in computer vision.\nYoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the 2018 Turing Award for \"conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing\".", "mimetype": "text/plain", "start_char_idx": 18984, "end_char_idx": 22900, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "550a2340-a66c-4052-b96d-c416a3724a03": {"__data__": {"id_": "550a2340-a66c-4052-b96d-c416a3724a03", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7055dc2-6cbc-4fd1-962a-4faa6c5459ea", "node_type": "1", "metadata": {}, "hash": "294e5445d58454abb293add53c64d260d9f8a1deeac58188ed5a28225bcd85b8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bfd2f854-7427-4153-81f9-a4ae9e862617", "node_type": "1", "metadata": {}, "hash": "7630e998aa14d81f893183b1559984cece1a66bf939352ed23985b2bd24bb01f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Neural networks ==\n\nArtificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.\nAn ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\nNeural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\").\n\n\n=== Deep neural networks ===\nA deep neural network (DNN) is an artificial neural network with multiple layers between the input and output layers. There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions. These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.\nFor example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer,  and complex DNN have many layers, hence the name \"deep\" networks. \nDNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives. The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network. For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.\nDeep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights. That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\nRecurrent neural networks, in which data can flow in any direction, are used for applications such as language modeling. Long short-term memory is particularly effective for this use.\nConvolutional neural networks (CNNs) are used in computer vision. CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).", "mimetype": "text/plain", "start_char_idx": 22903, "end_char_idx": 27825, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bfd2f854-7427-4153-81f9-a4ae9e862617": {"__data__": {"id_": "bfd2f854-7427-4153-81f9-a4ae9e862617", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "550a2340-a66c-4052-b96d-c416a3724a03", "node_type": "1", "metadata": {}, "hash": "09dcfab3f907be974a5ba060117d52df97863955c6c3ffc67f168027ea1caddf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58a6957f-df83-4fd3-abc8-5f7014d58b2a", "node_type": "1", "metadata": {}, "hash": "bbcd61324f8329f2301b6b48fa9da21d0856791ddcf50b5b017e00c844c5a7ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Challenges ====\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time.\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko's unit pruning or weight decay (\n  \n    \n      \n        \n          \u2113\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\ell _{2}}\n  \n-regularization) or sparsity (\n  \n    \n      \n        \n          \u2113\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\ell _{1}}\n  \n-regularization) can be applied during training to combat overfitting. Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies. Another interesting recent development is research into models of just enough complexity through an estimation of the intrinsic complexity of the task being modelled. This approach has been successfully applied for multivariate time series prediction tasks such as traffic prediction. Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.\nDNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples) speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.\nAlternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn't require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.\n\n\n== Hardware ==\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method for training large-scale commercial cloud AI . OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017) and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.\nSpecial electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform. Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).\nAtomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\nIn 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).\nIn 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing. The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds. Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.\n\n\n== Applications ==", "mimetype": "text/plain", "start_char_idx": 27828, "end_char_idx": 32395, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58a6957f-df83-4fd3-abc8-5f7014d58b2a": {"__data__": {"id_": "58a6957f-df83-4fd3-abc8-5f7014d58b2a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bfd2f854-7427-4153-81f9-a4ae9e862617", "node_type": "1", "metadata": {}, "hash": "7630e998aa14d81f893183b1559984cece1a66bf939352ed23985b2bd24bb01f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fde0c038-d905-45bf-9445-6c7407b628ce", "node_type": "1", "metadata": {}, "hash": "70b739311b55a76ac5f691bec58deeb1d0bae2a055cf32cba449473d9df71c81", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Applications ==\n\n\n=== Automatic speech recognition ===\n\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\n\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003\u20132007, accelerated progress in eight major areas:\n\nScale-up/out and accelerated DNN training and decoding\nSequence discriminative training\nFeature processing by deep models with solid understanding of the underlying mechanisms\nAdaptation of DNNs and related deep models\nMulti-task and transfer learning by DNNs and related deep models\nCNNs and how to design them to best exploit domain knowledge of speech\nRNN and its rich LSTM variants\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models.\nAll major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.\n\n\n=== Image recognition ===\n\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.\nDeep learning-trained vehicles now interpret 360\u00b0 camera views. Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\n\n\n=== Visual art processing ===\n\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\n\nidentifying the style period of a given painting\nNeural Style Transfer \u2013  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video\ngenerating striking imagery based on random visual input fields.\n\n\n=== Natural language processing ===\n\nNeural networks have been used for implementing language models since the early 2000s. LSTM helped to improve machine translation and language modeling.\nOther key techniques in this field are negative sampling and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.\nRecent developments generalize word embedding to sentence embedding.\nGoogle Translate (GT) uses a large end-to-end long short-term memory (LSTM) network. Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\". It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages. The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\". GT uses English as an intermediate between most language pairs.", "mimetype": "text/plain", "start_char_idx": 32377, "end_char_idx": 37541, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fde0c038-d905-45bf-9445-6c7407b628ce": {"__data__": {"id_": "fde0c038-d905-45bf-9445-6c7407b628ce", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58a6957f-df83-4fd3-abc8-5f7014d58b2a", "node_type": "1", "metadata": {}, "hash": "bbcd61324f8329f2301b6b48fa9da21d0856791ddcf50b5b017e00c844c5a7ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d2b217d1-9186-4f6b-9842-d85be4f76a6e", "node_type": "1", "metadata": {}, "hash": "203d799683eb9588c44580e498fcc0da5ec133394c65f1fdf1570d9e78483c8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Drug discovery and toxicology ===\n\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects. Research has explored use of deep learning to predict the biomolecular targets, off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.\nAtomNet is a deep learning system for structure-based rational drug design. AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus and multiple sclerosis.\nIn 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set. In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.\n\n\n=== Customer relationship management ===\n\nDeep reinforcement learning has been used to approximate the value of possible direct marketing actions, defined in terms of RFM variables. The estimated value function was shown to have a natural interpretation as customer lifetime value.\n\n\n=== Recommendation systems ===\n\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations. Multi-view deep learning has been applied for learning user preferences from multiple domains. The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\n\n\n=== Bioinformatics ===\n\nAn autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.\nIn medical informatics, deep learning was used to predict sleep quality based on data from wearables and predictions of health complications from electronic health record data.\nDeep neural networks have shown unparalleled performance in predicting protein structure, according to the sequence of the amino acids that make it up. In 2020, AlphaFold, a deep-learning based system, achieved a level of accuracy significantly higher than all previous computational methods.\n\n\n=== Deep Neural Network Estimations ===\nDeep neural networks can be used to estimate the entropy of a stochastic process and called Neural Joint Entropy Estimator (NJEE). Such an estimation provides insights on the effects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in case of large alphabet sizes.\n\n\n=== Medical image analysis ===\nDeep learning has been shown to produce competitive results in medical application such as cancer cell classification, lesion detection, organ segmentation and image enhancement. Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.\n\n\n=== Mobile advertising ===\nFinding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server. Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\n\n\n=== Image restoration ===\nDeep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization. These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\" which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration.\n\n\n=== Financial fraud detection ===\nDeep learning is being successfully applied to financial fraud detection, tax evasion detection, and anti-money laundering.\n\n\n=== Materials science ===\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.", "mimetype": "text/plain", "start_char_idx": 37544, "end_char_idx": 43427, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d2b217d1-9186-4f6b-9842-d85be4f76a6e": {"__data__": {"id_": "d2b217d1-9186-4f6b-9842-d85be4f76a6e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fde0c038-d905-45bf-9445-6c7407b628ce", "node_type": "1", "metadata": {}, "hash": "70b739311b55a76ac5f691bec58deeb1d0bae2a055cf32cba449473d9df71c81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "25622a5b-8aa9-4568-8022-2b8af6de1eb5", "node_type": "1", "metadata": {}, "hash": "a86d7c31655b78cd073763d5410367f0fe709ed56783e29415eb14c577f1bff7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Materials science ===\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.\n\n\n=== Military ===\nThe United States Department of Defense applied deep learning to train robots in new tasks through observation.\n\n\n=== Partial differential equations ===\nPhysics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner. One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods rely on.\n\n\n=== Deep backward stochastic differential equation method ===\nDeep backward stochastic differential equation method is a numerical method that combines deep learning with Backward stochastic differential equation (BSDE). This method is particularly useful for solving high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of deep neural networks, deep BSDE addresses the computational challenges faced by traditional numerical methods in high-dimensional settings. Specifically, traditional methods like finite difference methods or Monte Carlo simulations often struggle with the curse of dimensionality, where computational cost increases exponentially with the number of dimensions. Deep BSDE methods, however, employ deep neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden.\nIn addition, the integration of Physics-informed neural networks (PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws directly into the neural network architecture. This ensures that the solutions not only fit the data but also adhere to the governing stochastic differential equations. PINNs leverage the power of deep learning while respecting the constraints imposed by the physical models, resulting in more accurate and reliable solutions for financial mathematics problems.\n\n\n=== Image reconstruction ===\nImage reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging  and ultrasound imaging.\n\n\n=== Weather prediction ===\nTraditional weather prediction systems solve a very complex system of partial differential equations. GraphCast is a deep learning based model, trained on a long history of weather data to predict how weather patterns change over time. It is able to  predict weather conditions for up to 10 days globally, at a very detailed level, and in under a minute, with precision similar to state of the art systems.\n\n\n=== Epigenetic clock ===\n\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.", "mimetype": "text/plain", "start_char_idx": 42182, "end_char_idx": 46724, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "25622a5b-8aa9-4568-8022-2b8af6de1eb5": {"__data__": {"id_": "25622a5b-8aa9-4568-8022-2b8af6de1eb5", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d2b217d1-9186-4f6b-9842-d85be4f76a6e", "node_type": "1", "metadata": {}, "hash": "203d799683eb9588c44580e498fcc0da5ec133394c65f1fdf1570d9e78483c8a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "79a75544-d43e-4c53-8545-216d56255688", "node_type": "1", "metadata": {}, "hash": "07197a4c6e7e85e9f2db07f93efd7a4cb7a3823a841964eb13151a0365a52a7e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Epigenetic clock ===\n\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples. The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.\n\n\n== Relation to human cognitive and brain development ==\nDeep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".\nA variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism. Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality. In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.\nAlthough a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.\n\n\n== Commercial activity ==\nFacebook's AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.\nGoogle's DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player. Google Translate uses a neural network to translate between more than 100 languages.\nIn 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.\nAs of 2008, researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor. First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot with the ability to learn new tasks through observation. Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".\n\n\n== Criticism and comment ==\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.", "mimetype": "text/plain", "start_char_idx": 46198, "end_char_idx": 50647, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "79a75544-d43e-4c53-8545-216d56255688": {"__data__": {"id_": "79a75544-d43e-4c53-8545-216d56255688", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "25622a5b-8aa9-4568-8022-2b8af6de1eb5", "node_type": "1", "metadata": {}, "hash": "a86d7c31655b78cd073763d5410367f0fe709ed56783e29415eb14c577f1bff7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5be4cf5b-cf07-4416-84e2-499b3f65c7e7", "node_type": "1", "metadata": {}, "hash": "9c76554fdab68bbdc01d1af2e1090a3ed4195376e50f8a6390c87adff51c7f74", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Criticism and comment ==\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\n\n\n=== Theory ===\n\nA main criticism concerns the lack of theory surrounding some methods. Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear. (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.\nIn further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian's website.\n\n\n=== Errors ===\nSome deep learning architectures display problematic behaviors, such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014) and misclassifying minuscule perturbations of correctly classified images (2013). Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures. These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar decompositions of observed entities and events. Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition and artificial intelligence (AI).\n\n\n=== Cyber threat ===\nAs deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception. By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".\nIn 2016 researchers used one ANN to doctor images in trial and error fashion, identify another's focal points, and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system. One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.\nAnother group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.\nANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.\nIn 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".\nIn \"data poisoning\", false data is continually smuggled into a machine learning system's training set to prevent it from achieving mastery.\n\n\n=== Data collection ethics ===\nThe deep learning systems that are trained using supervised learning often rely on data that is created and/or annotated by humans. It has been argued that not only low-paid clickwork (such as on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such. The philosopher Rainer M\u00fchlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.", "mimetype": "text/plain", "start_char_idx": 50506, "end_char_idx": 55888, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5be4cf5b-cf07-4416-84e2-499b3f65c7e7": {"__data__": {"id_": "5be4cf5b-cf07-4416-84e2-499b3f65c7e7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32472154", "node_type": "4", "metadata": {}, "hash": "7b578095d28bfeb43f35271777f7de94616f137a53f556bbb1942f37edbf84ea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "79a75544-d43e-4c53-8545-216d56255688", "node_type": "1", "metadata": {}, "hash": "07197a4c6e7e85e9f2db07f93efd7a4cb7a3823a841964eb13151a0365a52a7e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Data collection ethics ===\nThe deep learning systems that are trained using supervised learning often rely on data that is created and/or annotated by humans. It has been argued that not only low-paid clickwork (such as on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such. The philosopher Rainer M\u00fchlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.\n\n\n== See also ==\nApplications of artificial intelligence\nComparison of deep learning software\nCompressed sensing\nDifferentiable programming\nEcho state network\nList of artificial intelligence projects\nLiquid state machine\nList of datasets for machine-learning research\nReservoir computing\nScale space and deep learning\nSparse coding\nStochastic parrot\nTopological deep learning\n\n\n== References ==\n\n\n== Further reading ==", "mimetype": "text/plain", "start_char_idx": 54966, "end_char_idx": 56307, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e19a71b-dc20-4e68-8330-08c490e51d33": {"__data__": {"id_": "1e19a71b-dc20-4e68-8330-08c490e51d33", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "76121942", "node_type": "4", "metadata": {}, "hash": "ce873510685e4d249b8ca1088239e2b5fbdff946b274452561cf3fcb00adcbdd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A neural network is a group of interconnected units called neurons that send signals to one another. Neurons can be either biological cells or mathematical models. While individual neurons are simple, many of them together in a network can perform complex tasks. There are two main types of neural networks.\n\nIn neuroscience, a biological neural network is a physical structure found in brains and complex nervous systems \u2013 a population of nerve cells connected by synapses.\nIn machine learning, an artificial neural network is a mathematical model used to approximate nonlinear functions. Artificial neural networks are used to solve artificial intelligence problems.\n\n\n== In biology ==\n\nIn the context of biology, a neural network is a population of biological neurons chemically connected to each other by synapses. A given neuron can be connected to hundreds of thousands of synapses.\nEach neuron sends and receives electrochemical signals called action potentials to its connected neighbors. A neuron can serve an excitatory role, amplifying and propagating signals it receives, or an inhibitory role, suppressing signals instead.\nPopulations of interconnected neurons that are smaller than neural networks are called neural circuits. Very large interconnected networks are called large scale brain networks, and many of these together form brains and nervous systems.\nSignals generated by neural networks in the brain eventually travel through the nervous system and across neuromuscular junctions to muscle cells, where they cause contraction and thereby motion.\n\n\n== In machine learning ==\n\nIn machine learning, a neural network is an artificial mathematical model used to approximate nonlinear functions. While early artificial neural networks were physical machines, today they are almost always implemented in software.\nNeurons in an artificial neural network are usually arranged into layers, with information passing from the first layer (the input layer) through one or more intermediate layers (the hidden layers) to the final layer (the output layer).\nThe \"signal\" input to each neuron is a number, specifically a linear combination of the outputs of the connected neurons in the previous layer. The signal each neuron outputs is calculated from this number, according to its activation function. The behavior of the network depends on the strengths (or weights) of the connections between neurons. A network is trained by modifying these weights through empirical risk minimization or backpropagation in order to fit some preexisting dataset.\nThe term deep neural network refers to neural networks that have more than three layers, typically including at least two hidden layers in addition to the input and output layers.\nNeural networks are used to solve problems in artificial intelligence, and have thereby found applications in many disciplines, including predictive modeling, adaptive control, facial recognition, handwriting recognition, general game playing, and generative AI.\n\n\n== History ==\n\nThe theoretical base for contemporary neural networks was independently proposed by Alexander Bain in 1873 and William James in 1890. Both posited that human thought emerged from interactions among large numbers of neurons inside the brain. In 1949, Donald Hebb described Hebbian learning, the idea that neural networks can change and learn over time by strengthening a synapse every time a signal travels along it.\nArtificial neural networks were originally used to model biological neural networks starting in the 1930s under the approach of connectionism. However, starting with the invention of the perceptron, a simple artificial neural network, by Warren McCulloch and Walter Pitts in 1943, followed by the implementation of one in hardware by Frank Rosenblatt in 1957,\nartificial neural networks became increasingly used for machine learning applications instead, and increasingly different from their biological counterparts.\n\n\n== See also ==\nEmergence\nBiological cybernetics\nBiologically-inspired computing\n\n\n== References ==", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4054, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "811bf8fe-a762-4f76-b782-979f7f567277": {"__data__": {"id_": "811bf8fe-a762-4f76-b782-979f7f567277", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "160e3bca-e219-42c8-b0b6-733cb8a71b58", "node_type": "1", "metadata": {}, "hash": "ec25a31db27e14def7d2876f2be3b484fc90731068663d84ebc1819cc9e8425f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio. Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision and image processing, and have only recently been replaced\u2014in some cases\u2014by newer deep learning architectures such as the transformer.\nVanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections. For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 \u00d7 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 weights for each convolutional layer are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features.\nSome applications of CNNs include: \n\nimage and video recognition,\nrecommender systems,\nimage classification,\nimage segmentation,\nmedical image analysis,\nnatural language processing,\nbrain\u2013computer interfaces, and\nfinancial time series.\nCNNs are also known as shift invariant or space invariant artificial neural networks, based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input.\nFeedforward neural networks are usually fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"full connectivity\" of these networks makes them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set.\nConvolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\nCNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are hand-engineered. This simplifies and automates the process, enhancing efficiency and scalability overcoming human-intervention bottlenecks.\n\n\n== Architecture ==\n\nA convolutional neural network consists of an input layer, hidden layers and an output layer. In a convolutional neural network, the hidden layers include one or more layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layer's input matrix. This product is usually the Frobenius inner product, and its activation function is commonly ReLU. As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers, fully connected layers, and normalization layers.\nHere it should be noted how close a convolutional neural network is to a matched filter.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3963, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "160e3bca-e219-42c8-b0b6-733cb8a71b58": {"__data__": {"id_": "160e3bca-e219-42c8-b0b6-733cb8a71b58", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "811bf8fe-a762-4f76-b782-979f7f567277", "node_type": "1", "metadata": {}, "hash": "bff1ffc7829a4df7a9f0a99b2f40bab260abe2c38a7698cb8ce9c77184b12417", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0da08d6f-b6c4-4bc8-97cb-5ee9095e6ae1", "node_type": "1", "metadata": {}, "hash": "bda2ebb583c9a8b676b2ed17a0659b8ce0f799f84dc1716f9625a1c6cfa61bf1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Architecture ==\n\nA convolutional neural network consists of an input layer, hidden layers and an output layer. In a convolutional neural network, the hidden layers include one or more layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layer's input matrix. This product is usually the Frobenius inner product, and its activation function is commonly ReLU. As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers, fully connected layers, and normalization layers.\nHere it should be noted how close a convolutional neural network is to a matched filter.\n\n\n=== Convolutional layers ===\nIn a CNN, the input is a tensor with shape:\n(number of inputs) \u00d7 (input height) \u00d7 (input width) \u00d7 (input channels)\nAfter passing through a convolutional layer, the image becomes abstracted to a feature map, also called an activation map, with shape:\n(number of inputs) \u00d7 (feature map height) \u00d7 (feature map width) \u00d7 (feature map channels).\nConvolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus. Each convolutional neuron processes data only for its receptive field. \n\nAlthough fully connected feedforward neural networks can be used to learn features and classify data, this architecture is generally impractical for larger inputs (e.g., high-resolution images), which would require massive numbers of neurons because each pixel is a relevant input feature. A fully connected layer for an image of size 100 \u00d7 100 has 10,000 weights for each neuron in the second layer. Convolution reduces the number of free parameters, allowing the network to be deeper. For example, using a 5 \u00d7 5 tiling region, each with the same shared weights, requires only 25 neurons. Using shared weights means there are many fewer parameters, which helps avoid the vanishing gradients and exploding gradients problems seen during backpropagation in earlier neural networks.\nTo speed processing, standard convolutional layers can be replaced by depthwise separable convolutional layers, which are based on a depthwise convolution followed by a pointwise convolution. The depthwise convolution is a spatial convolution applied independently over each channel of the input tensor, while the pointwise convolution is a standard convolution restricted to the use of \n  \n    \n      \n        1\n        \u00d7\n        1\n      \n    \n    {\\displaystyle 1\\times 1}\n  \n kernels.\n\n\n=== Pooling layers ===\nConvolutional networks may include local and/or global pooling layers along with traditional convolutional layers. Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, tiling sizes such as 2 \u00d7 2 are commonly used. Global pooling acts on all the neurons of the feature map. There are two common types of pooling in popular use: max and average. Max pooling uses the maximum value of each local cluster of neurons in the feature map, while average pooling takes the average value.\n\n\n=== Fully connected layers ===\nFully connected layers connect every neuron in one layer to every neuron in another layer. It is the same as a traditional multilayer perceptron neural network (MLP). The flattened matrix goes through a fully connected layer to classify the images.\n\n\n=== Receptive field ===\nIn neural networks, each neuron receives input from some number of locations in the previous layer. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron's receptive field. Typically the area is a square (e.g. 5 by 5 neurons). Whereas, in a fully connected layer, the receptive field is the entire previous layer. Thus, in each convolutional layer, each neuron takes input from a larger area in the input than previous layers. This is due to applying the convolution over and over, which takes the value of a pixel into account, as well as its surrounding pixels. When using dilated layers, the number of pixels in the receptive field remains constant, but the field is more sparsely populated as its dimensions grow when combining the effect of several layers.\nTo manipulate the receptive field size as desired, there are some alternatives to the standard convolutional layer. For example, atrous or dilated convolution expands the receptive field size without increasing the number of parameters by interleaving visible and blind regions. Moreover, a single dilated convolutional layer can comprise filters with multiple dilation ratios, thus having a variable receptive field size.", "mimetype": "text/plain", "start_char_idx": 3151, "end_char_idx": 8036, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0da08d6f-b6c4-4bc8-97cb-5ee9095e6ae1": {"__data__": {"id_": "0da08d6f-b6c4-4bc8-97cb-5ee9095e6ae1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "160e3bca-e219-42c8-b0b6-733cb8a71b58", "node_type": "1", "metadata": {}, "hash": "ec25a31db27e14def7d2876f2be3b484fc90731068663d84ebc1819cc9e8425f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "82ef047d-e8bd-4c93-b915-c27a5f027d1a", "node_type": "1", "metadata": {}, "hash": "2f251fa8d7d1e0c52028303717f9715af1e44bb4769fe1d5722d9947c7d65a16", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Weights ===\nEach neuron in a neural network computes an output value by applying a specific function to the input values received from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias (typically real numbers). Learning consists of iteratively adjusting these biases and weights.\nThe vectors of weights and biases are called filters and represent particular features of the input (e.g., a particular shape). A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces the memory footprint because a single bias and a single vector of weights are used across all receptive fields that share that filter, as opposed to each receptive field having its own bias and vector weighting.\n\n\n=== Deconvolutional ===\n\nA deconvolutional neural network is essentially the reverse of a CNN. It consists of deconvolutional layers and unpooling layers. \nA deconvolutional layer is the transpose of a convolutional layer. Specifically, a convolutional layer can be written as a multiplication with a matrix, and a deconvolutional layer is multiplication with the transpose of that matrix.\nAn unpooling layer expands the layer. The max-unpooling layer is the simplest, as it simply copies each entry multiple times. For example, a 2-by-2 max-unpooling layer is \n  \n    \n      \n        [\n        x\n        ]\n        \u21a6\n        \n          \n            [\n            \n              \n                \n                  x\n                \n                \n                  x\n                \n              \n              \n                \n                  x\n                \n                \n                  x\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle [x]\\mapsto {\\begin{bmatrix}x&x\\\\x&x\\end{bmatrix}}}\n  \n.\nDeconvolution layers are used in image generators. By default, it creates periodic checkerboard artifact, which can be fixed by upscale-then-convolve.\n\n\n== History ==\nCNN are often compared to the way the brain achieves vision processing in living organisms.\n\n\n=== Receptive fields in the visual cortex ===\nWork by Hubel and Wiesel in the 1950s and 1960s showed that cat visual cortices contain neurons that individually respond to small regions of the visual field. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field. Neighboring cells have similar and overlapping receptive fields. Receptive field size and location varies systematically across the cortex to form a complete map of visual space. The cortex in each hemisphere represents the contralateral visual field.\nTheir 1968 paper identified two basic visual cell types in the brain:\n\nsimple cells, whose output is maximized by straight edges having particular orientations within their receptive field\ncomplex cells, which have larger receptive fields, whose output is insensitive to the exact position of the edges in the field.\nHubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks.\n\n\n=== Fukushima's analog threshold elements in a vision model ===\nIn 1969, Kunihiko Fukushima introduced a multilayer visual feature detection network, inspired by the above-mentioned work of Hubel and Wiesel, in which \"All the elements in one layer have the same set of interconnecting coefficients; the arrangement of the elements and their interconnections are all homogeneous over a given layer.\"  This is the essential core of a convolutional network, but the weights were not trained.  In the same paper, Fukushima also introduced the ReLU (rectified linear unit) activation function.", "mimetype": "text/plain", "start_char_idx": 8039, "end_char_idx": 11823, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82ef047d-e8bd-4c93-b915-c27a5f027d1a": {"__data__": {"id_": "82ef047d-e8bd-4c93-b915-c27a5f027d1a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0da08d6f-b6c4-4bc8-97cb-5ee9095e6ae1", "node_type": "1", "metadata": {}, "hash": "bda2ebb583c9a8b676b2ed17a0659b8ce0f799f84dc1716f9625a1c6cfa61bf1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3875a3a4-1787-456a-b028-2aae29743af1", "node_type": "1", "metadata": {}, "hash": "007afd1be5de0db82730cee4e08eac3223697ed7d8cc657a2c6d95ec54e373d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Fukushima's analog threshold elements in a vision model ===\nIn 1969, Kunihiko Fukushima introduced a multilayer visual feature detection network, inspired by the above-mentioned work of Hubel and Wiesel, in which \"All the elements in one layer have the same set of interconnecting coefficients; the arrangement of the elements and their interconnections are all homogeneous over a given layer.\"  This is the essential core of a convolutional network, but the weights were not trained.  In the same paper, Fukushima also introduced the ReLU (rectified linear unit) activation function. \n\n\n=== Neocognitron, origin of the trainable CNN architecture ===\nThe \"neocognitron\" was introduced by Fukushima in 1980.  The neocognitron introduced the two basic types of layers:\n\n\"S-layer\": a shared-weights receptive-field layer, later known as a convolutional layer, which contains units whose receptive fields cover a patch of the previous layer. A shared-weights receptive-field group (a \"plane\" in neocognitron terminology) is often called a filter, and a layer typically has several such filters.\n\"C-layer\": a downsampling layer that contain units whose receptive fields cover patches of previous convolutional layers. Such a unit typically computes a weighted average of the activations of the units in its patch, and applies inhibition (divisive normalization) pooled from a somewhat larger patch and across different filters in a layer, and applies a saturating activation function. The patch weights are nonnegative and are not trainable in the original neocognitron. The downsampling and competitive inhibition help to classify features and objects in visual scenes even when the objects are shifted.\nSeveral supervised and unsupervised learning algorithms have been proposed over the decades to train the weights of a neocognitron. Today, however, the CNN architecture is usually trained through backpropagation.\nFukushima's ReLU activation function was not used in his neocognitron since all the weights were nonnegative; lateral inhibition was used instead. The rectifier has become a very popular activation function for CNNs and deep neural networks in general.\n\n\n=== Convolution in time ===\nThe term \"convolution\" first appears in neural networks in a paper by Toshiteru Homma, Les Atlas, and Robert Marks II at the first Conference on Neural Information Processing Systems in 1987. Their paper replaced multiplication with convolution in time, inherently providing shift invariance, motivated by and connecting more directly to the signal-processing concept of a filter, and demonstrated it on a speech recognition task. They also pointed out that as a data-trainable system, convolution is essentially equivalent to correlation since reversal of the weights does not affect the final learned function (\"For convenience, we denote * as correlation instead of convolution. Note that convolving a(t) with b(t) is equivalent to correlating a(-t) with b(t).\"). Modern CNN implementations typically do correlation and call it convolution, for convenience, as they did here.\n\n\n=== Time delay neural networks ===\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel et al. for phoneme recognition and was an early convolutional network exhibiting shift-invariance. A TDNN is a 1-D convolutional neural net where the convolution is performed along the time axis of the data. It is the first CNN utilizing weight sharing in combination with a training by gradient descent, using backpropagation. Thus, while also using a pyramidal structure as in the neocognitron, it performed a global optimization of the weights instead of a local one.\nTDNNs are convolutional networks that share weights along the temporal dimension. They allow speech signals to be processed time-invariantly. In 1990 Hampshire and Waibel introduced a variant that performs a two-dimensional convolution. Since these TDNNs operated on spectrograms, the resulting phoneme recognition system was invariant to both time and frequency shifts, as with images processed by a neocognitron.\nTDNNs improved the performance of far-distance speech recognition.", "mimetype": "text/plain", "start_char_idx": 11235, "end_char_idx": 15378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3875a3a4-1787-456a-b028-2aae29743af1": {"__data__": {"id_": "3875a3a4-1787-456a-b028-2aae29743af1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "82ef047d-e8bd-4c93-b915-c27a5f027d1a", "node_type": "1", "metadata": {}, "hash": "2f251fa8d7d1e0c52028303717f9715af1e44bb4769fe1d5722d9947c7d65a16", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2d42081-6470-4bba-9948-dee2abda04bd", "node_type": "1", "metadata": {}, "hash": "d7f3665ce0568050df9042dc14d2b20f266f9ef4d639df8277fe5fe3db1dbed7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Image recognition with CNNs trained by gradient descent ===\nDenker et al. (1989) designed a 2-D CNN system to recognize hand-written ZIP Code numbers. However, the lack of an efficient training method to determine the kernel coefficients of the involved convolutions meant that all the coefficients had to be laboriously hand-designed.\nFollowing the advances in the training of 1-D CNNs by Waibel et al. (1987), Yann LeCun et al. (1989) used back-propagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning was thus fully automatic, performed better than manual coefficient design, and was suited to a broader range of image recognition problems and image types. \nWei Zhang et al. (1988) used back-propagation to train the convolution kernels of a CNN for alphabets recognition. The model was called shift-invariant pattern recognition neural network before the name CNN was coined later in the early 1990s. Wei Zhang et al. also applied the same CNN without the last fully connected layer for medical image object segmentation (1991) and breast cancer detection in mammograms (1994).\nThis approach became a foundation of modern computer vision.\n\n\n==== Max pooling ====\nIn 1990 Yamaguchi et al. introduced the concept of max pooling, a fixed filtering operation that calculates and propagates the maximum value of a given region. They did so by combining TDNNs with max pooling to realize a speaker-independent isolated word recognition system. In their system they used several TDNNs per word, one for each syllable. The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.\nIn a variant of the neocognitron called the cresceptron, instead of using Fukushima's spatial averaging with inhibition and saturation, J. Weng et al. in 1993 used max pooling, where a downsampling unit computes the maximum of the activations of the units in its patch, introducing this method into the vision field. \nMax pooling is often used in modern CNNs.\n\n\n==== LeNet-5 ====\n\nLeNet-5, a pioneering 7-level convolutional network by LeCun et al. in 1995, classifies hand-written numbers on checks (British English: cheques) digitized in 32x32 pixel images. The ability to process higher-resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources.\nIt was superior than other commercial courtesy amount reading systems (as of 1995). The system was integrated in NCR's check reading systems, and fielded in several American banks since June 1996, reading millions of checks per day.\n\n\n=== Shift-invariant neural network ===\nA shift-invariant neural network was proposed by Wei Zhang et al. for image character recognition in 1988. It is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer. The model was trained with back-propagation. The training algorithm was further improved in 1991 to improve its generalization ability. The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation (1991) and automatic detection of breast cancer in mammograms (1994).\nA different convolution-based design was proposed in 1988 for application to decomposition of one-dimensional electromyography convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.", "mimetype": "text/plain", "start_char_idx": 15381, "end_char_idx": 18993, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a2d42081-6470-4bba-9948-dee2abda04bd": {"__data__": {"id_": "a2d42081-6470-4bba-9948-dee2abda04bd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3875a3a4-1787-456a-b028-2aae29743af1", "node_type": "1", "metadata": {}, "hash": "007afd1be5de0db82730cee4e08eac3223697ed7d8cc657a2c6d95ec54e373d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2344fc41-a542-485e-800c-fb4de34f79fd", "node_type": "1", "metadata": {}, "hash": "d669ab12718c1502c2854ed11cc11c14f95f65bf81edfce7bd40333927f7f4f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Shift-invariant neural network ===\nA shift-invariant neural network was proposed by Wei Zhang et al. for image character recognition in 1988. It is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer. The model was trained with back-propagation. The training algorithm was further improved in 1991 to improve its generalization ability. The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation (1991) and automatic detection of breast cancer in mammograms (1994).\nA different convolution-based design was proposed in 1988 for application to decomposition of one-dimensional electromyography convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.\n\n\n=== GPU implementations ===\nAlthough CNNs were invented in the 1980s, their breakthrough in the 2000s required fast implementations on graphics processing units (GPUs).\nIn 2004, it was shown by K. S. Oh and K. Jung that standard neural networks can be greatly accelerated on GPUs. Their implementation was 20 times faster than an equivalent implementation on CPU. In 2005, another paper also emphasised the value of GPGPU for machine learning.\nThe first GPU-implementation of a CNN was described in 2006 by K. Chellapilla et al. Their implementation was 4 times faster than an equivalent implementation on CPU. In the same period, GPUs were also used for unsupervised training of deep belief networks.\nIn 2010, Dan Ciresan et al. at IDSIA trained deep feedforward networks on GPUs. In 2011, they extended this to CNNs, accelerating by 60 compared to training CPU. In 2011, the network won an image recognition contest where they achieved superhuman performance for the first time. Then they won more competitions and achieved state of the art on several benchmarks.\nSubsequently, AlexNet, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012. It was an early catalytic event for the AI boom.\nCompared to the training of CNNs using GPUs, not much attention was given to CPU. (Viebke et al 2019) parallelizes CNN by thread- and SIMD-level parallelism that is available on the Intel Xeon Phi.", "mimetype": "text/plain", "start_char_idx": 18133, "end_char_idx": 20445, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2344fc41-a542-485e-800c-fb4de34f79fd": {"__data__": {"id_": "2344fc41-a542-485e-800c-fb4de34f79fd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2d42081-6470-4bba-9948-dee2abda04bd", "node_type": "1", "metadata": {}, "hash": "d7f3665ce0568050df9042dc14d2b20f266f9ef4d639df8277fe5fe3db1dbed7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1142e6e0-0f91-4318-a894-2130ab3b6cb9", "node_type": "1", "metadata": {}, "hash": "702551c10d7f7170d374907a743e0776b4cac616b46e25a4ecdbd88ed8f4d3b0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Distinguishing features ==\nIn the past, traditional multilayer perceptron (MLP) models were used for image recognition. However, the full connectivity between nodes caused the curse of dimensionality, and was computationally intractable with higher-resolution images. A 1000\u00d71000-pixel image with RGB color channels has 3 million weights per fully-connected neuron, which is too high to feasibly process efficiently at scale.\n\nFor example, in CIFAR-10, images are only of size 32\u00d732\u00d73 (32 wide, 32 high, 3 color channels), so a single fully connected neuron in the first hidden layer of a regular neural network would have 32*32*3 = 3,072 weights. A 200\u00d7200 image, however, would lead to neurons that have 200*200*3 = 120,000 weights.\nAlso, such network architecture does not take into account the spatial structure of data, treating input pixels which are far apart in the same way as pixels that are close together. This ignores locality of reference in data with a grid-topology (such as images), both computationally and semantically. Thus, full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by spatially local input patterns.\nConvolutional neural networks are variants of multilayer perceptrons, designed to emulate the behavior of a visual cortex. These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs, CNNs have the following distinguishing features:\n\n3D volumes of neurons. The layers of a CNN have neurons arranged in 3 dimensions: width, height and depth. Where each neuron inside a convolutional layer is connected to only a small region of the layer before it, called a receptive field. Distinct types of layers, both locally and completely connected, are stacked to form a CNN architecture.\nLocal connectivity: following the concept of receptive fields, CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers. The architecture thus ensures that the learned \"filters\" produce the strongest response to a spatially local input pattern. Stacking many such layers leads to nonlinear filters that become increasingly global (i.e. responsive to a larger region of pixel space) so that the network first creates representations of small parts of the input, then from them assembles representations of larger areas.\nShared weights: In CNNs, each filter is replicated across the entire visual field. These replicated units share the same parameterization (weight vector and bias) and form a feature map. This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field. Replicating units in this way allows for the resulting activation map to be equivariant under shifts of the locations of input features in the visual field, i.e. they grant translational equivariance\u2014given that the layer has a stride of one.\nPooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value. In addition to reducing the sizes of feature maps, the pooling operation grants a degree of local translational invariance to the features contained therein, allowing the CNN to be more robust to variations in their positions.\nTogether, these properties allow CNNs to achieve better generalization on vision problems. Weight sharing dramatically reduces the number of free parameters learned, thus lowering the memory requirements for running the network and allowing the training of larger, more powerful networks.\n\n\n== Building blocks ==\nA CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume (e.g. holding the class scores) through a differentiable function. A few distinct types of layers are commonly used. These are further discussed below.\n\n\n=== Convolutional layer ===\n\nThe convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the filter entries and the input, producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.\nStacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input. Each entry in an activation map use the same set of parameters that define the filter.\nSelf-supervised learning has been adapted for use in convolutional layers by using sparse patches with a high-mask ratio and a global response normalization layer.", "mimetype": "text/plain", "start_char_idx": 20448, "end_char_idx": 25601, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1142e6e0-0f91-4318-a894-2130ab3b6cb9": {"__data__": {"id_": "1142e6e0-0f91-4318-a894-2130ab3b6cb9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2344fc41-a542-485e-800c-fb4de34f79fd", "node_type": "1", "metadata": {}, "hash": "d669ab12718c1502c2854ed11cc11c14f95f65bf81edfce7bd40333927f7f4f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "84d0ad74-5b58-47db-9c0c-fd81ed88be69", "node_type": "1", "metadata": {}, "hash": "caa1afbf2cacc6b06ab77bf006b420a4edd36df99d7ef35f3a3512cb05ba4052", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Local connectivity ====\n\nWhen dealing with high-dimensional inputs such as images, it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account. Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.\nThe extent of this connectivity is a hyperparameter called the receptive field of the neuron. The connections are local in space (along width and height), but always extend along the entire depth of the input volume. Such an architecture ensures that the learned filters produce the strongest response to a spatially local input pattern.\n\n\n==== Spatial arrangement ====\nThree hyperparameters control the size of the output volume of the convolutional layer: the depth, stride, and padding size:\n\nThe depth of the output volume controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input. For example, if the first convolutional layer takes the raw image as input, then different neurons along the depth dimension may activate in the presence of various oriented edges, or blobs of color.\nStride controls how depth columns around the width and height are allocated. If the stride is 1, then we move the filters one pixel at a time. This leads to heavily overlapping receptive fields between the columns, and to large output volumes. For any integer \n  \n    \n      \n        S\n        >\n        0\n        ,\n      \n    \n    {\\textstyle S>0,}\n  \n a stride S means that the filter is translated S units at a time per output. In practice, \n  \n    \n      \n        S\n        \u2265\n        3\n      \n    \n    {\\textstyle S\\geq 3}\n  \n is rare. A greater stride means smaller overlap of receptive fields and smaller spatial dimensions of the output volume.\nSometimes, it is convenient to pad the input with zeros (or other values, such as the average of the region) on the border of the input volume. The size of this padding is a third hyperparameter. Padding provides control of the output volume's spatial size. In particular, sometimes it is desirable to exactly preserve the spatial size of the input volume, this is commonly referred to as \"same\" padding.\n\nThe spatial size of the output volume is a function of the input volume size \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  \n, the kernel field size \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n of the convolutional layer neurons, the stride \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n, and the amount of zero padding \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n on the border. The number of neurons that \"fit\" in a given volume is then:\n\n  \n    \n      \n        \n          \n            \n              W\n              \u2212\n              K\n              +\n              2\n              P\n            \n            S\n          \n        \n        +\n        1.\n      \n    \n    {\\displaystyle {\\frac {W-K+2P}{S}}+1.}\n  \n\nIf this number is not an integer, then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a symmetric way. In general, setting zero padding to be \n  \n    \n      \n        P\n        =\n        (\n        K\n        \u2212\n        1\n        )\n        \n          /\n        \n        2\n      \n    \n    {\\textstyle P=(K-1)/2}\n  \n when the stride is \n  \n    \n      \n        S\n        =\n        1\n      \n    \n    {\\displaystyle S=1}\n  \n ensures that the input volume and output volume will have the same size spatially. However, it is not always completely necessary to use all of the neurons of the previous layer. For example, a neural network designer may decide to use just a portion of padding.", "mimetype": "text/plain", "start_char_idx": 25604, "end_char_idx": 29532, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "84d0ad74-5b58-47db-9c0c-fd81ed88be69": {"__data__": {"id_": "84d0ad74-5b58-47db-9c0c-fd81ed88be69", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1142e6e0-0f91-4318-a894-2130ab3b6cb9", "node_type": "1", "metadata": {}, "hash": "702551c10d7f7170d374907a743e0776b4cac616b46e25a4ecdbd88ed8f4d3b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c25a7e50-10e3-46d3-88e8-f899fbb4d9fd", "node_type": "1", "metadata": {}, "hash": "d90c2cbdf4d09b492ee2ea267befbd3b36de85f40b3864c323fbca0c255ecfaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Parameter sharing ====\nA parameter sharing scheme is used in convolutional layers to control the number of free parameters. It relies on the assumption that if a patch feature is useful to compute at some spatial position, then it should also be useful to compute at other positions. Denoting a single 2-dimensional slice of depth as a depth slice, the neurons in each depth slice are constrained to use the same weights and bias.\nSince all neurons in a single depth slice share the same parameters, the forward pass in each depth slice of the convolutional layer can be computed as a convolution of the neuron's weights with the input volume. Therefore, it is common to refer to the sets of weights as a filter (or a kernel), which is convolved with the input. The result of this convolution is an activation map, and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume. Parameter sharing contributes to the translation invariance of the CNN architecture.\nSometimes, the parameter sharing assumption may not make sense. This is especially the case when the input images to a CNN have some specific centered structure; for which we expect completely different features to be learned on different spatial locations. One practical example is when the inputs are faces that have been centered in the image: we might expect different eye-specific or hair-specific features to be learned in different parts of the image. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a \"locally connected layer\".\n\n\n=== Pooling layer ===\n\nAnother important concept of CNNs is pooling, which is used as a form of non-linear down-sampling. Pooling provides downsampling because it reduces the spatial dimensions (height and width) of the input feature maps while retaining the most important information. There are several non-linear functions to implement pooling, where max pooling and average pooling are the most common. Pooling aggregates information from small regions of the input creating partitions of the input feature map, typically using a fixed-size window (like 2x2) and applying a stride (often 2) to move the window across the input. Note that without using a stride greater than 1, pooling would not perform downsampling, as it would simply move the pooling window across the input one step at a time, without reducing the size of the feature map. In other words, the stride is what actually causes the downsampling by determining how much the pooling window moves over the input.\nIntuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting. This is known as down-sampling. It is common to periodically insert a pooling layer between successive convolutional layers (each one typically followed by an activation function, such as a ReLU layer) in a CNN architecture.:\u200a460\u2013461\u200a While pooling layers contribute to local translation invariance, they do not provide global translation invariance in a CNN, unless a form of global pooling is used. The pooling layer commonly operates independently on every depth, or slice, of the input and resizes it spatially. A very common form of max pooling is a layer with filters of size 2\u00d72, applied with a stride of 2, which subsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations:\n  \n    \n      \n        \n          f\n          \n            X\n            ,\n            Y\n          \n        \n        (\n        S\n        )\n        =\n        \n          max\n          \n            a\n            ,\n            b\n            =\n            0\n          \n          \n            1\n          \n        \n        \n          S\n          \n            2\n            X\n            +\n            a\n            ,\n            2\n            Y\n            +\n            b\n          \n        \n        .\n      \n    \n    {\\displaystyle f_{X,Y}(S)=\\max _{a,b=0}^{1}S_{2X+a,2Y+b}.}\n  \n\nIn this case, every max operation is over 4 numbers. The depth dimension remains unchanged (this is true for other forms of pooling as well).\nIn addition to max pooling, pooling units can use other functions, such as average pooling or \u21132-norm pooling. Average pooling was often used historically but has recently fallen out of favor compared to max pooling, which generally performs better in practice.\nDue to the effects of fast spatial reduction of the size of the representation, there is a recent trend towards using smaller filters or discarding pooling layers altogether.", "mimetype": "text/plain", "start_char_idx": 29535, "end_char_idx": 34444, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c25a7e50-10e3-46d3-88e8-f899fbb4d9fd": {"__data__": {"id_": "c25a7e50-10e3-46d3-88e8-f899fbb4d9fd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "84d0ad74-5b58-47db-9c0c-fd81ed88be69", "node_type": "1", "metadata": {}, "hash": "caa1afbf2cacc6b06ab77bf006b420a4edd36df99d7ef35f3a3512cb05ba4052", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f2c1ae07-686f-4f6a-9190-3efa7ef621f3", "node_type": "1", "metadata": {}, "hash": "252de977c7e4754b3005c9a4608b805345e90dc118908f8e879ee2798f2693e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Channel max pooling ====\nA channel max pooling (CMP) operation layer conducts the MP operation along the channel side among the corresponding positions of the consecutive feature maps for the purpose of redundant information elimination. The CMP makes the significant features gather together within fewer channels, which is important for fine-grained image classification that needs more discriminating features. Meanwhile, another advantage of the CMP operation is to make the channel number of feature maps smaller before it connects to the first fully connected (FC) layer. Similar to the MP operation, we denote the input feature maps and output feature maps of a CMP layer as F \u2208 R(C\u00d7M\u00d7N) and C \u2208 R(c\u00d7M\u00d7N), respectively, where C and c are the channel numbers of the input and output feature maps, M and N are the widths and the height of the feature maps, respectively. Note that the CMP operation only changes the channel number of the feature maps. The width and the height of the feature maps are not changed, which is different from the MP operation.\nSee  for reviews for pooling methods.\n\n\n=== ReLU layer ===\nReLU is the abbreviation of rectified linear unit. It was proposed by Alston Householder in 1941, and used in CNN by Kunihiko Fukushima in 1969. ReLU applies the non-saturating activation function \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        max\n        (\n        0\n        ,\n        x\n        )\n      \n    \n    {\\textstyle f(x)=\\max(0,x)}\n  \n. It effectively removes negative values from an activation map by setting them to zero. It introduces nonlinearity to the decision function and in the overall network without affecting the receptive fields of the convolution layers.\nIn 2011, Xavier Glorot, Antoine Bordes and Yoshua Bengio found that ReLU enables better training of deeper networks, compared to widely used activation functions prior to 2011.\nOther functions can also be used to increase nonlinearity, for example the saturating hyperbolic tangent \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        tanh\n        \u2061\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)=\\tanh(x)}\n  \n, \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          |\n        \n        tanh\n        \u2061\n        (\n        x\n        )\n        \n          |\n        \n      \n    \n    {\\displaystyle f(x)=|\\tanh(x)|}\n  \n, and the sigmoid function \n  \n    \n      \n        \u03c3\n        (\n        x\n        )\n        =\n        (\n        1\n        +\n        \n          e\n          \n            \u2212\n            x\n          \n        \n        \n          )\n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\textstyle \\sigma (x)=(1+e^{-x})^{-1}}\n  \n. ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to generalization accuracy.\n\n\n=== Fully connected layer ===\nAfter several convolutional and max pooling layers, the final classification is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional) artificial neural networks. Their activations can thus be computed as an affine transformation, with matrix multiplication followed by a bias offset (vector addition of a learned or fixed bias term).\n\n\n=== Loss layer ===\n\nThe \"loss layer\", or \"loss function\", exemplifies how training penalizes the deviation between the predicted output of the network, and the true data labels (during supervised learning). Various loss functions can be used, depending on the specific task.\nThe Softmax loss function is used for predicting a single class of K mutually exclusive classes. Sigmoid cross-entropy loss is used for predicting K independent probability values in \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  \n. Euclidean loss is used for regressing to real-valued labels \n  \n    \n      \n        (\n        \u2212\n        \u221e\n        ,\n        \u221e\n        )\n      \n    \n    {\\displaystyle (-\\infty ,\\infty )}\n  \n.\n\n\n== Hyperparameters ==\n\nHyperparameters are various settings that are used to control the learning process. CNNs use more hyperparameters than a standard multilayer perceptron (MLP).\n\n\n=== Padding ===\nPadding is the addition of (typically) 0-valued pixels on the borders of an image. This is done so that the border pixels are not undervalued (lost) from the output because they would ordinarily participate in only a single receptive field instance. The padding applied is typically one less than the corresponding kernel dimension. For example, a convolutional layer using 3x3 kernels would receive a 2-pixel pad, that is 1 pixel on each side of the image.", "mimetype": "text/plain", "start_char_idx": 34447, "end_char_idx": 39261, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f2c1ae07-686f-4f6a-9190-3efa7ef621f3": {"__data__": {"id_": "f2c1ae07-686f-4f6a-9190-3efa7ef621f3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c25a7e50-10e3-46d3-88e8-f899fbb4d9fd", "node_type": "1", "metadata": {}, "hash": "d90c2cbdf4d09b492ee2ea267befbd3b36de85f40b3864c323fbca0c255ecfaf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bae32750-1e0b-4f3c-97f6-bbd3cdea4f0c", "node_type": "1", "metadata": {}, "hash": "aaad958f2a02f0aa6beb7bced4a98b5ef621274e5424304d2c7647d42313945c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Hyperparameters ==\n\nHyperparameters are various settings that are used to control the learning process. CNNs use more hyperparameters than a standard multilayer perceptron (MLP).\n\n\n=== Padding ===\nPadding is the addition of (typically) 0-valued pixels on the borders of an image. This is done so that the border pixels are not undervalued (lost) from the output because they would ordinarily participate in only a single receptive field instance. The padding applied is typically one less than the corresponding kernel dimension. For example, a convolutional layer using 3x3 kernels would receive a 2-pixel pad, that is 1 pixel on each side of the image.\n\n\n=== Stride ===\nThe stride is the number of pixels that the analysis window moves on each iteration. A stride of 2 means that each kernel is offset by 2 pixels from its predecessor.\n\n\n=== Number of filters ===\nSince feature map size decreases with depth, layers near the input layer tend to have fewer filters while higher layers can have more. To equalize computation at each layer, the product of feature values va with pixel position is kept roughly constant across layers. Preserving more information about the input would require keeping the total number of activations (number of feature maps times number of pixel positions) non-decreasing from one layer to the next.\nThe number of feature maps directly controls the capacity and depends on the number of available examples and task complexity.\n\n\n=== Filter (or Kernel) size ===\nCommon filter sizes found in the literature vary greatly, and are usually chosen based on the data set. Typical filter sizes range from 1x1 to 7x7. As two famous examples, AlexNet used 3x3, 5x5, and 11x11. Inceptionv3 used 1x1, 3x3, and 5x5.\nThe challenge is to find the right level of granularity so as to create abstractions at the proper scale, given a particular data set, and without overfitting.\n\n\n=== Pooling type and size ===\nMax pooling is typically used, often with a 2x2 dimension. This implies that the input is drastically downsampled, reducing processing cost.\nGreater pooling reduces the dimension of the signal, and may result in unacceptable information loss. Often, non-overlapping pooling windows perform best.\n\n\n=== Dilation ===\nDilation involves ignoring pixels within a kernel. This reduces processing memory potentially without significant signal loss. A dilation of 2 on a 3x3 kernel expands the kernel to 5x5, while still processing 9 (evenly spaced) pixels. Specifically, the processed pixels after the dilation are the cells (1,1), (1,3), (1,5), (3,1), (3,3), (3,5), (5,1), (5,3), (5,5), where (i,j) denotes the cell of the i-th row and j-th column in the expanded 5x5 kernel. Accordingly, dilation of 4 expands the kernel to 7x7.\n\n\n== Translation equivariance and aliasing ==\nIt is commonly assumed that CNNs are invariant to shifts of the input. Convolution or pooling layers within a CNN that do not have a stride greater than one are indeed equivariant to translations of the input. However, layers with a stride greater than one ignore the Nyquist\u2013Shannon sampling theorem and might lead to aliasing of the input signal While, in principle, CNNs are capable of implementing anti-aliasing filters, it has been observed that this does not happen in practice, and therefore yield models that are not equivariant to translations.\nFurthermore, if a CNN makes use of fully connected layers, translation equivariance does not imply translation invariance, as the fully connected layers are not invariant to shifts of the input. One solution for complete translation invariance is avoiding any down-sampling throughout the network and applying global average pooling at the last layer. Additionally, several other partial solutions have been proposed, such as anti-aliasing before downsampling operations, spatial transformer networks, data augmentation, subsampling combined with pooling, and capsule neural networks.\n\n\n== Evaluation ==\nThe accuracy of the final model is typically estimated on a sub-part of the dataset set apart at the start, often called a test set. Alternatively, methods such as k-fold cross-validation are applied. Other strategies include using conformal prediction.\n\n\n== Regularization methods ==\n\nRegularization is a process of introducing additional information to solve an ill-posed problem or to prevent overfitting. CNNs use various types of regularization.\n\n\n=== Empirical ===", "mimetype": "text/plain", "start_char_idx": 38604, "end_char_idx": 43031, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bae32750-1e0b-4f3c-97f6-bbd3cdea4f0c": {"__data__": {"id_": "bae32750-1e0b-4f3c-97f6-bbd3cdea4f0c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f2c1ae07-686f-4f6a-9190-3efa7ef621f3", "node_type": "1", "metadata": {}, "hash": "252de977c7e4754b3005c9a4608b805345e90dc118908f8e879ee2798f2693e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3065e88e-5f7a-4319-aec7-964d3ea86f59", "node_type": "1", "metadata": {}, "hash": "f914196a2f4d0f4742ac2d2ddd83556efd8581746726cf79c286bd968cd8fb19", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Evaluation ==\nThe accuracy of the final model is typically estimated on a sub-part of the dataset set apart at the start, often called a test set. Alternatively, methods such as k-fold cross-validation are applied. Other strategies include using conformal prediction.\n\n\n== Regularization methods ==\n\nRegularization is a process of introducing additional information to solve an ill-posed problem or to prevent overfitting. CNNs use various types of regularization.\n\n\n=== Empirical ===\n\n\n==== Dropout ====\nBecause networks have so many parameters, they are prone to overfitting. One method to reduce overfitting is dropout, introduced in 2014. At each training stage, individual nodes are either \"dropped out\" of the net (ignored) with probability \n  \n    \n      \n        1\n        \u2212\n        p\n      \n    \n    {\\displaystyle 1-p}\n  \n or kept with probability \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights.\nIn the training stages, \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n is usually 0.5; for input nodes, it is typically much higher because information is directly lost when input nodes are ignored.\nAt testing time after training has finished, we would ideally like to find a sample average of all possible \n  \n    \n      \n        \n          2\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle 2^{n}}\n  \n dropped-out networks; unfortunately this is unfeasible for large values of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n. However, we can find an approximation by using the full network with each node's output weighted by a factor of \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, so the expected value of the output of any node is the same as in the training stages. This is the biggest contribution of the dropout method: although it effectively generates \n  \n    \n      \n        \n          2\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle 2^{n}}\n  \n neural nets, and as such allows for model combination, at test time only a single network needs to be tested.\nBy avoiding training all nodes on all training data, dropout decreases overfitting. The method also significantly improves training speed. This makes the model combination practical, even for deep neural networks. The technique seems to reduce node interactions, leading them to learn more robust features that better generalize to new data.\n\n\n==== DropConnect ====\nDropConnect is the generalization of dropout in which each connection, rather than each output unit, can be dropped with probability \n  \n    \n      \n        1\n        \u2212\n        p\n      \n    \n    {\\displaystyle 1-p}\n  \n. Each unit thus receives input from a random subset of units in the previous layer.\nDropConnect is similar to dropout as it introduces dynamic sparsity within the model, but differs in that the sparsity is on the weights, rather than the output vectors of a layer. In other words, the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage.\n\n\n==== Stochastic pooling ====\nA major drawback to dropout is that it does not have the same benefits for convolutional layers, where the neurons are not fully connected.\nEven before dropout, in 2013 a technique called stochastic pooling, the conventional deterministic pooling operations were replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region. This approach is free of hyperparameters and can be combined with other regularization approaches, such as dropout and data augmentation.\nAn alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations. This is similar to explicit elastic deformations of the input images, which delivers excellent performance on the MNIST data set. Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.\n\n\n==== Artificial data ====\n\nBecause the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Because there is often not enough available data to train, especially considering that some part should be spared for later testing, two approaches are to either generate new data from scratch (if possible) or perturb existing data to create new ones. The latter one is used since mid-1990s. For example, input images can be cropped, rotated, or rescaled to create new examples with the same labels as the original training set.\n\n\n=== Explicit ===", "mimetype": "text/plain", "start_char_idx": 42544, "end_char_idx": 47674, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3065e88e-5f7a-4319-aec7-964d3ea86f59": {"__data__": {"id_": "3065e88e-5f7a-4319-aec7-964d3ea86f59", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bae32750-1e0b-4f3c-97f6-bbd3cdea4f0c", "node_type": "1", "metadata": {}, "hash": "aaad958f2a02f0aa6beb7bced4a98b5ef621274e5424304d2c7647d42313945c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7a2a0e5-bb31-4765-b782-5a4df75bdbac", "node_type": "1", "metadata": {}, "hash": "703a30f66fb0b7dd4496e96fa97e0b800bd3ea1454d47c3e5508816479c50854", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Artificial data ====\n\nBecause the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Because there is often not enough available data to train, especially considering that some part should be spared for later testing, two approaches are to either generate new data from scratch (if possible) or perturb existing data to create new ones. The latter one is used since mid-1990s. For example, input images can be cropped, rotated, or rescaled to create new examples with the same labels as the original training set.\n\n\n=== Explicit ===\n\n\n==== Early stopping ====\n\nOne of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. It comes with the disadvantage that the learning process is halted.\n\n\n==== Number of parameters ====\nAnother simple way to prevent overfitting is to limit the number of parameters, typically by limiting the number of hidden units in each layer or limiting network depth. For convolutional networks, the filter size also affects the number of parameters. Limiting the number of parameters restricts the predictive power of the network directly, reducing the complexity of the function that it can perform on the data, and thus limits the amount of overfitting. This is equivalent to a \"zero norm\".\n\n\n==== Weight decay ====\nA simple form of added regularizer is weight decay, which simply adds an additional error, proportional to the sum of weights (L1 norm) or squared magnitude (L2 norm) of the weight vector, to the error at each node. The level of acceptable model complexity can be reduced by increasing the proportionality constant('alpha' hyperparameter), thus increasing the penalty for large weight vectors.\nL2 regularization is the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot.\nL1 regularization is also common. It makes the weight vectors sparse during optimization. In other words, neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs. L1 with L2 regularization can be combined; this is called elastic net regularization.\n\n\n==== Max norm constraints ====\nAnother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector \n  \n    \n      \n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {w}}}\n  \n of every neuron to satisfy \n  \n    \n      \n        \u2016\n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n        \n          \u2016\n          \n            2\n          \n        \n        <\n        c\n      \n    \n    {\\displaystyle \\|{\\vec {w}}\\|_{2}<c}\n  \n. Typical values of \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n are order of 3\u20134. Some papers report improvements when using this form of regularization.", "mimetype": "text/plain", "start_char_idx": 47002, "end_char_idx": 50674, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b7a2a0e5-bb31-4765-b782-5a4df75bdbac": {"__data__": {"id_": "b7a2a0e5-bb31-4765-b782-5a4df75bdbac", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3065e88e-5f7a-4319-aec7-964d3ea86f59", "node_type": "1", "metadata": {}, "hash": "f914196a2f4d0f4742ac2d2ddd83556efd8581746726cf79c286bd968cd8fb19", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "36f36bc1-8a69-4bcf-a36a-3097c1952edf", "node_type": "1", "metadata": {}, "hash": "b163152590e9ffbcb338e2d964e03e99ff4c9fddb445dfaf4b7c100ea6f0af1f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Max norm constraints ====\nAnother form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector \n  \n    \n      \n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {w}}}\n  \n of every neuron to satisfy \n  \n    \n      \n        \u2016\n        \n          \n            \n              w\n              \u2192\n            \n          \n        \n        \n          \u2016\n          \n            2\n          \n        \n        <\n        c\n      \n    \n    {\\displaystyle \\|{\\vec {w}}\\|_{2}<c}\n  \n. Typical values of \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n are order of 3\u20134. Some papers report improvements when using this form of regularization.\n\n\n== Hierarchical coordinate frames ==\nPooling loses the precise spatial relationships between high-level parts (such as nose and mouth in a face image). These relationships are needed for identity recognition. Overlapping the pools so that each feature occurs in multiple pools, helps retain the information. Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint, such as a different orientation or scale. On the other hand, people are very good at extrapolating; after seeing a new shape once they can recognize it from a different viewpoint.\nAn earlier common way to deal with this problem is to train the network on transformed data in different orientations, scales, lighting, etc. so that the network can cope with these variations. This is computationally intensive for large data-sets. The alternative is to use a hierarchy of coordinate frames and use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the retina. The pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic features' coordinate frame.\nThus, one way to represent something is to embed the coordinate frame within it. This allows large features to be recognized by using the consistency of the poses of their parts (e.g. nose and mouth poses make a consistent prediction of the pose of the whole face). This approach ensures that the higher-level entity (e.g. face) is present when the lower-level (e.g. nose and mouth) agree on its prediction of the pose. The vectors of neuronal activity that represent pose (\"pose vectors\") allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints. This is similar to the way the human visual system imposes coordinate frames in order to represent shapes.\n\n\n== Applications ==", "mimetype": "text/plain", "start_char_idx": 49690, "end_char_idx": 52633, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "36f36bc1-8a69-4bcf-a36a-3097c1952edf": {"__data__": {"id_": "36f36bc1-8a69-4bcf-a36a-3097c1952edf", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b7a2a0e5-bb31-4765-b782-5a4df75bdbac", "node_type": "1", "metadata": {}, "hash": "703a30f66fb0b7dd4496e96fa97e0b800bd3ea1454d47c3e5508816479c50854", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f4045224-b123-4c58-82b0-7f7b6ea1d98a", "node_type": "1", "metadata": {}, "hash": "0cfa6b15c6a0b00307622d53db5d7d8dc3caca30abfd65393dbc14d76215e434", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Applications ==\n\n\n=== Image recognition ===\nCNNs are often used in image recognition systems. In 2012, an error rate of 0.23% on the MNIST database was reported. Another paper on using CNN for image classification reported that the learning process was \"surprisingly fast\"; in the same paper, the best published results as of 2011 were achieved in the MNIST database and the NORB database. Subsequently, a similar CNN called AlexNet won the ImageNet Large Scale Visual Recognition Challenge 2012.\nWhen applied to facial recognition, CNNs achieved a large decrease in error rate. Another paper reported a 97.6% recognition rate on \"5,600 still images of more than 10 subjects\". CNNs were used to assess video quality in an objective way after manual training; the resulting system had a very low root mean square error.\nThe ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes. In the ILSVRC 2014, a large-scale visual recognition challenge, almost every highly ranked team used CNN as their basic framework. The winner GoogLeNet (the foundation of DeepDream) increased the mean average precision of object detection to 0.439329, and reduced classification error to 0.06656, the best result to date. Its network applied more than 30 layers. That performance of convolutional neural networks on the ImageNet tests was close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters, an increasingly common phenomenon with modern digital cameras. By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained categories such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this.\nIn 2015, a many-layered CNN demonstrated the ability to spot faces from a wide range of angles, including upside down, even when partially occluded, with competitive performance. The network was trained on a database of 200,000 images that included faces at various angles and orientations and a further 20 million images without faces. They used batches of 128 images over 50,000 iterations.\n\n\n=== Video analysis ===\nCompared to image data domains, there is relatively little work on applying CNNs to video classification. Video is more complex than images since it has another (temporal) dimension. However, some extensions of CNNs into the video domain have been explored. One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space. Another way is to fuse the features of two convolutional neural networks, one for the spatial and one for the temporal stream. Long short-term memory (LSTM) recurrent units are typically incorporated after the CNN to account for inter-frame or inter-clip dependencies. Unsupervised learning schemes for training spatio-temporal features have been introduced, based on Convolutional Gated Restricted Boltzmann Machines and Independent Subspace Analysis. Its application can be seen in text-to-video model.\n\n\n=== Natural language processing ===\nCNNs have also been explored for natural language processing. CNN models are effective for various NLP problems and achieved excellent results in semantic parsing, search query retrieval, sentence modeling, classification, prediction and other traditional NLP tasks.\nCompared to traditional language processing methods such as recurrent neural networks, CNNs can represent different contextual realities of language that do not rely on a series-sequence assumption, while RNNs are better suitable when classical time series modeling is required.\n\n\n=== Anomaly detection ===\nA CNN with 1-D convolutions was used on time series in the frequency domain (spectral residual) by an unsupervised model to detect anomalies in the time domain.\n\n\n=== Drug discovery ===\nCNNs have been used in drug discovery. Predicting the interaction between molecules and biological proteins can identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for structure-based drug design. The system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures, AtomNet discovers chemical features, such as aromaticity, sp3 carbons, and hydrogen bonding. Subsequently, AtomNet was used to predict novel candidate biomolecules for multiple disease targets, most notably treatments for the Ebola virus and multiple sclerosis.", "mimetype": "text/plain", "start_char_idx": 52615, "end_char_idx": 57501, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4045224-b123-4c58-82b0-7f7b6ea1d98a": {"__data__": {"id_": "f4045224-b123-4c58-82b0-7f7b6ea1d98a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "36f36bc1-8a69-4bcf-a36a-3097c1952edf", "node_type": "1", "metadata": {}, "hash": "b163152590e9ffbcb338e2d964e03e99ff4c9fddb445dfaf4b7c100ea6f0af1f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b6780513-e950-4e89-90bd-08554676dcf9", "node_type": "1", "metadata": {}, "hash": "52c992e9cb923aaf5cee0aca8819eed9c8a036ffacd4aecc5ead7dd923f53bf3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Anomaly detection ===\nA CNN with 1-D convolutions was used on time series in the frequency domain (spectral residual) by an unsupervised model to detect anomalies in the time domain.\n\n\n=== Drug discovery ===\nCNNs have been used in drug discovery. Predicting the interaction between molecules and biological proteins can identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for structure-based drug design. The system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures, AtomNet discovers chemical features, such as aromaticity, sp3 carbons, and hydrogen bonding. Subsequently, AtomNet was used to predict novel candidate biomolecules for multiple disease targets, most notably treatments for the Ebola virus and multiple sclerosis.\n\n\n=== Checkers game ===\nCNNs have been used in the game of checkers. From 1999 to 2001, Fogel and Chellapilla published papers showing how a convolutional neural network could learn to play checkers using co-evolution. The learning process did not use prior human professional games, but rather focused on a minimal set of information contained in the checkerboard: the location and type of pieces, and the difference in number of pieces between the two sides. Ultimately, the program (Blondie24) was tested on 165 games against players and ranked in the highest 0.4%. It also earned a win against the program Chinook at its \"expert\" level of play.\n\n\n=== Go ===\nCNNs have been used in computer Go. In December 2014, Clark and Storkey published a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform GNU Go and win some games against Monte Carlo tree search Fuego 1.1 in a fraction of the time it took Fuego to play. Later it was announced that a large 12-layer convolutional neural network had correctly predicted the professional move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GNU Go in 97% of games, and matched the performance of the Monte Carlo tree search program Fuego simulating ten thousand playouts (about a million positions) per move.\nA couple of CNNs for choosing moves to try (\"policy network\") and evaluating positions (\"value network\") driving MCTS were used by AlphaGo, the first to beat the best human player at the time.\n\n\n=== Time series forecasting ===\nRecurrent neural networks are generally considered the best neural network architectures for time series forecasting (and sequence modeling in general), but recent studies show that convolutional networks can perform comparably or even better. Dilated convolutions might enable one-dimensional convolutional neural networks to effectively learn time series dependences. Convolutions can be implemented more efficiently than RNN-based solutions, and they do not suffer from vanishing (or exploding) gradients. Convolutional networks can provide an improved forecasting performance when there are multiple similar time series to learn from. CNNs can also be applied to further tasks in time series analysis (e.g., time series classification or quantile forecasting).\n\n\n=== Cultural heritage and 3D-datasets ===\nAs archaeological findings such as clay tablets with cuneiform writing are increasingly acquired using 3D scanners, benchmark datasets are becoming available, including HeiCuBeDa providing almost 2000 normalized 2-D and 3-D datasets prepared with the GigaMesh Software Framework. So curvature-based measures are used in conjunction with geometric neural networks (GNNs), e.g. for period classification of those clay tablets being among the oldest documents of human history.\n\n\n== Fine-tuning ==\nFor many applications, training data is not very available. Convolutional neural networks usually require a large amount of training data in order to avoid overfitting. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights, this is known as transfer learning. Furthermore, this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets.\n\n\n== Human interpretable explanations ==\nEnd-to-end training and prediction are common practice in computer vision. However, human interpretable explanations are required for critical systems such as a self-driving cars. With recent advances in visual salience, spatial attention, and temporal attention, the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.\n\n\n== Related architectures ==", "mimetype": "text/plain", "start_char_idx": 56559, "end_char_idx": 61515, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b6780513-e950-4e89-90bd-08554676dcf9": {"__data__": {"id_": "b6780513-e950-4e89-90bd-08554676dcf9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "40409788", "node_type": "4", "metadata": {}, "hash": "e3dc56b9ef42af1f1a69930bccf0dad09e4ff8d7b0e8e4a7e4ef9ff14c03a388", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4045224-b123-4c58-82b0-7f7b6ea1d98a", "node_type": "1", "metadata": {}, "hash": "0cfa6b15c6a0b00307622d53db5d7d8dc3caca30abfd65393dbc14d76215e434", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Fine-tuning ==\nFor many applications, training data is not very available. Convolutional neural networks usually require a large amount of training data in order to avoid overfitting. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights, this is known as transfer learning. Furthermore, this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets.\n\n\n== Human interpretable explanations ==\nEnd-to-end training and prediction are common practice in computer vision. However, human interpretable explanations are required for critical systems such as a self-driving cars. With recent advances in visual salience, spatial attention, and temporal attention, the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.\n\n\n== Related architectures ==\n\n\n=== Deep Q-networks ===\nA deep Q-network (DQN) is a type of deep learning model that combines a deep neural network with Q-learning, a form of reinforcement learning. Unlike earlier reinforcement learning agents, DQNs that utilize CNNs can learn directly from high-dimensional sensory inputs via reinforcement learning.\nPreliminary results were presented in 2014, with an accompanying paper in February 2015. The research described an application to Atari 2600 gaming. Other deep reinforcement learning models preceded it.\n\n\n=== Deep belief networks ===\n\nConvolutional deep belief networks (CDBN) have structure very similar to convolutional neural networks and are trained similarly to deep belief networks. Therefore, they exploit the 2D structure of images, like CNNs do, and make use of pre-training like deep belief networks. They provide a generic structure that can be used in many image and signal processing tasks. Benchmark results on standard image datasets like CIFAR have been obtained using CDBNs.\n\n\n=== Neural abstraction pyramid ===\nThe feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid by lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models, image-like outputs at the highest resolution were generated, e.g., for semantic segmentation, image reconstruction, and object localization tasks.\n\n\n== Notable libraries ==\nCaffe: A library for convolutional neural networks. Created by the Berkeley Vision and Learning Center (BVLC). It supports both CPU and GPU. Developed in C++, and has Python and MATLAB wrappers.\nDeeplearning4j: Deep learning in Java and Scala on multi-GPU-enabled Spark. A general-purpose deep learning library for the JVM production stack running on a C++ scientific computing engine. Allows the creation of custom layers. Integrates with Hadoop and Kafka.\nDlib: A toolkit for making real world machine learning and data analysis applications in C++.\nMicrosoft Cognitive Toolkit: A deep learning toolkit written by Microsoft with several unique features enhancing scalability over multiple nodes. It supports full-fledged interfaces for training in C++ and Python and with additional support for model inference in C# and Java.\nTensorFlow: Apache 2.0-licensed Theano-like library with support for CPU, GPU, Google's proprietary tensor processing unit (TPU), and mobile devices.\nTheano: The reference deep-learning library for Python with an API largely compatible with the popular NumPy library. Allows user to write symbolic mathematical expressions, then automatically generates their derivatives, saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to CUDA code for a fast, on-the-GPU implementation.\nTorch: A scientific computing framework with wide support for machine learning algorithms, written in C and Lua.\n\n\n== See also ==\nAttention (machine learning)\nConvolution\nDeep learning\nNatural-language processing\nNeocognitron\nScale-invariant feature transform\nTime delay neural network\nVision processing unit\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\nCS231n: Convolutional Neural Networks for Visual Recognition \u2014 Andrej Karpathy's Stanford computer science course on CNNs in computer vision\nvdumoulin/conv_arithmetic: A technical report on convolution arithmetic in the context of deep learning. Animations of convolutions.", "mimetype": "text/plain", "start_char_idx": 60489, "end_char_idx": 65082, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1dd41de2-bdad-4989-8ba3-16e5dce73351": {"__data__": {"id_": "1dd41de2-bdad-4989-8ba3-16e5dce73351", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c62f167-7dbc-4b76-8fbb-4fd35ee4263a", "node_type": "1", "metadata": {}, "hash": "a395b9d1efa18315c37497f551dd362d1cc568ea2319f1efc71e8c7fb86136a0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\nMajor tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.\n\n\n== History ==\n\nNatural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\n\n\n=== Symbolic NLP (1950s \u2013 early 1990s) ===\nThe premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n\n1950s: The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.  However, real progress was much slower, and after the ALPAC report in 1966, which found that ten years of research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted in America (though some research continued elsewhere, such as Japan and Europe) until the late 1980s when the first statistical machine translation systems were developed.\n1960s: Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 and 1966. Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\". Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only twenty words, because that was all that would fit in a computer  memory at the time.\n1970s: During the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data.  Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).  During this time, the first chatterbots were written (e.g., PARRY).\n1980s: The 1980s and early 1990s mark the heyday of symbolic methods in NLP. Focus areas of the time included research on rule-based parsing (e.g., the development of HPSG as a computational operationalization of generative grammar), morphology (e.g., two-level morphology), semantics (e.g., Lesk algorithm), reference (e.g., within Centering Theory) and other areas of natural language understanding (e.g., in the Rhetorical Structure Theory). Other lines of research were continued, e.g., the development of chatterbots with Racter and Jabberwacky. An important development (that eventually led to the statistical turn in the 1990s) was the rising importance of quantitative evaluation in this period.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3909, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c62f167-7dbc-4b76-8fbb-4fd35ee4263a": {"__data__": {"id_": "5c62f167-7dbc-4b76-8fbb-4fd35ee4263a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1dd41de2-bdad-4989-8ba3-16e5dce73351", "node_type": "1", "metadata": {}, "hash": "105ab3b5bc45d3a13f20c32fdc7681f44dfd18496e349f110826987a8222b624", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "55baec5d-f219-4d86-8d6d-2e6575f80bd7", "node_type": "1", "metadata": {}, "hash": "5fc55e741fccdcb5d99a32bb1003efa3f41348538dba744109ffb0eb9f6250e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Statistical NLP (1990s\u2013present) ===\nUp until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. \n\n1990s: Many of the notable early successes in statistical methods in NLP occurred in the field of machine translation, due especially to work at IBM Research, such as IBM alignment models.  These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.  However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems. As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.\n2000s: With the growth of the web, increasing amounts of raw (unannotated) language data have become available since the mid-1990s. Research has thus increasingly focused on unsupervised and semi-supervised learning algorithms.  Such algorithms can learn from data that has not been hand-annotated with the desired answers or using a combination of annotated and non-annotated data.  Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data.  However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the worse efficiency if the algorithm used has a low enough time complexity to be practical.\n2003: word n-gram model, at the time the best statistical algorithm, is outperformed by a multi-layer perceptron (with a single hidden layer and context length of several words, trained on up to 14 million words, by Bengio et al.)\n2010: Tom\u00e1\u0161 Mikolov (then a PhD student at Brno University of Technology) with co-authors applied a simple recurrent neural network with a single hidden layer to language modelling, and in the following years he went on to develop Word2vec. In the 2010s, representation learning and deep neural network-style (featuring many hidden layers) machine learning methods became widespread in natural language processing. That popularity was due partly to a flurry of results showing that such techniques can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling and parsing. This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care or protect patient privacy.\n\n\n== Approaches: Symbolic, statistical, neural networks ==\nSymbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular: such as by writing grammars or devising heuristic rules for stemming.\nMachine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \n\nboth statistical and neural networks methods can focus more on the most common cases extracted from a corpus of texts, whereas the rule-based approach needs to provide rules for both rare cases and common ones equally.\nlanguage models, produced by either statistical or neural networks methods, are more robust to both unfamiliar (e.g. containing words or structures that have not been seen before) and erroneous input (e.g. with misspelled words or words accidentally omitted) in comparison to the rule-based systems, which are also more costly to produce.\nthe larger such a (probabilistic) language model is, the more accurate it becomes, in contrast to rule-based systems that can gain accuracy only by increasing the amount and complexity of the rules leading to intractability problems.\nRule-based systems are commonly used:\n\nwhen the amount of training data is insufficient to successfully apply machine learning methods, e.g., for the machine translation of low-resource languages such as provided by the Apertium system,\nfor preprocessing in NLP pipelines, e.g., tokenization, or\nfor postprocessing and transforming the output of NLP pipelines, e.g., for knowledge extraction from syntactic parses.", "mimetype": "text/plain", "start_char_idx": 3912, "end_char_idx": 8961, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55baec5d-f219-4d86-8d6d-2e6575f80bd7": {"__data__": {"id_": "55baec5d-f219-4d86-8d6d-2e6575f80bd7", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c62f167-7dbc-4b76-8fbb-4fd35ee4263a", "node_type": "1", "metadata": {}, "hash": "a395b9d1efa18315c37497f551dd362d1cc568ea2319f1efc71e8c7fb86136a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "317f134a-8f9f-4c9c-b16a-82900d3fa03b", "node_type": "1", "metadata": {}, "hash": "43017ebed3ab6cb435709e28ff43c306bdf02e2f6fc47891779b57b97f363482", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Statistical approach ===\nIn the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.\nThe earliest decision trees, producing systems of hard if\u2013then rules, were still very similar to the old rule-based approaches.\nOnly the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\n\n\n=== Neural networks ===\n\nA major drawback of statistical methods is that they require elaborate feature engineering. Since 2015, the statistical approach has been replaced by the neural networks approach, using semantic networks and word embeddings to capture semantic properties of words.  \nIntermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. \nNeural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\n\n\n== Common NLP tasks ==\nThe following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\nThough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\n\n\n=== Text and speech processing ===\nOptical character recognition (OCR)\nGiven an image representing printed text, determine the corresponding text.\nSpeech recognition\nGiven a sound clip of a person or people speaking, determine the textual representation of the speech.  This is the opposite of text to speech and is one of the extremely difficult problems colloquially termed \"AI-complete\" (see above).  In natural speech there are hardly any pauses between successive words, and thus speech segmentation is a necessary subtask of speech recognition (see below). In most spoken languages, the sounds representing successive letters blend into each other in a process termed coarticulation, so the conversion of the analog signal to discrete characters can be a very difficult process. Also, given that words in the same language are spoken by people with different accents, the speech recognition software must be able to recognize the wide variety of input as being identical to each other in terms of its textual equivalent.\nSpeech segmentation\nGiven a sound clip of a person or people speaking, separate it into words.  A subtask of speech recognition and typically grouped with it.\nText-to-speech\nGiven a text, transform those units and produce a spoken representation. Text-to-speech can be used to aid the visually impaired.\nWord segmentation (Tokenization)\nTokenization is a process used in text analysis that divides text into individual words or word fragments. This technique results in two key components: a word index and tokenized text. The word index is a list that maps unique words to specific numerical identifiers, and the tokenized text replaces each word with its corresponding numerical token. These numerical tokens are then used in various deep learning methods.\nFor a language like English, this is fairly trivial, since words are usually separated by spaces. However, some written languages like Chinese, Japanese and Thai do not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language. Sometimes this process is also used in cases like bag of words (BOW) creation in data mining.", "mimetype": "text/plain", "start_char_idx": 8964, "end_char_idx": 12679, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "317f134a-8f9f-4c9c-b16a-82900d3fa03b": {"__data__": {"id_": "317f134a-8f9f-4c9c-b16a-82900d3fa03b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "55baec5d-f219-4d86-8d6d-2e6575f80bd7", "node_type": "1", "metadata": {}, "hash": "5fc55e741fccdcb5d99a32bb1003efa3f41348538dba744109ffb0eb9f6250e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "34c6ce7a-41fd-4449-a0fb-fc3e4484c4ef", "node_type": "1", "metadata": {}, "hash": "fadf772f3e0b9f36538e8d67a972b138eedad412f2686a334f0e95f208f450ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Morphological analysis ===\nLemmatization\nThe task of removing inflectional endings only and to return the base dictionary form of a word which is also known as a lemma. Lemmatization is another technique for reducing words to their normalized form. But in this case, the transformation actually uses a dictionary to map words to their actual form.\nMorphological segmentation\nSeparate words into individual morphemes and identify the class of the morphemes. The difficulty of this task depends greatly on the complexity of the morphology (i.e., the structure of words) of the language being considered. English has fairly simple morphology, especially inflectional morphology, and thus it is often possible to ignore this task entirely and simply model all possible forms of a word (e.g., \"open, opens, opened, opening\") as separate words. In languages such as Turkish or Meitei, a highly agglutinated Indian language, however, such an approach is not possible, as each dictionary entry has thousands of possible word forms.\nPart-of-speech tagging\nGiven a sentence, determine the part of speech (POS) for each word. Many words, especially common ones, can serve as multiple parts of speech. For example, \"book\" can be a noun (\"the book on the table\") or verb (\"to book a flight\"); \"set\" can be a noun, verb or adjective; and \"out\" can be any of at least five different parts of speech.\nStemming\nThe process of reducing inflected (or sometimes derived) words to a base form (e.g., \"close\" will be the root for \"closed\", \"closing\", \"close\", \"closer\" etc.). Stemming yields similar results as lemmatization, but does so on grounds of rules, not a dictionary.\n\n\n=== Syntactic analysis ===\n\nGrammar induction\nGenerate a formal grammar that describes a language's syntax.\nSentence breaking (also known as \"sentence boundary disambiguation\")\nGiven a chunk of text, find the sentence boundaries. Sentence boundaries are often marked by periods or other punctuation marks, but these same characters can serve other purposes (e.g., marking abbreviations).\nParsing\nDetermine the parse tree (grammatical analysis) of a given sentence. The grammar for natural languages is ambiguous and typical sentences have multiple possible analyses: perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human). There are two primary types of parsing: dependency parsing and constituency parsing. Dependency parsing focuses on the relationships between words in a sentence (marking things like primary objects and predicates), whereas constituency parsing focuses on building out the parse tree using a probabilistic context-free grammar (PCFG) (see also stochastic grammar).", "mimetype": "text/plain", "start_char_idx": 12682, "end_char_idx": 15422, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "34c6ce7a-41fd-4449-a0fb-fc3e4484c4ef": {"__data__": {"id_": "34c6ce7a-41fd-4449-a0fb-fc3e4484c4ef", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "317f134a-8f9f-4c9c-b16a-82900d3fa03b", "node_type": "1", "metadata": {}, "hash": "43017ebed3ab6cb435709e28ff43c306bdf02e2f6fc47891779b57b97f363482", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ea5ee3ce-0629-403d-ae59-7d5b5025bdae", "node_type": "1", "metadata": {}, "hash": "7a7eed47972ad9047135d03780ae888ef99e9e2bdacbf5cf2ba94770eeb31afd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Syntactic analysis ===\n\nGrammar induction\nGenerate a formal grammar that describes a language's syntax.\nSentence breaking (also known as \"sentence boundary disambiguation\")\nGiven a chunk of text, find the sentence boundaries. Sentence boundaries are often marked by periods or other punctuation marks, but these same characters can serve other purposes (e.g., marking abbreviations).\nParsing\nDetermine the parse tree (grammatical analysis) of a given sentence. The grammar for natural languages is ambiguous and typical sentences have multiple possible analyses: perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human). There are two primary types of parsing: dependency parsing and constituency parsing. Dependency parsing focuses on the relationships between words in a sentence (marking things like primary objects and predicates), whereas constituency parsing focuses on building out the parse tree using a probabilistic context-free grammar (PCFG) (see also stochastic grammar).\n\n\n=== Lexical semantics (of individual words in context) ===\nLexical semantics\nWhat is the computational meaning of individual words in context?\nDistributional semantics\nHow can we learn semantic representations from data?\nNamed entity recognition (NER)\nGiven a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization). Although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity, and in any case, is often inaccurate or insufficient.  For example, the first letter of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized.  Furthermore, many other languages in non-Western scripts (e.g. Chinese or Arabic) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names. For example, German capitalizes all nouns, regardless of whether they are names, and French and Spanish do not capitalize names that serve as adjectives. Another name for this task is token classification.\nSentiment analysis (see also Multimodal sentiment analysis)\nSentiment analysis is a computational method used to identify and classify the emotional intent behind text. This technique involves analyzing text to determine whether the expressed sentiment is positive, negative, or neutral. Models for sentiment classification typically utilize inputs such as word n-grams, Term Frequency-Inverse Document Frequency (TF-IDF) features, hand-generated features, or employ deep learning models designed to recognize both long-term and short-term dependencies in text sequences. The applications of sentiment analysis are diverse, extending to tasks such as categorizing customer reviews on various online platforms.\nTerminology extraction\nThe goal of terminology extraction is to automatically extract relevant terms from a given corpus.\nWord-sense disambiguation (WSD)\nMany words have more than one meaning; we have to select the meaning which makes the most sense in context.  For this problem, we are typically given a list of words and associated word senses, e.g. from a dictionary or an online resource such as WordNet.\nEntity linking\nMany words\u2014typically proper names\u2014refer to named entities; here we have to select the entity (a famous individual, a location, a company, etc.) which is referred to in context.\n\n\n=== Relational semantics (semantics of individual sentences) ===\nRelationship extraction\nGiven a chunk of text, identify the relationships among named entities (e.g. who is married to whom).\nSemantic parsing\nGiven a piece of text (typically a sentence), produce a formal representation of its semantics, either as a graph (e.g., in AMR parsing) or in accordance with a logical formalism (e.g., in DRT parsing). This challenge typically includes aspects of several more elementary NLP tasks from semantics (e.g., semantic role labelling, word-sense disambiguation) and can be extended to include full-fledged discourse analysis (e.g., discourse analysis, coreference; see Natural language understanding below).\nSemantic role labelling (see also implicit semantic role labelling below)\nGiven a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames), then identify and classify the frame elements (semantic roles).", "mimetype": "text/plain", "start_char_idx": 14343, "end_char_idx": 18894, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ea5ee3ce-0629-403d-ae59-7d5b5025bdae": {"__data__": {"id_": "ea5ee3ce-0629-403d-ae59-7d5b5025bdae", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "34c6ce7a-41fd-4449-a0fb-fc3e4484c4ef", "node_type": "1", "metadata": {}, "hash": "fadf772f3e0b9f36538e8d67a972b138eedad412f2686a334f0e95f208f450ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1a60dfd-2964-45a2-8bac-9b66549be437", "node_type": "1", "metadata": {}, "hash": "a94a9a8d874f80e0abeaa351faee8b2cba8f854d9ffc0b112e61ae757e407af5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Relational semantics (semantics of individual sentences) ===\nRelationship extraction\nGiven a chunk of text, identify the relationships among named entities (e.g. who is married to whom).\nSemantic parsing\nGiven a piece of text (typically a sentence), produce a formal representation of its semantics, either as a graph (e.g., in AMR parsing) or in accordance with a logical formalism (e.g., in DRT parsing). This challenge typically includes aspects of several more elementary NLP tasks from semantics (e.g., semantic role labelling, word-sense disambiguation) and can be extended to include full-fledged discourse analysis (e.g., discourse analysis, coreference; see Natural language understanding below).\nSemantic role labelling (see also implicit semantic role labelling below)\nGiven a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames), then identify and classify the frame elements (semantic roles).\n\n\n=== Discourse (semantics beyond individual sentences) ===\nCoreference resolution\nGiven a sentence or larger chunk of text, determine which words (\"mentions\") refer to the same objects (\"entities\"). Anaphora resolution is a specific example of this task, and is specifically concerned with matching up pronouns with the nouns or names to which they refer. The more general task of coreference resolution also includes identifying so-called \"bridging relationships\" involving referring expressions. For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to).\nDiscourse analysis\nThis rubric includes several related tasks.  One task is discourse parsing, i.e., identifying the discourse structure of a connected text, i.e. the nature of the discourse relationships between sentences (e.g. elaboration, explanation, contrast).  Another possible task is recognizing and classifying the speech acts in a chunk of text (e.g. yes\u2013no question, content question, statement, assertion, etc.).\nImplicit semantic role labelling\nGiven a single sentence, identify and disambiguate semantic predicates (e.g., verbal frames) and their explicit semantic roles in the current sentence (see Semantic role labelling above). Then, identify semantic roles that are not explicitly realized in the current sentence, classify them into arguments that are explicitly realized elsewhere in the text and those that are not specified, and resolve the former against the local text. A closely related task is zero anaphora resolution, i.e., the extension of coreference resolution to pro-drop languages.\nRecognizing textual entailment\nGiven two text fragments, determine if one being true entails the other, entails the other's negation, or allows the other to be either true or false.\nTopic segmentation and recognition\nGiven a chunk of text, separate it into segments each of which is devoted to a topic, and identify the topic of the segment.\nArgument mining\nThe goal of argument mining is the automatic extraction and identification of argumentative structures from natural language text with the aid of computer programs. Such argumentative structures include the premise, conclusions, the argument scheme and the relationship between the main and subsidiary argument, or the main and counter-argument within discourse.", "mimetype": "text/plain", "start_char_idx": 17953, "end_char_idx": 21453, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c1a60dfd-2964-45a2-8bac-9b66549be437": {"__data__": {"id_": "c1a60dfd-2964-45a2-8bac-9b66549be437", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ea5ee3ce-0629-403d-ae59-7d5b5025bdae", "node_type": "1", "metadata": {}, "hash": "7a7eed47972ad9047135d03780ae888ef99e9e2bdacbf5cf2ba94770eeb31afd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4723263f-2090-46e7-be96-d0b44bb72c6b", "node_type": "1", "metadata": {}, "hash": "093ee75a8d1f8b75f75ea98e4c6eb08e099e4cf9639732fe735546ac573775f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Higher-level NLP applications ===\nAutomatic summarization (text summarization)\nProduce a readable summary of a chunk of text.  Often used to provide summaries of the text of a known type, such as research papers, articles in the financial section of a newspaper.\nGrammatical error correction\nGrammatical error detection and correction involves a great band-width of problems on all levels of linguistic analysis (phonology/orthography, morphology, syntax, semantics, pragmatics). Grammatical error correction is impactful since it affects hundreds of millions of people that use or acquire English as a second language. It has thus been subject to a number of shared tasks since 2011. As far as orthography, morphology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as GPT-2, this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications.\nLogic translation\nTranslate a text from a natural language into formal logic.\nMachine translation (MT)\nAutomatically translate text from one human language to another.  This is one of the most difficult problems, and is a member of a class of problems colloquially termed \"AI-complete\", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) to solve properly.\nNatural-language understanding (NLU)\nConvert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption, or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization.\nNatural-language generation (NLG):\nConvert information from computer databases or semantic intents into readable human language.\nBook generation\nNot an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books. The first machine-generated book was created by a rule-based system in 1984 (Racter, The policeman's beard is half-constructed). The first published work by a neural network was published in 2018, 1 the Road, marketed as a novel, contains sixty million words. Both these systems are basically elaborate but non-sensical (semantics-free) language models. The first machine-generated science book was published in 2019 (Beta Writer, Lithium-Ion Batteries, Springer, Cham). Unlike Racter and 1 the Road, this is grounded on factual knowledge and based on text summarization.\nDocument AI\nA Document AI platform sits on top of the NLP technology enabling users with no prior experience of artificial intelligence, machine learning or NLP to quickly train a computer to extract the specific data they need from different document types. NLP-powered Document AI enables non-technical teams to quickly access information hidden in documents, for example, lawyers, business analysts and accountants.\nDialogue management\nComputer systems intended to converse with a human.\nQuestion answering\nGiven a human-language question, determine its answer. Typical questions have a specific right answer (such as \"What is the capital of Canada?\"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\").\nText-to-image generation\nGiven a description of an image, generate an image that matches the description.\nText-to-scene generation\nGiven a description of a scene, generate a 3D model of the scene.\nText-to-video\nGiven a description of a video, generate a video that matches the description.", "mimetype": "text/plain", "start_char_idx": 21456, "end_char_idx": 25584, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4723263f-2090-46e7-be96-d0b44bb72c6b": {"__data__": {"id_": "4723263f-2090-46e7-be96-d0b44bb72c6b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1a60dfd-2964-45a2-8bac-9b66549be437", "node_type": "1", "metadata": {}, "hash": "a94a9a8d874f80e0abeaa351faee8b2cba8f854d9ffc0b112e61ae757e407af5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5d5d7710-34f3-4a7d-ba46-76ac34a29038", "node_type": "1", "metadata": {}, "hash": "30671dddf41c41ebe5b01089827bbddb1763a9c7f27f60dcc408bfdaedbf252e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== General tendencies and (possible) future directions ==\nBased on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:\n\nInterest on increasingly abstract, \"cognitive\" aspects of natural language (1999\u20132001: shallow parsing, 2002\u201303: named entity recognition, 2006\u201309/2017\u201318: dependency syntax, 2004\u201305/2008\u201309 semantic role labelling, 2011\u201312 coreference, 2015\u201316: discourse parsing, 2019: semantic parsing).\nIncreasing interest in multilinguality, and, potentially, multimodality (English since 1999; Spanish, Dutch since 2002; German since 2003; Bulgarian, Danish, Japanese, Portuguese, Slovenian, Swedish, Turkish since 2006; Basque, Catalan, Chinese, Greek, Hungarian, Italian, Turkish since 2007; Czech since 2009; Arabic since 2012; 2017: 40+ languages; 2018: 60+/100+ languages)\nElimination of symbolic representations (rule-based over supervised towards weakly supervised methods, representation learning and end-to-end systems)", "mimetype": "text/plain", "start_char_idx": 25587, "end_char_idx": 26672, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5d5d7710-34f3-4a7d-ba46-76ac34a29038": {"__data__": {"id_": "5d5d7710-34f3-4a7d-ba46-76ac34a29038", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21652", "node_type": "4", "metadata": {}, "hash": "5920a39fe1164eab3cb0bccfdbb4613b3bc5f57a687fce00c17d6aed43add4b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4723263f-2090-46e7-be96-d0b44bb72c6b", "node_type": "1", "metadata": {}, "hash": "093ee75a8d1f8b75f75ea98e4c6eb08e099e4cf9639732fe735546ac573775f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Cognition ===\nMost higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\nCognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\" Cognitive science is the interdisciplinary, scientific study of the mind and its processes. Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics. Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\nAs an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics, with two defining aspects:\n\nApply the theory of conceptual metaphor, explained by Lakoff as \"the understanding of one idea, in terms of another\" which provides an idea of the intent of the author. For example, consider the English word big. When used in a comparison (\"That is a big tree\"), the author's intent is to imply that the tree is physically large relative to other trees or the authors experience.  When used metaphorically (\"Tomorrow is a big day\"), the author's intent to imply importance.  The intent behind other usages, like in \"She is a big person\", will remain somewhat ambiguous to a person and a cognitive NLP algorithm alike without additional information.\nAssign relative measures of meaning to a word, phrase, sentence or piece of text based on the information presented before and after the piece of text being analyzed, e.g., by means of a probabilistic context-free grammar (PCFG). The mathematical equation for such algorithms is presented in  US Patent 9269353:\n\n  \n    \n      \n        \n          R\n          M\n          M\n          (\n          t\n          o\n          k\n          e\n          \n            n\n            \n              N\n            \n          \n          )\n        \n        =\n        \n          P\n          M\n          M\n          (\n          t\n          o\n          k\n          e\n          \n            n\n            \n              N\n            \n          \n          )\n        \n        \u00d7\n        \n          \n            1\n            \n              2\n              d\n            \n          \n        \n        \n          (\n          \n            \n              \u2211\n              \n                i\n                =\n                \u2212\n                d\n              \n              \n                d\n              \n            \n            \n              (\n              (\n              P\n              M\n              M\n              (\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                \n              \n              )\n            \n            \u00d7\n            \n              P\n              F\n              (\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                  \u2212\n                  i\n                \n              \n              ,\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                \n              \n              ,\n              t\n              o\n              k\n              e\n              \n                n\n                \n                  N\n                  +\n                  i\n                \n              \n              )\n              \n                )\n                \n                  i\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle {RMM(token_{N})}={PMM(token_{N})}\\times {\\frac {1}{2d}}\\left(\\sum _{i=-d}^{d}{((PMM(token_{N})}\\times {PF(token_{N-i},token_{N},token_{N+i}))_{i}}\\right)}\n  \n\nWhere\nRMM is the relative measure of meaning\ntoken is any block of text, sentence, phrase or word\nN is the number of tokens being analyzed\nPMM is the probable measure of meaning based on a corpora\nd is the non zero location of the token along the sequence of N tokens\nPF is the probability function specific to a language\nTies with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar, functional grammar, construction grammar, computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\". Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit) and developments in artificial intelligence, specifically tools and technologies using large language model approaches and new directions in artificial general intelligence based on the free energy principle by British neuroscientist and theoretician at University College London Karl J. Friston.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n Media related to Natural language processing at Wikimedia Commons", "mimetype": "text/plain", "start_char_idx": 26675, "end_char_idx": 32440, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a8e00bba-ce6c-4e7a-bdee-23ccb3369cbf": {"__data__": {"id_": "a8e00bba-ce6c-4e7a-bdee-23ccb3369cbf", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb06471e-7fe8-484f-aca8-418f5c0a9f2a", "node_type": "1", "metadata": {}, "hash": "5a51e5132d8d421e3d6edcfc4850e00358d87b4efc30b76388a80931991a799f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \nGenerative AI tools have become more common since an \"AI boom\" in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, DeepSeek, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Technology companies developing generative AI include OpenAI, Anthropic, Microsoft, Google, DeepSeek, and Baidu.\nGenerative AI has raised many ethical questions. It can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to the mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on and emulate copyrighted works of art. \nGenerative AI is used across many industries. Examples include software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. \n\n\n== History ==\n\n\n=== Early history ===\nThe first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\n\n\n=== Generative neural nets (2014-2019) ===\n\nSince its inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models, leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018. This was followed in 2019 by GPT-2, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.\nThe new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4372, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "eb06471e-7fe8-484f-aca8-418f5c0a9f2a": {"__data__": {"id_": "eb06471e-7fe8-484f-aca8-418f5c0a9f2a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8e00bba-ce6c-4e7a-bdee-23ccb3369cbf", "node_type": "1", "metadata": {}, "hash": "2f875300cbf09e7bcbb10c671becfb85948c6841ad7322473167b12fd6a15b03", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "788240d0-bb49-4a6e-a0cf-ddbdc62f8765", "node_type": "1", "metadata": {}, "hash": "e1a4fed407a0d7309d43684f1a3e0bbf3f61118ccb058696cc966f802e9d5e7c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Generative AI boom (2020-) ===\n\nIn March 2020, the release of 15.ai, a free web application created by an anonymous MIT researcher that could generate convincing character voices using minimal training data, marked one of the earliest popular use cases of generative AI. The platform is credited as the first mainstream service to popularize AI voice cloning (audio deepfakes) in memes and content creation, influencing subsequent developments in voice AI technology.\nIn 2021, the emergence of DALL-E, a transformer-based pixel generative model, marked an advance in AI-generated imagery. This was followed by the releases of Midjourney and Stable Diffusion in 2022, which further democratized access to high-quality artificial intelligence art creation from natural language prompts. These systems demonstrated unprecedented capabilities in generating photorealistic images, artwork, and designs based on text descriptions, leading to widespread adoption among artists, designers, and the general public.\nIn late 2022, the public release of ChatGPT revolutionized the accessibility and application of generative AI for general-purpose text-based tasks. The system's ability to engage in natural conversations, generate creative content, assist with coding, and perform various analytical tasks captured global attention and sparked widespread discussion about AI's potential impact on work, education, and creativity.\nIn March 2023, GPT-4's release represented another jump in generative AI capabilities. A team from Microsoft Research controversially argued that it \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\" However, this assessment was contested by other scholars who maintained that generative AI remained \"still far from reaching the benchmark of 'general human intelligence'\" as of 2023. Later in 2023, Meta released ImageBind, an AI model combining multiple modalities including text, images, video, thermal data, 3D data, audio, and motion, paving the way for more immersive generative AI applications.\nIn December 2023, Google unveiled Gemini, a multimodal AI model available in four versions: Ultra, Pro, Flash, and Nano. The company integrated Gemini Pro into its Bard chatbot and announced plans for \"Bard Advanced\" powered by the larger Gemini Ultra model. In February 2024, Google unified Bard and Duet AI under the Gemini brand, launching a mobile app on Android and integrating the service into the Google app on iOS.\nIn March 2024, Anthropic released the Claude 3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus. The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google. In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis.\n\nAccording to a survey by SAS and Coleman Parkes Research, China has emerged as a global leader in generative AI adoption, with 83% of Chinese respondents using the technology, exceeding both the global average of 54% and the U.S. rate of 65%. This leadership is further evidenced by China's intellectual property developments in the field, with a UN report revealing that Chinese entities filed over 38,000 generative AI patents from 2014 to 2023, substantially surpassing the United States in patent applications.", "mimetype": "text/plain", "start_char_idx": 4375, "end_char_idx": 7915, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "788240d0-bb49-4a6e-a0cf-ddbdc62f8765": {"__data__": {"id_": "788240d0-bb49-4a6e-a0cf-ddbdc62f8765", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb06471e-7fe8-484f-aca8-418f5c0a9f2a", "node_type": "1", "metadata": {}, "hash": "5a51e5132d8d421e3d6edcfc4850e00358d87b4efc30b76388a80931991a799f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b187125-22ec-4c42-abab-67e0d206092d", "node_type": "1", "metadata": {}, "hash": "55939be9f839810e5fbc5546e629fb1c0b805c871c49519397c7d5ef9b1fd81d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Applications ==\nA generative AI system is constructed by applying unsupervised machine learning (invoking for instance neural network architectures such as generative adversarial networks (GANs), variation autoencoders (VAEs), transformers, or self-supervised machine learning trained on a dataset. The capabilities of a generative AI system depend on the output (modality) of the data set used. Generative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input. For example, one version of OpenAI's GPT-4 accepts both text and image inputs.\nGenerative AI has made its appearance in a wide variety of industries, radically changing the dynamics of content creation, analysis, and delivery. In healthcare, generative AI is instrumental in accelerating drug discovery by creating molecular structures with target characteristics and generating radiology images for training diagnostic models. This extraordinary ability not only enables faster and cheaper development but also enhances medical decision-making. In finance, generative AI is invaluable as it generates datasets to train models and automates report generation with natural language summarization capabilities. It automates content creation, produces synthetic financial data, and tailors customer communications. It also powers chatbots and virtual agents. Collectively, these technologies enhance efficiency, reduce operational costs, and support data-driven decision-making in financial institutions. The media industry makes use of generative AI for numerous creative activities such as music composition, scriptwriting, video editing, and digital art. The educational sector is impacted as well, since the tools make learning personalized through creating quizzes, study aids, and essay composition. Both the teachers and the learners benefit from AI-based platforms that suit various learning patterns.\n\n\n=== Text and software code ===\n\nGenerative AI systems trained on words or word tokens include GPT-3, GPT-4, GPT-4o, LaMDA, LLaMA, BLOOM, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks. Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\nIn addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs. Examples include OpenAI Codex, Tabnine, GitHub Copilot, Microsoft Copilot, and VS Code fork Cursor.\nSome AI assistants help candidates cheat during online coding interviews by providing code, improvements, and explanations. Their clandestine interfaces minimize the need for eye movements that would expose cheating to the interviewer.\n\n\n=== Images ===\n\nProducing high-quality visual art is a prominent application of generative AI. Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, FLUX.1, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer. Datasets include LAION-5B and others (see List of datasets in computer vision and image processing). \n\n\n=== Audio ===\n\nGenerative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities. An early pioneer in this field was 15.ai, launched in March 2020, which demonstrated the ability to clone character voices using as little as 15 seconds of training data. The website gained widespread attention for its ability to generate emotionally expressive speech for various fictional characters, though it was later taken offline in 2022 due to copyright concerns. Commercial alternatives subsequently emerged, including ElevenLabs' context-aware synthesis tools and Meta Platform's Voicebox.\nGenerative AI systems such as MusicLM and MusicGen can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\nAudio deepfakes of music lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z's vocals. Music artist's instrumentals and lyrics are copyrighted but their voices are not protected from regenerative AI yet, raising a debate about whether artists should get royalties from audio deepfakes.\nMany AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.\n\n\n=== Video ===\n\nGenerative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI, Runway, and Make-A-Video by Meta Platforms.", "mimetype": "text/plain", "start_char_idx": 7918, "end_char_idx": 12930, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6b187125-22ec-4c42-abab-67e0d206092d": {"__data__": {"id_": "6b187125-22ec-4c42-abab-67e0d206092d", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "788240d0-bb49-4a6e-a0cf-ddbdc62f8765", "node_type": "1", "metadata": {}, "hash": "e1a4fed407a0d7309d43684f1a3e0bbf3f61118ccb058696cc966f802e9d5e7c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33307083-a862-47c2-9027-c3ac9f843895", "node_type": "1", "metadata": {}, "hash": "e31d163e261ff502e3524111b74e4a4835d7e47d52a5bb1e7bbc0b9b33d333a8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Video ===\n\nGenerative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI, Runway, and Make-A-Video by Meta Platforms.\n\n\n=== Robotics ===\nGenerative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm. Multimodal \"vision-language-action\" models such as Google's RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.\n\n\n=== 3D modeling ===\n\nArtificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling. AI-based CAD libraries could also be developed using linked open data of schematics and diagrams. AI CAD assistants are used as tools to help streamline workflow.\n\n\n== Software and hardware ==\n\nGenerative AI models are used to power chatbot products such as ChatGPT, programming tools such as GitHub Copilot, text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2. Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office (Microsoft Copilot), Google Photos, and the Adobe Suite (Adobe Firefly). Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA language model.\nSmaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4 and one version of Stable Diffusion can run on an iPhone 11.\nLarger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.\nThe advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks. Yann LeCun has advocated open-source models for their value to vertical applications and for improving AI safety.\nLanguage models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA's H100) or AI accelerator chips (such as Google's TPU). These very large models are typically accessed as cloud services over the Internet.\nIn 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI. Chips such as the NVIDIA A800 and the Biren Technology BR104 were developed to meet the requirements of the sanctions.\nThere is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it. Potential mitigation strategies for detecting generative AI content include digital watermarking, content authentication, information retrieval, and machine learning classifier models. Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.\n\n\n=== Generative models and training techniques ===\n\n\n==== Generative adversarial networks ====\n\nGenerative adversarial networks (GANs) are an influential generative modeling technique. GANs consist of two neural networks\u2014the generator and the discriminator\u2014trained simultaneously in a competitive setting. The generator creates synthetic data by transforming random noise into samples that resemble the training dataset. The discriminator is trained to distinguish the authentic data from synthetic data produced by the generator. The two models engage in a minimax game: the generator aims to create increasingly realistic data to \"fool\" the discriminator, while the discriminator improves its ability to distinguish real from fake data. This continuous training setup enables the generator to produce high-quality and realistic outputs.", "mimetype": "text/plain", "start_char_idx": 12723, "end_char_idx": 17528, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "33307083-a862-47c2-9027-c3ac9f843895": {"__data__": {"id_": "33307083-a862-47c2-9027-c3ac9f843895", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b187125-22ec-4c42-abab-67e0d206092d", "node_type": "1", "metadata": {}, "hash": "55939be9f839810e5fbc5546e629fb1c0b805c871c49519397c7d5ef9b1fd81d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c533f28-97f1-420b-896d-bd0b9afe0478", "node_type": "1", "metadata": {}, "hash": "5ad3f3ea3afed8fc9afd41ff4479a116b908505c21ceba04a371603a9f85f912", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Generative models and training techniques ===\n\n\n==== Generative adversarial networks ====\n\nGenerative adversarial networks (GANs) are an influential generative modeling technique. GANs consist of two neural networks\u2014the generator and the discriminator\u2014trained simultaneously in a competitive setting. The generator creates synthetic data by transforming random noise into samples that resemble the training dataset. The discriminator is trained to distinguish the authentic data from synthetic data produced by the generator. The two models engage in a minimax game: the generator aims to create increasingly realistic data to \"fool\" the discriminator, while the discriminator improves its ability to distinguish real from fake data. This continuous training setup enables the generator to produce high-quality and realistic outputs.\n\n\n==== Variational autoencoders ====\n\nVariational autoencoders (VAEs) are deep learning models that probabilistically encode data. They are typically used for tasks such as noise reduction from images, data compression, identifying unusual patterns, and facial recognition. Unlike standard autoencoders, which compress input data into a fixed latent representation, VAEs model the latent space as a probability distribution, allowing for smooth sampling and interpolation between data points. The encoder (\"recognition model\") maps input data to a latent space, producing means and variances that define a probability distribution. The decoder (\"generative model\") samples from this latent distribution and attempts to reconstruct the original input. VAEs optimize a loss function that includes both the reconstruction error and a Kullback\u2013Leibler divergence term, which ensures the latent space follows a known prior distribution. VAEs are particularly suitable for tasks that require structured but smooth latent spaces, although they may create blurrier images than GANs. They are used for applications like image generation, data interpolation and anomaly detection.\n\n\n===== Transformers =====\nTransformers became the foundation for many powerful generative models, most notably the generative pre-trained transformer (GPT) series developed by OpenAI. They marked a major shift in natural language processing by replacing traditional recurrent and convolutional models. This architecture allows models to process entire sequences simultaneously and capture long-range dependencies more efficiently. The self-attention mechanism enables the model to capture the significance of every word in a sequence when predicting the subsequent word, thus improving its contextual understanding. Unlike recurrent neural networks, transformers process all the tokens in parallel, which improves the training efficiency and scalability. Transformers are typically pre-trained on enormous corpora in a self-supervised manner, prior to being fine-tuned.\n\n\n== Law and regulation ==\n\nIn the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the Biden administration in July 2023 to watermark AI-generated content. In October 2023, Executive Order 14110 applied the Defense Production Act to require all US companies to report information to the federal government when training certain high-impact AI models.\nIn the European Union, the proposed Artificial Intelligence Act includes requirements to disclose copyrighted material used to train generative AI systems, and to label any AI-generated output as such.\nIn China, the Interim Measures for the Management of Generative AI Services introduced by the Cyberspace Administration of China regulates any public-facing generative AI. It includes requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI must \"adhere to socialist core values\".\n\n\n=== Copyright ===\n\n\n==== Training with copyrighted content ====\nGenerative AI systems such as ChatGPT and Midjourney are trained on large, publicly available datasets that include copyrighted works. AI developers have argued that such training is protected under fair use, while copyright holders have argued that it infringes their rights.\nProponents of fair use training have argued that it is a transformative use and does not involve making copies of copyrighted works available to the public. Critics have argued that image generators such as Midjourney can create nearly-identical copies of some copyrighted images, and that generative AI programs compete with the content they are trained on.\nAs of 2024, several lawsuits related to the use of copyrighted material in training are ongoing.\nGetty Images has sued Stability AI over the use of its images to train Stable Diffusion. Both the Authors Guild and The New York Times have sued Microsoft and OpenAI over the use of their works to train ChatGPT.", "mimetype": "text/plain", "start_char_idx": 16691, "end_char_idx": 21596, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9c533f28-97f1-420b-896d-bd0b9afe0478": {"__data__": {"id_": "9c533f28-97f1-420b-896d-bd0b9afe0478", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "33307083-a862-47c2-9027-c3ac9f843895", "node_type": "1", "metadata": {}, "hash": "e31d163e261ff502e3524111b74e4a4835d7e47d52a5bb1e7bbc0b9b33d333a8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e0d19347-bbbd-4dc5-b34c-09ba3749b867", "node_type": "1", "metadata": {}, "hash": "1d324771060f7aae8cdf54717004214d49046ce69bdc1bc7c465ebccbe70416c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Copyright ===\n\n\n==== Training with copyrighted content ====\nGenerative AI systems such as ChatGPT and Midjourney are trained on large, publicly available datasets that include copyrighted works. AI developers have argued that such training is protected under fair use, while copyright holders have argued that it infringes their rights.\nProponents of fair use training have argued that it is a transformative use and does not involve making copies of copyrighted works available to the public. Critics have argued that image generators such as Midjourney can create nearly-identical copies of some copyrighted images, and that generative AI programs compete with the content they are trained on.\nAs of 2024, several lawsuits related to the use of copyrighted material in training are ongoing.\nGetty Images has sued Stability AI over the use of its images to train Stable Diffusion. Both the Authors Guild and The New York Times have sued Microsoft and OpenAI over the use of their works to train ChatGPT.\n\n\n==== Copyright of AI-generated content ====\nA separate question is whether AI-generated works can qualify for copyright protection. The United States Copyright Office has ruled that works created by artificial intelligence without any human input cannot be copyrighted, because they lack human authorship. Some legal professionals have suggested that Naruto v. Slater (2018), in which the U.S. 9th Circuit Court of Appeals held that non-humans cannot be copyright holders of artistic works, could be a potential precedent in copyright litigation over works created by generative AI. However, the office has also begun taking public input to determine if these rules need to be refined for generative AI.\nIn January 2025, the Copyright Office released extensive guidance regarding the use of AI tools in the creative process, and established that \"...generative AI systems also offer tools that similarly allow users to exert control. [These] can enable the user to control the selection and placement of individual creative elements. Whether such modifications rise to the minimum standard of originality required under Feist will depend on a case-by-case determination. In those cases where they do, the output should be copyrightable\" Subsequently, the Copyright Office registered the first visual artwork to be composed of entirely AI-generated materials, titled \"A Single Piece of American Cheese\".  \n\n\n== Concerns ==\n\nThe development of generative AI has raised concerns from governments, businesses, and individuals, resulting in protests, legal actions, calls to pause AI experiments, and actions by multiple governments. In a July 2023 briefing of the United Nations Security Council, Secretary-General Ant\u00f3nio Guterres stated \"Generative AI has enormous potential for good and evil at scale\", that AI may \"turbocharge global development\" and contribute between $10 and $15 trillion to the global economy by 2030, but that its malicious use \"could cause horrific levels of death and destruction, widespread trauma, and deep psychological damage on an unimaginable scale\". In addition, generative AI has a significant carbon footprint.\n\n\n=== Job losses ===\n\nFrom the early days of the development of AI, there have been arguments put forward by ELIZA creator Joseph Weizenbaum and others about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculations and qualitative, value-based judgements. In April 2023, it was reported that image generation AI has resulted in 70% of the jobs for video game illustrators in China being lost. In July 2023, developments in generative AI contributed to the 2023 Hollywood labor disputes. Fran Drescher, president of the Screen Actors Guild, declared that \"artificial intelligence poses an existential threat to creative professions\" during the 2023 SAG-AFTRA strike. Voice generation AI has been seen as a potential challenge to the voice acting sector.\nThe intersection of AI and employment concerns among underrepresented groups globally remains a critical facet. While AI promises efficiency enhancements and skill acquisition, concerns about job displacement and biased recruiting processes persist among these groups, as outlined in surveys by Fast Company. To leverage AI for a more equitable society, proactive steps encompass mitigating biases, advocating transparency, respecting privacy and consent, and embracing diverse teams and ethical considerations. Strategies involve redirecting policy emphasis on regulation, inclusive design, and education's potential for personalized teaching to maximize benefits while minimizing harms.\n\n\n=== Racial and gender bias ===\nGenerative AI models can reflect and amplify any cultural bias present in the underlying data. For example, a language model might assume that doctors and judges are male, and that secretaries or nurses are female, if those biases are common in the training data. Similarly, an image model prompted with the text \"a photo of a CEO\" might disproportionately generate images of white male CEOs, if trained on a racially biased data set. A number of methods for mitigating bias have been attempted, such as altering input prompts and reweighting training data.", "mimetype": "text/plain", "start_char_idx": 20588, "end_char_idx": 25883, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e0d19347-bbbd-4dc5-b34c-09ba3749b867": {"__data__": {"id_": "e0d19347-bbbd-4dc5-b34c-09ba3749b867", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c533f28-97f1-420b-896d-bd0b9afe0478", "node_type": "1", "metadata": {}, "hash": "5ad3f3ea3afed8fc9afd41ff4479a116b908505c21ceba04a371603a9f85f912", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "06d37da8-2020-4c50-856a-58f4c4595575", "node_type": "1", "metadata": {}, "hash": "4b5a686ed62ef6dd34fc7483b359f868e3289a3c7409d2128fa8d840a6ee4dc3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Racial and gender bias ===\nGenerative AI models can reflect and amplify any cultural bias present in the underlying data. For example, a language model might assume that doctors and judges are male, and that secretaries or nurses are female, if those biases are common in the training data. Similarly, an image model prompted with the text \"a photo of a CEO\" might disproportionately generate images of white male CEOs, if trained on a racially biased data set. A number of methods for mitigating bias have been attempted, such as altering input prompts and reweighting training data.\n\n\n=== Deepfakes ===\n\nDeepfakes (a portmanteau of \"deep learning\" and \"fake\") are AI-generated media that take a person in an existing image or video and replace them with someone else's likeness using artificial neural networks. Deepfakes have garnered widespread attention and concerns for their uses in deepfake celebrity pornographic videos, revenge porn, fake news, hoaxes, health disinformation, financial fraud, and covert foreign election interference. This has elicited responses from both industry and government to detect and limit their use.\nIn July 2023, the fact-checking company Logically found that the popular generative AI models Midjourney, DALL-E 2 and Stable Diffusion would produce plausible disinformation images when prompted to do so, such as images of electoral fraud in the United States and Muslim women supporting India's Hindu nationalist Bharatiya Janata Party.\nIn April 2024, a paper proposed to use blockchain (distributed ledger technology) to promote \"transparency, verifiability, and decentralization in AI development and usage\".\n\n\n==== Audio deepfakes ====\n\nInstances of users abusing software to generate controversial statements in the vocal style of celebrities, public officials, and other famous individuals have raised ethical concerns over voice generation AI. In response, companies such as ElevenLabs have stated that they would work on mitigating potential abuse through safeguards and identity verification.\nConcerns and fandoms have spawned from AI-generated music. The same software used to clone voices has been used on famous musicians' voices to create songs that mimic their voices, gaining both tremendous popularity and criticism. Similar techniques have also been used to create improved quality or full-length versions of songs that have been leaked or have yet to be released.\nGenerative AI has also been used to create new digital artist personalities, with some of these receiving enough attention to receive record deals at major labels. The developers of these virtual artists have also faced their fair share of criticism for their personified programs, including backlash for \"dehumanizing\" an artform, and also creating artists which create unrealistic or immoral appeals to their audiences.\n\n\n=== Illegal content ===\n\nMany websites that allow explicit AI generated images or videos have been created, and this has been used to create illegal content, such as rape, child sexual abuse material, necrophilia, and zoophilia. \n\n\n=== Cybercrime ===\nGenerative AI's ability to create realistic fake content has been exploited in numerous types of cybercrime, including phishing scams. Deepfake video and audio have been used to create disinformation and fraud. In 2020, former Google click fraud czar Shuman Ghosemajumder argued that once deepfake videos become perfectly realistic, they would stop appearing remarkable to viewers, potentially leading to uncritical acceptance of false information. Additionally, large language models and other forms of text-generation AI have been used to create fake reviews of e-commerce websites to boost ratings. Cybercriminals have created large language models focused on fraud, including WormGPT and FraudGPT. \nA 2023 study showed that generative AI can be vulnerable to jailbreaks, reverse psychology and prompt injection attacks, enabling attackers to obtain help with harmful requests, such as for crafting social engineering and phishing attacks. Additionally, other researchers have demonstrated that open-source models can be fine-tuned to remove their safety restrictions at low cost.\n\n\n=== Reliance on industry giants ===\nTraining frontier AI models requires an enormous amount of computing power. Usually only Big Tech companies have the financial resources to make such investments. Smaller start-ups such as Cohere and OpenAI end up buying access to data centers from Google and Microsoft respectively.", "mimetype": "text/plain", "start_char_idx": 25295, "end_char_idx": 29800, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "06d37da8-2020-4c50-856a-58f4c4595575": {"__data__": {"id_": "06d37da8-2020-4c50-856a-58f4c4595575", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e0d19347-bbbd-4dc5-b34c-09ba3749b867", "node_type": "1", "metadata": {}, "hash": "1d324771060f7aae8cdf54717004214d49046ce69bdc1bc7c465ebccbe70416c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "52812ff0-f0bc-482c-b06e-f5998df25a36", "node_type": "1", "metadata": {}, "hash": "60f9f841f52af37ef3042177dfd0a0dc1b9e139e0a133bb3eaeb237ddaf96833", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Reliance on industry giants ===\nTraining frontier AI models requires an enormous amount of computing power. Usually only Big Tech companies have the financial resources to make such investments. Smaller start-ups such as Cohere and OpenAI end up buying access to data centers from Google and Microsoft respectively.\n\n\n=== Energy and environment ===\n\nAI has a significant carbon footprint due to growing energy consumption from both training and usage. Scientists and journalists have expressed concerns about the environmental impact that the development and deployment of generative models are having: high CO2 emissions, large amounts of freshwater used for data centers, and high amounts of electricity usage. There is also concern that these impacts may increase as these models are incorporated into widely used search engines such as Google Search and Bing, as chatbots and other applications become more popular, and as models need to be retrained.\nProposed mitigation strategies include factoring potential environmental costs prior to model development or data collection, increasing efficiency of data centers to reduce electricity/energy usage, building more efficient machine learning models, minimizing the number of times that models need to be retrained, developing a government-directed framework for auditing the environmental impact of these models, regulating for transparency of these models, regulating their energy and water usage, encouraging researchers to publish data on their models' carbon footprint, and increasing the number of subject matter experts who understand both machine learning and climate science.\n\n\n=== Content quality ===\n\nThe New York Times defines slop as analogous to spam: \"shoddy or unwanted A.I. content in social media, art, books and ... in search results.\" Journalists have expressed concerns about the scale of low-quality generated content with respect to social media content moderation, the monetary incentives from social media companies to spread such content, false political messaging, spamming of scientific research paper submissions, increased time and effort to find higher quality or desired content on the Internet, the indexing of generated content by search engines, and on journalism itself.\nA paper published by researchers at Amazon Web Services AI Labs found that over 57% of sentences from a sample of over 6 billion sentences from Common Crawl, a snapshot of web pages, were machine translated. Many of these automated translations were seen as lower quality, especially for sentences that were translated across at least three languages. Many lower-resource languages (ex. Wolof, Xhosa) were translated across more languages than higher-resource languages (ex. English, French).\nIn September 2024, Robyn Speer, the author of wordfreq, an open source database that calculated word frequencies based on text from the Internet, announced that she had stopped updating the data for several reasons: high costs for obtaining data from Reddit and Twitter, excessive focus on generative AI compared to other methods in the natural language processing community, and that \"generative AI has polluted the data\".\nThe adoption of generative AI tools led to an explosion of AI-generated content across multiple domains. A study from University College London estimated that in 2023, more than 60,000 scholarly articles\u2014over 1% of all publications\u2014were likely written with LLM assistance. According to Stanford University's Institute for Human-Centered AI, approximately 17.5% of newly published computer science papers and 16.9% of peer review text now incorporate content generated by LLMs. Many academic disciplines have concerns about the factual reliably of academic content generated by AI.\nVisual content follows a similar trend. Since the launch of DALL-E 2 in 2022, it is estimated that an average of 34 million images have been created daily. As of August 2023, more than 15 billion images had been generated using text-to-image algorithms, with 80% of these created by models based on Stable Diffusion.\nIf AI-generated content is included in new data crawls from the Internet for additional training of AI models, defects in the resulting models may occur. Training an AI model exclusively on the output of another AI model produces a lower-quality model. Repeating this process, where each new model is trained on the previous model's output, leads to progressive degradation and eventually results in a \"model collapse\" after multiple iterations. Tests have been conducted with pattern recognition of handwritten letters and with pictures of human faces. As a consequence, the value of data collected from genuine human interactions with systems may become increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.\nOn the other side, synthetic data is often used as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy, including for structured data. The approach is not limited to text generation; image generation has been employed to train computer vision models.", "mimetype": "text/plain", "start_char_idx": 29481, "end_char_idx": 34692, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "52812ff0-f0bc-482c-b06e-f5998df25a36": {"__data__": {"id_": "52812ff0-f0bc-482c-b06e-f5998df25a36", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "06d37da8-2020-4c50-856a-58f4c4595575", "node_type": "1", "metadata": {}, "hash": "4b5a686ed62ef6dd34fc7483b359f868e3289a3c7409d2128fa8d840a6ee4dc3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "96028078-62c0-460a-b467-10ce5140dee0", "node_type": "1", "metadata": {}, "hash": "0ce24842ce22970e81ec5df3c6284e30d02abfdf0c6c0448967f834e862324ea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Misuse in journalism ===\n\nIn January 2023, Futurism.com broke the story that CNET had been using an undisclosed internal AI tool to write at least 77 of its stories; after the news broke, CNET posted corrections to 41 of the stories.\nIn April 2023, the German tabloid Die Aktuelle published a fake AI-generated interview with former racing driver Michael Schumacher, who had not made any public appearances since 2013 after sustaining a brain injury in a skiing accident. The story included two possible disclosures: the cover included the line \"deceptively real\", and the interview included an acknowledgment at the end that it was AI-generated. The editor-in-chief was fired shortly thereafter amid the controversy.\nOther outlets that have published articles whose content or byline have been confirmed or suspected to be created by generative AI models \u2013 often with false content, errors, or non-disclosure of generative AI use \u2013 include:\n\nIn May 2024, Futurism noted that a content management system video by AdVon Commerce, who had used generative AI to produce articles for many of the aforementioned outlets, appeared to show that they \"had produced tens of thousands of articles for more than 150 publishers.\"\nNews broadcasters in Kuwait, Greece, South Korea, India, China and Taiwan have presented news with anchors based on Generative AI models, prompting concerns about job losses for human anchors and audience trust in news that has historically been influenced by parasocial relationships with broadcasters, content creators or social media influencers. Algorithmically generated anchors have also been used by allies of ISIS for their broadcasts.\nIn 2023, Google reportedly pitched a tool to news outlets that claimed to \"produce news stories\" based on input data provided, such as \"details of current events\". Some news company executives who viewed the pitch described it as \"[taking] for granted the effort that went into producing accurate and artful news stories.\"\nIn February 2024, Google launched a program to pay small publishers to write three articles per day using a beta generative AI model. The program does not require the knowledge or consent of the websites that the publishers are using as sources, nor does it require the published articles to be labeled as being created or assisted by these models.\nMany defunct news sites (The Hairpin, The Frisky, Apple Daily, Ashland Daily Tidings, Clayton County Register, Southwest Journal) and blogs (The Unofficial Apple Weblog, iLounge) have undergone cybersquatting, with articles created by generative AI.\nUnited States Senators Richard Blumenthal and Amy Klobuchar have expressed concern that generative AI could have a harmful impact on local news. In July 2023, OpenAI partnered with the American Journalism Project to fund local news outlets for experimenting with generative AI, with Axios noting the possibility of generative AI companies creating a dependency for these news outlets.\nMeta AI, a chatbot based on Llama 3 which summarizes news stories, was noted by The Washington Post to copy sentences from those stories without direct attribution and to potentially further decrease the traffic of online news outlets.\nIn response to potential pitfalls around the use and misuse of generative AI in journalism and worries about declining audience trust, outlets around the world, including publications such as Wired, Associated Press, The Quint, Rappler or The Guardian have published guidelines around how they plan to use and not use AI and generative AI in their work.\nIn June 2024, Reuters Institute published their Digital News Report for 2024. In a survey of people in America and Europe, Reuters Institute reports that 52% and 47% respectively are uncomfortable with news produced by \"mostly AI with some human oversight\", and 23% and 15% respectively report being comfortable. 42% of Americans and 33% of Europeans reported that they were comfortable with news produced by \"mainly human with some help from AI\". The results of global surveys reported that people were more uncomfortable with news topics including politics (46%), crime (43%), and local news (37%) produced by AI than other news topics.\n\n\n== See also ==\n\nArtificial general intelligence \u2013 Type of AI with wide-ranging abilities\nArtificial imagination \u2013 Artificial simulation of human imagination\nArtificial intelligence art \u2013 Visual media created with AI\nArtificial life \u2013 Field of study\nChatbot \u2013 Program that simulates conversation\nComputational creativity \u2013 Multidisciplinary endeavour\nGenerative adversarial network \u2013 Deep learning method\nGenerative pre-trained transformer \u2013 Type of large language model\nLarge language model \u2013 Type of machine learning model\nMusic and artificial intelligence \u2013 Usage of artificial intelligence to generate music\nGenerative AI pornography \u2013 Explicit material produced by generative AI\nProcedural generation \u2013 Method in which data is created algorithmically as opposed to manually\nRetrieval-augmented generation \u2013 Type of information retrieval using LLMs\nStochastic parrot \u2013 Term used in machine learning\n\n\n== References ==", "mimetype": "text/plain", "start_char_idx": 34695, "end_char_idx": 39819, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "96028078-62c0-460a-b467-10ce5140dee0": {"__data__": {"id_": "96028078-62c0-460a-b467-10ce5140dee0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73291755", "node_type": "4", "metadata": {}, "hash": "d0e4179388311d0b9b40e0003fac3694bd4aeaff1770bfa32b4af397e2a58740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "52812ff0-f0bc-482c-b06e-f5998df25a36", "node_type": "1", "metadata": {}, "hash": "60f9f841f52af37ef3042177dfd0a0dc1b9e139e0a133bb3eaeb237ddaf96833", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== See also ==\n\nArtificial general intelligence \u2013 Type of AI with wide-ranging abilities\nArtificial imagination \u2013 Artificial simulation of human imagination\nArtificial intelligence art \u2013 Visual media created with AI\nArtificial life \u2013 Field of study\nChatbot \u2013 Program that simulates conversation\nComputational creativity \u2013 Multidisciplinary endeavour\nGenerative adversarial network \u2013 Deep learning method\nGenerative pre-trained transformer \u2013 Type of large language model\nLarge language model \u2013 Type of machine learning model\nMusic and artificial intelligence \u2013 Usage of artificial intelligence to generate music\nGenerative AI pornography \u2013 Explicit material produced by generative AI\nProcedural generation \u2013 Method in which data is created algorithmically as opposed to manually\nRetrieval-augmented generation \u2013 Type of information retrieval using LLMs\nStochastic parrot \u2013 Term used in machine learning\n\n\n== References ==\n\n\n== Further reading ==\nHe, Ran; Cao, Jie; Tan, Tieniu (2025). \"Generative Artificial Intelligence: A Historical Perspective\". National Science Review. 12 (5): nwaf050. doi:10.1093/nsr/nwaf050. PMC 11970245. PMID 40191253.", "mimetype": "text/plain", "start_char_idx": 38899, "end_char_idx": 40042, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "957102fc-ecb3-4c77-b017-b0c6a13b209e": {"__data__": {"id_": "957102fc-ecb3-4c77-b017-b0c6a13b209e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4a4b6e99-211c-48d2-9523-4aa420d8a709", "node_type": "1", "metadata": {}, "hash": "f982611ed8a9f5198fa9fbe17f914dcd51a772437f089cfe86468f142c22d4be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text.\nThe largest and most capable LLMs are generative pretrained transformers (GPTs). Modern models can be fine-tuned for specific tasks or guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.\n\n\n== History ==\n\nBefore 2017, there were a few language models that were large as compared to capacities then available. In the 1990s, the IBM alignment models pioneered statistical language modelling. A smoothed n-gram model in 2001 trained on 0.3 billion words achieved state-of-the-art perplexity at the time. In the 2000s, as Internet use became prevalent, some researchers constructed Internet-scale language datasets (\"web as corpus\"), upon which they trained statistical language models. In 2009, in most language processing tasks, statistical language models dominated over symbolic language models because they can usefully ingest large datasets.\n\nAfter neural networks became dominant in image processing around 2012, they were applied to language modelling as well. Google converted its translation service to Neural Machine Translation in 2016. Because it preceded the existence of transformers, it was done by seq2seq deep LSTM networks.\nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper's goal was to improve upon 2014 seq2seq technology, and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014. The following year in 2018, BERT was introduced and quickly became \"ubiquitous\". Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model. Academic and research usage of BERT began to decline in 2023, following rapid improvements in the abilities of decoder-only models (such as GPT) to solve tasks via prompting.\nAlthough decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI at first deemed it too powerful to release publicly, out of fear of malicious use. GPT-3 in 2020 went a step further and as of 2024 is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based ChatGPT that captured the imaginations of the general population and caused some media hype and online buzz. The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities. OpenAI did not reveal the high-level architecture and the number of parameters of GPT-4. The release of ChatGPT led to an uptick in LLM usage across several research subfields of computer science, including robotics, software engineering, and societal impact work. In 2024 OpenAI released the reasoning model OpenAI o1, which generates long chains of thought before returning a final answer.\nCompeting language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.\nSince 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI's models Mistral 7B and Mixtral 8x7b have the more permissive Apache License. In January 2025, DeepSeek released DeepSeek R1, a 671-billion-parameter open-weight model that performs comparably to OpenAI o1 but at a much lower cost.\nSince 2023, many LLMs have been trained to be multimodal, having the ability to also process or generate other types of data, such as images or audio. These LLMs are also called large multimodal models (LMMs).\nAs of 2024, the largest and most capable models are all based on the transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).\n\n\n== Dataset preprocessing ==", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4237, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4a4b6e99-211c-48d2-9523-4aa420d8a709": {"__data__": {"id_": "4a4b6e99-211c-48d2-9523-4aa420d8a709", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "957102fc-ecb3-4c77-b017-b0c6a13b209e", "node_type": "1", "metadata": {}, "hash": "567f9912e9e740140719ce8bb87d5ace632b029f8e2746d0495036b7cb6f3e37", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8b6b633-9068-4a77-8156-9a3dc2198948", "node_type": "1", "metadata": {}, "hash": "4681df97e18a954222e5ef855bf62b3c97545ee5fe522669cf327a5b6722dbb4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Dataset preprocessing ==\n\n\n=== Tokenization ===\n\nAs machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include byte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters, such as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"\u0120\" denotes a preceding whitespace in RoBERTa and GPT. \"##\" denotes continuation of a preceding word in BERT.\nFor example, the BPE tokenizer used by GPT-3 (Legacy) would split tokenizer: texts -> series of numerical \"tokens\" as\n\nTokenization also compresses the datasets. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. How many tokens are, on average, needed per word depends on the language of the dataset.\n\n\n==== BPE ====\n\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary of prescribed size is obtained (in case of GPT-3, the size is 50257). After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.\n\n\n==== Problems ====\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. However, an average word in another language encoded by such an English-optimized tokenizer is split into a suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the Shan language from Myanmar. Even more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to English.\nGreedy tokenization also causes subtle problems with text completion.\n\n\n=== Dataset cleaning ===\n\nIn the context of training LLMs, datasets are typically cleaned by removing low-quality, duplicated, or toxic data. Cleaned datasets can increase training efficiency and lead to improved downstream performance. A trained LLM can be used to clean datasets for training a further LLM.\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).\n\n\n=== Synthetic data ===\n\nTraining of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft's Phi series of LLMs is trained on textbook-like data generated by another LLM.\n\n\n== Training and architecture ==\n\n\n=== Reinforcement learning from human feedback ===\nReinforcement learning from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.\n\n\n=== Instruction tuning ===\nUsing \"self-instruct\" approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases. For example, in the instruction \"Write an essay about the main themes represented in Hamlet,\" an initial naive completion might be \"If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay,\" based on the frequency of this textual sequence in the corpus.\n\n\n=== Mixture of experts ===\n\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.", "mimetype": "text/plain", "start_char_idx": 4210, "end_char_idx": 8758, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8b6b633-9068-4a77-8156-9a3dc2198948": {"__data__": {"id_": "d8b6b633-9068-4a77-8156-9a3dc2198948", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a4b6e99-211c-48d2-9523-4aa420d8a709", "node_type": "1", "metadata": {}, "hash": "f982611ed8a9f5198fa9fbe17f914dcd51a772437f089cfe86468f142c22d4be", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e94da11d-2325-4e76-a929-1b5304970b03", "node_type": "1", "metadata": {}, "hash": "6f2bb1f4452feca33652515c52152a74cef27b5797ec01d613fa5e334e849b40", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Instruction tuning ===\nUsing \"self-instruct\" approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases. For example, in the instruction \"Write an essay about the main themes represented in Hamlet,\" an initial naive completion might be \"If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay,\" based on the frequency of this textual sequence in the corpus.\n\n\n=== Mixture of experts ===\n\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.\n\n\n=== Prompt engineering, attention mechanism, and context window ===\n\nMost results previously achievable only by (costly) fine-tuning, can be achieved through prompt engineering, although limited to the scope of a single conversation (more precisely, limited to the scope of a context window).\n\nIn order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model has had twelve attention heads and a context window of only 1k tokens. In its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.\nThe largest models, such as Google's Gemini 1.5, presented in February 2024, can have a context window sized up to 1 million (context window of 10 million was also \"successfully tested\"). Other models with large context windows includes Anthropic's Claude 2.1, with a context window of up to 200k tokens. Note that this maximum refers to the number of input tokens and that the maximum number of output tokens differs from the input and is often smaller. For example, the GPT-4 Turbo model has a maximum output of 4096 tokens.\nLength of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well. If the length of a conversation, for example with ChatGPT, is longer than its context window, only the parts inside the context window are taken into account when generating the next answer, or the model needs to apply some algorithm to summarize the too distant parts of conversation.\nThe shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them is a matter of experimentation and domain-specific considerations.\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset. It can be either\n\nautoregressive (i.e. predicting how the segment continues, as GPTs do): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\n\"masked\" (i.e. filling in the parts missing from the segment, the way \"BERT\" does it): for example, given a segment \"I like to [__] [__] cream\", the model predicts that \"eat\" and \"ice\" are missing.\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus. During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\n\n\n=== Infrastructure ===\nSubstantial infrastructure is necessary for training the largest models.", "mimetype": "text/plain", "start_char_idx": 7998, "end_char_idx": 11969, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e94da11d-2325-4e76-a929-1b5304970b03": {"__data__": {"id_": "e94da11d-2325-4e76-a929-1b5304970b03", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8b6b633-9068-4a77-8156-9a3dc2198948", "node_type": "1", "metadata": {}, "hash": "4681df97e18a954222e5ef855bf62b3c97545ee5fe522669cf327a5b6722dbb4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8061e96d-1391-44f8-b8d4-de22afa68c44", "node_type": "1", "metadata": {}, "hash": "80fc91df66398f4b7ba4cfa6efffb01c3791a955a55fd0b483c341d3e0278b5a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Infrastructure ===\nSubstantial infrastructure is necessary for training the largest models.\n\n\n== Training cost ==\n\nThe qualifier \"large\" in \"large language model\" is inherently vague, as there is no definitive threshold for the number of parameters required to qualify as \"large\". As time goes on, what was previously considered \"large\" may evolve. GPT-1 of 2018 is usually considered the first LLM, even though it has only 0.117 billion parameters. The tendency towards larger models is visible in the list of large language models.\nAs technology advanced, large sums have been invested in increasingly large models. For example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the PaLM (i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million.\nFor Transformer-based LLM, training cost is much higher than inference cost. It costs 6 FLOPs per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.\n\n\n== Tool use ==\nThere are certain tasks that, in principle, cannot be solved by any LLM, at least not without the use of external tools or additional software. An example of such a task is responding to the user's input '354 * 139 = ', provided that the LLM has not already encountered a continuation of this calculation in its training corpus. In such cases, the LLM needs to resort to running program code that calculates the result, which can then be included in its response.: Another example is \"What is the time now? It is \", where a separate program interpreter would need to execute a code to get system time on the computer, so that the LLM can include it in its reply. This basic strategy can be sophisticated with multiple attempts of generated programs, and other sampling strategies.\nGenerally, in order to get an LLM to use tools, one must fine-tune it for tool-use. If the number of tools is finite, then fine-tuning may be done just once. If the number of tools can grow arbitrarily, as with online API services, then the LLM can be fine-tuned to be able to read API documentation and call API correctly.\nRetrieval-augmented generation (RAG) is another approach that enhances LLMs by integrating them with document retrieval systems. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a vector database) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.", "mimetype": "text/plain", "start_char_idx": 11874, "end_char_idx": 14582, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8061e96d-1391-44f8-b8d4-de22afa68c44": {"__data__": {"id_": "8061e96d-1391-44f8-b8d4-de22afa68c44", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e94da11d-2325-4e76-a929-1b5304970b03", "node_type": "1", "metadata": {}, "hash": "6f2bb1f4452feca33652515c52152a74cef27b5797ec01d613fa5e334e849b40", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bc1354c6-c026-47db-99ef-24ee0bd02244", "node_type": "1", "metadata": {}, "hash": "a6b5f2d2d2d336e2878ead8872c695df9b2a30caf13fdb589d22fff57fb8f859", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Agency ==\nAn LLM is typically not an autonomous agent by itself, as it lacks the ability to interact with dynamic environments, recall past behaviors, and plan future actions, but can be transformed into one by integrating modules like profiling, memory, planning, and action.\nThe ReAct pattern, a portmanteau of \"Reason + Act\", constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment. The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.\nIn the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions, then it is prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.\nThe Reflexion method constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are given to the agent in the subsequent episodes.\nMonte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.\nFor open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent. Alternatively, it can propose increasingly difficult tasks for curriculum learning. Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.\nLLM-powered agents can keep a long-term memory of its previous contexts, and the memory can be retrieved in the same way as Retrieval Augmented Generation. Multiple such agents can interact socially.\n\n\n== Compression ==\n\nTypically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have 100 billion parameters, requiring 200 gigabytes to load, which places them outside the range of most consumer electronics.\nPost-training quantization aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance. The simplest form of quantization simply truncates all numbers to a given number of bits. It can be improved by using a different quantization codebook per layer. Further improvement can be done by applying different precisions to different parameters, with higher precision for particularly important parameters (\"outlier weights\"). See the visual guide to quantization by Maarten Grootendorst for a visual depiction.\nWhile quantized models are typically frozen, and only pre-quantized models are fine-tuned, quantized models can still be fine-tuned.", "mimetype": "text/plain", "start_char_idx": 14585, "end_char_idx": 18040, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bc1354c6-c026-47db-99ef-24ee0bd02244": {"__data__": {"id_": "bc1354c6-c026-47db-99ef-24ee0bd02244", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8061e96d-1391-44f8-b8d4-de22afa68c44", "node_type": "1", "metadata": {}, "hash": "80fc91df66398f4b7ba4cfa6efffb01c3791a955a55fd0b483c341d3e0278b5a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ef8185ca-1b6c-42af-a491-c91870195d07", "node_type": "1", "metadata": {}, "hash": "b693c81085f701ae94920cd909fc870b500683dc1cf2d5a502e87ece5cb8e578", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Multimodality ==\n\nMultimodality means \"having several modalities\", and a \"modality\" refers to a type of input or output, such as video, image, audio, text, proprioception, etc. There have been many AI models trained specifically to ingest one modality and output another modality, such as AlexNet for image to label, visual question answering for image-text to text, and speech recognition for speech to text.\nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n. Make a small multilayered perceptron \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n, so that for any image \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n, the post-processed vector \n  \n    \n      \n        f\n        (\n        E\n        (\n        y\n        )\n        )\n      \n    \n    {\\displaystyle f(E(y))}\n  \n has the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability.\nFlamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch. Google PaLM model was fine-tuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control. LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs, and video inputs.\nGPT-4 can use both text and image as inputs (although the vision component was not released to the public until GPT-4V); Google DeepMind's Gemini is also multimodal.  Mistral introduced its own multimodel Pixtral 12B model in September 2024.\n\n\n== Reasoning ==\nIn late 2024, a new direction emerged in LLM development with models specifically designed for complex reasoning tasks. These \"reasoning models\" were trained to spend more time generating step-by-step solutions before providing final answers, similar to human problem-solving processes.\nOpenAI introduced this trend with their o1 model in September 2024, followed by o3 in December 2024. These models showed significant improvements in mathematics, science, and coding tasks compared to traditional LLMs. For example, on International Mathematics Olympiad qualifying exam problems, GPT-4o achieved 13% accuracy while o1 reached 83%.\nIn January 2025, the Chinese company DeepSeek released DeepSeek-R1, a 671-billion-parameter open-weight reasoning model that achieved comparable performance to OpenAI's o1 while being significantly more cost-effective to operate. Unlike proprietary models from OpenAI, DeepSeek-R1's open-weight nature allowed researchers to study and build upon the algorithm, though its training data remained private.\nThese reasoning models typically require more computational resources per query compared to traditional LLMs, as they perform more extensive processing to work through problems step-by-step. However, they have shown superior capabilities in domains requiring structured logical thinking, such as mathematics, scientific research, and computer programming.\nEfforts to reduce or compensate for hallucinations have employed automated reasoning, RAG (retrieval-augmented generation), fine-tuning, and other methods.\n\n\n== Properties ==", "mimetype": "text/plain", "start_char_idx": 18043, "end_char_idx": 21719, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef8185ca-1b6c-42af-a491-c91870195d07": {"__data__": {"id_": "ef8185ca-1b6c-42af-a491-c91870195d07", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bc1354c6-c026-47db-99ef-24ee0bd02244", "node_type": "1", "metadata": {}, "hash": "a6b5f2d2d2d336e2878ead8872c695df9b2a30caf13fdb589d22fff57fb8f859", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "888871dd-08b3-42cf-8f10-61fcca99fe97", "node_type": "1", "metadata": {}, "hash": "88117e3874a450e2ded6cec1bca3e9de1f2baa9cf9417a81605159ab35b39f8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Properties ==\n\n\n=== Scaling laws ===\n\nThe performance of an LLM after pretraining largely depends on the:\n\ncost of pretraining \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n (the total amount of compute used),\nsize of the artificial neural network itself, such as number of parameters \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n (i.e. amount of neurons in its layers, amount of weights between them and biases),\nsize of its pretraining dataset (i.e. number of tokens in corpus, \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n).\n\"Scaling laws\" are empirical statistical laws that predict LLM performance based on such factors. One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:\n\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  C\n                  =\n                  \n                    C\n                    \n                      0\n                    \n                  \n                  N\n                  D\n                \n              \n              \n                \n                  L\n                  =\n                  \n                    \n                      A\n                      \n                        N\n                        \n                          \u03b1\n                        \n                      \n                    \n                  \n                  +\n                  \n                    \n                      B\n                      \n                        D\n                        \n                          \u03b2\n                        \n                      \n                    \n                  \n                  +\n                  \n                    L\n                    \n                      0\n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}C=C_{0}ND\\\\[6pt]L={\\frac {A}{N^{\\alpha }}}+{\\frac {B}{D^{\\beta }}}+L_{0}\\end{cases}}}\n  \n where the variables are\n\n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n is the cost of training the model, in FLOPs.\n\n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of parameters in the model.\n\n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is the number of tokens in the training set.\n\n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is the average negative log-likelihood loss per token (nats/token), achieved by the trained LLM on the test dataset.\nand the statistical hyper-parameters are\n\n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        =\n        6\n      \n    \n    {\\displaystyle C_{0}=6}\n  \n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.\n\n  \n    \n      \n        \u03b1\n        =\n        0.34\n        ,\n        \u03b2\n        =\n        0.28\n        ,\n        A\n        =\n        406.4\n        ,\n        B\n        =\n        410.7\n        ,\n        \n          L\n          \n            0\n          \n        \n        =\n        1.69\n      \n    \n    {\\displaystyle \\alpha =0.34,\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}", "mimetype": "text/plain", "start_char_idx": 21703, "end_char_idx": 25098, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "888871dd-08b3-42cf-8f10-61fcca99fe97": {"__data__": {"id_": "888871dd-08b3-42cf-8f10-61fcca99fe97", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef8185ca-1b6c-42af-a491-c91870195d07", "node_type": "1", "metadata": {}, "hash": "b693c81085f701ae94920cd909fc870b500683dc1cf2d5a502e87ece5cb8e578", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a3a135db-6b90-4bb5-b59f-6728cb7e4100", "node_type": "1", "metadata": {}, "hash": "e1a71c52c193414305ac74c91e18dc4b9febd551133d9b1be6e01133e4cc833b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Emergent abilities ===\n\nPerformance of bigger models on various tasks, when plotted on a log-log scale, appears as a linear extrapolation of performance achieved by smaller models. However, this linearity may be punctuated by \"break(s)\" in the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\". They arise from the complex interaction of the model's components and are not explicitly programmed or designed. \nFurthermore, recent research has demonstrated that AI systems, including large language models, can employ heuristic reasoning akin to human cognition. They balance between exhaustive logical processing and the use of cognitive shortcuts (heuristics), adapting their reasoning strategies to optimize between accuracy and effort. This behavior aligns with principles of resource-rational human cognition, as discussed in classical theories of bounded rationality and dual-process theory.\nOne of the emergent abilities is in-context learning from example demonstrations. In-context learning is involved in tasks, such as:\n\nreported arithmetics\ndecoding the International Phonetic Alphabet\nunscrambling a word's letters\ndisambiguating word-in-context datasets\nconverting spatial words\ncardinal directions (for example, replying \"northeast\" in response to a 3x3 grid of 8 zeros and a 1 in the top-right), color terms represented in text.\nchain-of-thought prompting: In a 2022 research paper, chain-of-thought prompting only improved the performance for models that had at least 62B. Smaller models perform better when prompted to answer immediately, without chain of thought.\nidentifying offensive content in paragraphs of Hinglish (a combination of Hindi and English), and generating a similar English equivalent of Kiswahili proverbs.\nSchaeffer et. al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.\nLet \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n be the number of parameter count, and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n be the performance of the model.\n\n\n== Interpretation ==\nLarge language models by themselves are black boxes, and it is not clear how they can perform linguistic tasks. Similarly, it is unclear if or how LLMs should be viewed as models of the human brain and/or human mind.\nVarious techniques have been developed to enhance the transparency and interpretability of LLMs. Mechanistic interpretability aims to reverse-engineer LLMs by discovering symbolic algorithms that approximate the inference performed by an LLM. In recent years, sparse coding models such as sparse autoencoders, transcoders, and crosscoders have emerged as promising tools for identifying interpretable features. \n\n\n=== Studying a replacement model ===\nTranscoders, which are more interpretable than transformers, have been utilized to develop \u201creplacement models.\u201d In one such study involving the mechanistic interpretation of writing a rhyming poem by an LLM, it was shown that although they are believed to simply predict the next token, they can, in fact, plan ahead.\n\n\n=== Explainability ===\nA related concept is AI explainability, which focuses on understanding how an AI model arrives at a given result. Techniques such as partial dependency plots, SHAP (SHapley Additive exPlanations), and feature importance assessments allow researchers to visualize and understand the contributions of various input features to the model's predictions. These methods help ensure that AI models make decisions based on relevant and fair criteria, enhancing trust and accountability.\nBy integrating these techniques, researchers and practitioners can gain deeper insights into the operations of LLMs, fostering trust and facilitating the responsible deployment of these powerful models.\nIn another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.", "mimetype": "text/plain", "start_char_idx": 25104, "end_char_idx": 29378, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a3a135db-6b90-4bb5-b59f-6728cb7e4100": {"__data__": {"id_": "a3a135db-6b90-4bb5-b59f-6728cb7e4100", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "888871dd-08b3-42cf-8f10-61fcca99fe97", "node_type": "1", "metadata": {}, "hash": "88117e3874a450e2ded6cec1bca3e9de1f2baa9cf9417a81605159ab35b39f8a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "63efa929-4aec-4f21-909a-cda2f85664aa", "node_type": "1", "metadata": {}, "hash": "e0800c5f31028da24117a3218f2b899b72a94f3494f699708589351dbd353c94", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Explainability ===\nA related concept is AI explainability, which focuses on understanding how an AI model arrives at a given result. Techniques such as partial dependency plots, SHAP (SHapley Additive exPlanations), and feature importance assessments allow researchers to visualize and understand the contributions of various input features to the model's predictions. These methods help ensure that AI models make decisions based on relevant and fair criteria, enhancing trust and accountability.\nBy integrating these techniques, researchers and practitioners can gain deeper insights into the operations of LLMs, fostering trust and facilitating the responsible deployment of these powerful models.\nIn another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.\n\n\n=== Understanding and intelligence ===\n\nNLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\". Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\" Ilya Sutskever argues that predicting the next word sometimes involves reasoning and deep insights, for example if the LLM has to predict the name of the criminal in an unknown detective novel after processing the entire story leading up to the revelation. Some researchers characterize LLMs as \"alien intelligence\". For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don't push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"\nIn contrast, some skeptics of LLM understanding believe that existing LLMs are \"simply remixing and recombining existing writing\", a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability. For example, GPT-4 has natural deficits in planning and in real-time learning. Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\". Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input. Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".\nThe matter of LLM's exhibiting intelligence or understanding has two main aspects \u2013 the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human like language. These aspects of language as a model of cognition have been developed in the field of cognitive linguistics. American linguist George Lakoff presented Neural Theory of Language (NTL) as a computational basis for using language as a model of learning tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human like language.\n\n\n== Evaluation ==", "mimetype": "text/plain", "start_char_idx": 28481, "end_char_idx": 33149, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "63efa929-4aec-4f21-909a-cda2f85664aa": {"__data__": {"id_": "63efa929-4aec-4f21-909a-cda2f85664aa", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3a135db-6b90-4bb5-b59f-6728cb7e4100", "node_type": "1", "metadata": {}, "hash": "e1a71c52c193414305ac74c91e18dc4b9febd551133d9b1be6e01133e4cc833b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7f251bf0-1193-4189-9da1-4b8632f5f19a", "node_type": "1", "metadata": {}, "hash": "f821e538d79a19911c3f3c2f880c066b332da45c9ceb70722a5ff374a93e38f6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Evaluation ==\n\n\n=== Perplexity ===\nThe canonical measure of the performance of an LLM is its perplexity on a given text corpus. Perplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential of the average negative log likelihood per token.\n\n  \n    \n      \n        log\n        \u2061\n        (\n        \n          Perplexity\n        \n        )\n        =\n        \u2212\n        \n          \n            1\n            N\n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        log\n        \u2061\n        (\n        Pr\n        (\n        \n          \n            token\n          \n          \n            i\n          \n        \n        \u2223\n        \n          \n            context for token\n          \n          \n            i\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle \\log({\\text{Perplexity}})=-{\\frac {1}{N}}\\sum _{i=1}^{N}\\log(\\Pr({\\text{token}}_{i}\\mid {\\text{context for token}}_{i}))}\n  \n\nHere, \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of tokens in the text corpus, and \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" depends on the specific type of LLM. If the LLM is autoregressive, then \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" is the segment of text appearing before token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n. If the LLM is masked, then \"context for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\" is the segment of text surrounding token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n.\nBecause language models may overfit to training data, models are usually evaluated by their perplexity on a test set. This evaluation is potentially problematic for larger models which, as they are trained on increasingly large corpora of text, are increasingly likely to inadvertently include portions of any given test set.\n\n\n==== Measures ====\nIn information theory, the concept of entropy is intricately linked to perplexity, a relationship notably established by Claude Shannon. This relationship is mathematically expressed as \n  \n    \n      \n        \n          Entropy\n        \n        =\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        (\n        \n          Perplexity\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Entropy}}=\\log _{2}({\\text{Perplexity}})}\n  \n.\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different Large Language Models (LLMs), BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\nIn the evaluation and comparison of language models, cross-entropy is generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model's enhanced capability for compression. This, in turn, reflects the model's proficiency in making accurate predictions.", "mimetype": "text/plain", "start_char_idx": 33133, "end_char_idx": 36733, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7f251bf0-1193-4189-9da1-4b8632f5f19a": {"__data__": {"id_": "7f251bf0-1193-4189-9da1-4b8632f5f19a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "63efa929-4aec-4f21-909a-cda2f85664aa", "node_type": "1", "metadata": {}, "hash": "e0800c5f31028da24117a3218f2b899b72a94f3494f699708589351dbd353c94", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ffc8cf32-ef4e-42ed-abc9-4623d393d8be", "node_type": "1", "metadata": {}, "hash": "5b54fc25a71a40254126160792b0e17687ccb97e30238e0de15f7d951a41f91e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Benchmarks ===\nBenchmarks are used to evaluate LLM performance on specific tasks. Tests evaluate capabilities such as general knowledge, bias, commonsense reasoning, question answering, and mathematical problem-solving. Composite benchmarks examine multiple capabilities. Results are often sensitive to the prompting method.\nA question answering benchmark is termed \"open book\" if the model's prompt includes text from which the expected answer can be derived (for example, the previous question could be combined with text that includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"). Otherwise, the task is considered \"closed book\", and the model must draw solely on its training. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, HELM, and HLE (Humanity's Last Exam).\nLLM bias may be assessed through benchmarks such as CrowS-Pairs (Crowdsourced Stereotype Pairs), Stereo Set, and Parity Benchmark.\nFact-checking and misinformation detection benchmarks are available. A 2023 study compared the fact-checking accuracy of LLMs including ChatGPT 3.5 and 4.0, Bard, and Bing AI against independent fact-checkers such as PolitiFact and Snopes. The results demonstrated moderate proficiency, with GPT-4 achieving the highest accuracy at 71%, lagging behind human fact-checkers.\nAn earlier standard tested using a portion of the evaluation dataset. It became more common to evaluate a pre-trained model directly through prompting techniques. Researchers vary in how they formulate prompts for particular tasks, particularly with respect to the number of correct examples attached to the prompt (i.e. the value of n in n-shot prompting).\n\n\n==== Datasets ====\nTypical datasets consist of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\"). Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.\nEvaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".\nDatasets are of varying quality and may contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality.\n\n\n==== Adversarial evaluations ====\nLLMs' rapid improvement regularly obsoletes benchmarks, with the models exceeding the performance of human annotators. In addition, \"shortcut learning\" allows AIs to \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording to guess the correct responses, without considering the specific question.\nSome datasets are adversarial, focusing on problems that confound LLMs. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions that stump LLMs by mimicking falsehoods to which they were exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can't teach an old dog new tricks, even though this is not literally true.\nAnother example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model. The resulting problems are trivial for humans but defeated LLMs. Sample questions:\n\nWe see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\n\ndemonstrates how to increase efficient exercise work by running up and down balls.\nmoves all his arms and legs and builds up a lot of muscle.\nthen plays the ball and we see a graphics and hedge trimming demonstration.\nperforms sit ups while on the ball and talking.\n\nBERT selects b) as the most likely completion, though the correct answer is d).\n\n\n== Wider impact ==\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\" Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally. Brinkmann et al. (2023) also argue that LLMs are transforming processes of cultural evolution by shaping processes of variation, transmission, and selection.", "mimetype": "text/plain", "start_char_idx": 36736, "end_char_idx": 41440, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ffc8cf32-ef4e-42ed-abc9-4623d393d8be": {"__data__": {"id_": "ffc8cf32-ef4e-42ed-abc9-4623d393d8be", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f251bf0-1193-4189-9da1-4b8632f5f19a", "node_type": "1", "metadata": {}, "hash": "f821e538d79a19911c3f3c2f880c066b332da45c9ceb70722a5ff374a93e38f6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3d8ebb20-fda2-47d2-a479-977a27d1410e", "node_type": "1", "metadata": {}, "hash": "a2eab7abf8fe6da2452415599ef00dd1865ad8f78986cf281abd4d74a58f689d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Wider impact ==\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\" Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally. Brinkmann et al. (2023) also argue that LLMs are transforming processes of cultural evolution by shaping processes of variation, transmission, and selection.\n\n\n=== Memorization and copyright ===\n\nMemorization is an emergent behavior in LLMs in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural nets. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates or up to about 7%.\nA 2023 study showed that when ChatGPT 3.5 turbo was prompted to repeat the same word indefinitely, after a few hundreds of repetitions, it would start outputting excerpts from its training data.\n\n\n=== Security ===\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse. For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.\nThe potential presence of \"sleeper agents\" within LLMs is another emerging security concern. These are hidden functionalities built into the model that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions.\nLLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, a 2023 study proposed a method for circumventing LLM safety systems. In 2025, The American Sunlight Project, a non-profit, published a study showing evidence that the so-called Pravda network, a pro-Russia propaganda aggregator, was strategically placing web content through mass publication and duplication with the intention of biasing LLM outputs. The American Sunlight Project coined this technique \"LLM grooming,\" and pointed to it as a new tool of weaponizing AI to spread disinformation and harmful content. Similarly, Yongge Wang illustrated in 2024 how a potential criminal could potentially bypass ChatGPT 4o's safety controls to obtain information on establishing a drug trafficking operation. External filters, circuit breakers and overrides have been posed as solutions.\n\n\n=== Algorithmic bias ===\n\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups. Since English data is overrepresented in current large language models' training data, it may also downplay non-English views.\n\n\n==== Stereotyping ====\nAI models can reinforce a wide range of stereotypes, including those based on gender, ethnicity, age, nationality, religion, or occupation. This can lead to outputs that homogenize, or unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways.\nNotably, gender bias refers to the tendency of these models to produce outputs that are unfairly prejudiced towards one gender over another. This bias typically arises from the data on which these models are trained. Large language models often assign roles and characteristics based on traditional gender norms. For example, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men.\n\n\n==== Selection bias ====\nSelection bias refers the inherent tendency of large language models to favor certain option identifiers irrespective of the actual content of the options. This bias primarily stems from token bias\u2014that is, the model assigns a higher a priori probability to specific answer tokens (such as \u201cA\u201d) when generating responses. As a result, when the ordering of options is altered (for example, by systematically moving the correct answer to different positions), the model\u2019s performance can fluctuate significantly. This phenomenon undermines the reliability of large language models in multiple-choice settings.\n\n\n==== Political bias ====\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.", "mimetype": "text/plain", "start_char_idx": 40748, "end_char_idx": 46075, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3d8ebb20-fda2-47d2-a479-977a27d1410e": {"__data__": {"id_": "3d8ebb20-fda2-47d2-a479-977a27d1410e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73248112", "node_type": "4", "metadata": {}, "hash": "863f6621ce41a961b8ab75f7f7a17e95d47f117eac5f68ef866d1f4f84433747", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ffc8cf32-ef4e-42ed-abc9-4623d393d8be", "node_type": "1", "metadata": {}, "hash": "5b54fc25a71a40254126160792b0e17687ccb97e30238e0de15f7d951a41f91e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Selection bias ====\nSelection bias refers the inherent tendency of large language models to favor certain option identifiers irrespective of the actual content of the options. This bias primarily stems from token bias\u2014that is, the model assigns a higher a priori probability to specific answer tokens (such as \u201cA\u201d) when generating responses. As a result, when the ordering of options is altered (for example, by systematically moving the correct answer to different positions), the model\u2019s performance can fluctuate significantly. This phenomenon undermines the reliability of large language models in multiple-choice settings.\n\n\n==== Political bias ====\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.\n\n\n=== Energy demands ===\nThe energy demands of LLMs have grown along with their size and capabilities. Data centers that enable LLM training require substantial amounts of electricity. Much of that electricity is generated by non-renewable resources that create greenhouse gases and contribute to climate change. Nuclear power and geothermal energy are two options tech companies are exploring to meet the sizable energy demands of LLM training. The significant expense of investing in geothermal solutions has led to major shale producers like Chevron and Exxon Mobil advocating for tech companies to use electricity produced via natural gas to fuel their large energy demands.\n\n\n== See also ==\nFoundation models\nList of large language models\nList of chatbots\nLanguage model benchmark\nReinforcement learning\nSmall language model\n\n\n== References ==\n\n\n== Further reading ==\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\nZhao, Wayne Xin; et al. (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\nKaddour, Jean; et al. (2023). \"Challenges and Applications of Large Language Models\". arXiv:2307.10169 [cs.CL].\nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2024). \"A Survey on Multimodal Large Language Models\". National Science Review. 11 (12): nwae403. arXiv:2306.13549. doi:10.1093/nsr/nwae403. PMC 11645129. PMID 39679213.\n\"AI Index Report 2024 \u2013 Artificial Intelligence Index\". aiindex.stanford.edu. Retrieved 2024-05-05.\nFrank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large language models\". Nature Reviews Psychology. 2 (8): 451\u2013452. doi:10.1038/s44159-023-00211-x. ISSN 2731-0574. S2CID 259713140. Retrieved 2 July 2023.\nAnwar, U.; Saparov, A.; Rando, J.; Paleka, D.; Turpin, M.; Hase, P.; Lubana, E. S.; Jenner, E.; Casper, S.; Sourbut, O.; Edelman, B. L.; Zhang, Z.; G\u00fcnther, M.; Korinek, A.; Hernandez-Orallo, J.; Hammond, L.; Bigelow, E.; Pan, A.; Langosco, L.; Krueger, D. (2024). \"Foundational Challenges in Assuring Alignment and Safety of Large Language Models\". arXiv:2404.09932 [cs.LG].", "mimetype": "text/plain", "start_char_idx": 44983, "end_char_idx": 48306, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "da1741a2-b54c-49f3-acba-cec69b1e92ec": {"__data__": {"id_": "da1741a2-b54c-49f3-acba-cec69b1e92ec", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c37f473e-5e04-40bd-bf6a-5ba605fb4970", "node_type": "1", "metadata": {}, "hash": "aa1d28d789f53ad5ac527840311ece98ad2437c2ebb4b816fb39ce7376b7eee0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Automation describes a wide range of technologies that reduce human intervention in processes, mainly by predetermining decision criteria, subprocess relationships, and related actions, as well as embodying those predeterminations in machines. Automation has been achieved by various means including mechanical, hydraulic, pneumatic, electrical, electronic devices, and computers, usually in combination. Complicated systems, such as modern factories, airplanes, and ships typically use combinations of all of these techniques. The benefit of automation includes labor savings, reducing waste, savings in electricity costs, savings in material costs, and improvements to quality, accuracy, and precision.\nAutomation includes the use of various equipment and control systems such as machinery, processes in factories, boilers, and heat-treating ovens, switching on telephone networks, steering, stabilization of ships, aircraft and other applications and vehicles with reduced human intervention. Examples range from a household thermostat controlling a boiler to a large industrial control system with tens of thousands of input measurements and output control signals. Automation has also found a home in the banking industry. It can range from simple on-off control to multi-variable high-level algorithms in terms of control complexity.\nIn the simplest type of an automatic control loop, a controller compares a measured value of a process with a desired set value and processes the resulting error signal to change some input to the process, in such a way that the process stays at its set point despite disturbances. This closed-loop control is an application of negative feedback to a system. The mathematical basis of control theory was begun in the 18th century and advanced rapidly in the 20th. The term automation, inspired by the earlier word automatic (coming from automaton), was not widely used before 1947, when Ford established an automation department. It was during this time that the industry was rapidly adopting feedback controllers, which were introduced in the 1930s.\nThe World Bank's World Development Report of 2019 shows evidence that the new industries and jobs in the technology sector outweigh the economic effects of workers being displaced by automation. Job losses and downward mobility blamed on automation have been cited as one of many factors in the resurgence of nationalist, protectionist and populist politics in the US, UK and France, among other countries since the 2010s.\n\n\n== History ==\n\n\n=== Early history ===\n\nIt was a preoccupation of the Greeks and Arabs (in the period between about 300 BC and about 1200 AD) to keep accurate track of time. In Ptolemaic Egypt, about 270 BC, Ctesibius described a float regulator for a water clock, a device not unlike the ball and cock in a modern flush toilet. This was the earliest feedback-controlled mechanism. The appearance of the mechanical clock in the 14th century made the water clock and its feedback control system obsolete.\nThe Persian Ban\u016b M\u016bs\u0101 brothers, in their Book of Ingenious Devices (850 AD), described a number of automatic controls. Two-step level controls for fluids, a form of discontinuous variable structure controls, were developed by the Banu Musa brothers. They also described a feedback controller. The design of feedback control systems up through the Industrial Revolution was by trial-and-error, together with a great deal of engineering intuition. It was not until the mid-19th century that the stability of feedback control systems was analyzed using mathematics, the formal language of automatic control theory.\nThe centrifugal governor was invented by Christiaan Huygens in the seventeenth century, and used to adjust the gap between millstones.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3765, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c37f473e-5e04-40bd-bf6a-5ba605fb4970": {"__data__": {"id_": "c37f473e-5e04-40bd-bf6a-5ba605fb4970", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "da1741a2-b54c-49f3-acba-cec69b1e92ec", "node_type": "1", "metadata": {}, "hash": "8dd1622119f047cafe2da77ba58988f121fea9268d0d51b038ff1625675d4bd5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b61d906-4e2e-4658-8d5b-9ff4177981c9", "node_type": "1", "metadata": {}, "hash": "ebd93b58f12565d902d915cfd4efa9fa60ce920b0704b51c14e9a5ff7569d8a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Industrial Revolution in Western Europe ===\n\nThe introduction of prime movers, or self-driven machines advanced grain mills, furnaces, boilers, and the steam engine created a new requirement for automatic control systems including temperature regulators (invented in 1624; see Cornelius Drebbel), pressure regulators (1681), float regulators (1700) and speed control devices. Another control mechanism was used to tent the sails of windmills. It was patented by Edmund Lee in 1745. Also in 1745, Jacques de Vaucanson invented the first automated loom. Around 1800, Joseph Marie Jacquard created a punch-card system to program looms.\nIn 1771 Richard Arkwright invented the first fully automated spinning mill driven by water power, known at the time as the water frame. An automatic flour mill was developed by Oliver Evans in 1785, making it the first completely automated industrial process.\n\nA centrifugal governor was used by Mr. Bunce of England in 1784 as part of a model steam crane. The centrifugal governor was adopted by James Watt for use on a steam engine in 1788 after Watt's partner Boulton saw one at a flour mill Boulton & Watt were building. The governor could not actually hold a set speed; the engine would assume a new constant speed in response to load changes. The governor was able to handle smaller variations such as those caused by fluctuating heat load to the boiler. Also, there was a tendency for oscillation whenever there was a speed change. As a consequence, engines equipped with this governor were not suitable for operations requiring constant speed, such as cotton spinning.\nSeveral improvements to the governor, plus improvements to valve cut-off timing on the steam engine, made the engine suitable for most industrial uses before the end of the 19th century. Advances in the steam engine stayed well ahead of science, both thermodynamics and control theory. The governor received relatively little scientific attention until James Clerk Maxwell published a paper that established the beginning of a theoretical basis for understanding control theory.\n\n\n=== 20th century ===\nRelay logic was introduced with factory electrification, which underwent rapid adaption from 1900 through the 1920s. Central electric power stations were also undergoing rapid growth and the operation of new high-pressure boilers, steam turbines and electrical substations created a large demand for instruments and controls. Central control rooms became common in the 1920s, but as late as the early 1930s, most process controls were on-off. Operators typically monitored charts drawn by recorders that plotted data from instruments. To make corrections, operators manually opened or closed valves or turned switches on or off. Control rooms also used color-coded lights to send signals to workers in the plant to manually make certain changes.\nThe development of the electronic amplifier during the 1920s, which was important for long-distance telephony, required a higher signal-to-noise ratio, which was solved by negative feedback noise cancellation. This and other telephony applications contributed to the control theory. In the 1940s and 1950s, German mathematician Irmgard Fl\u00fcgge-Lotz developed the theory of discontinuous automatic controls, which found military applications during the Second World War to fire control systems and aircraft navigation systems.\nControllers, which were able to make calculated changes in response to deviations from a set point rather than on-off control, began being introduced in the 1930s. Controllers allowed manufacturing to continue showing productivity gains to offset the declining influence of factory electrification.\nFactory productivity was greatly increased by electrification in the 1920s. U.S. manufacturing productivity growth fell from 5.2%/yr 1919\u201329 to 2.76%/yr 1929\u201341. Alexander Field notes that spending on non-medical instruments increased significantly from 1929 to 1933 and remained strong thereafter.\nThe First and Second World Wars saw major advancements in the field of mass communication and signal processing. Other key advances in automatic controls include differential equations, stability theory and system theory (1938), frequency domain analysis (1940), ship control (1950), and stochastic analysis (1941).\nStarting in 1958, various systems based on solid-state digital logic modules for hard-wired programmed logic controllers (the predecessors of programmable logic controllers [PLC]) emerged to replace electro-mechanical relay logic in industrial control systems for process control and automation, including early Telefunken/AEG Logistat, Siemens Simatic, Philips/Mullard/Valvo Norbit, BBC Sigmatronic, ACEC Logacec, Akkord Estacord, Krone Mibakron, Bistat, Datapac, Norlog, SSR, or Procontic systems.\nIn 1959 Texaco's Port Arthur Refinery became the first chemical plant to use digital control.\nConversion of factories to digital control began to spread rapidly in the 1970s as the price of computer hardware fell.", "mimetype": "text/plain", "start_char_idx": 3768, "end_char_idx": 8782, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b61d906-4e2e-4658-8d5b-9ff4177981c9": {"__data__": {"id_": "8b61d906-4e2e-4658-8d5b-9ff4177981c9", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c37f473e-5e04-40bd-bf6a-5ba605fb4970", "node_type": "1", "metadata": {}, "hash": "aa1d28d789f53ad5ac527840311ece98ad2437c2ebb4b816fb39ce7376b7eee0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7fbcc181-b354-4e2f-a4c3-baf6f9281f95", "node_type": "1", "metadata": {}, "hash": "8bb3af1665891d0cb5a936450ca15f1aed3253deea73ecda5b16b6abf5ad63f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Significant applications ===\nThe automatic telephone switchboard was introduced in 1892 along with dial telephones. By 1929, 31.9% of the Bell system was automatic.:\u200a158\u200a  Automatic telephone switching originally used vacuum tube amplifiers and electro-mechanical switches, which consumed a large amount of electricity. Call volume eventually grew so fast that it was feared the telephone system would consume all electricity production, prompting Bell Labs to begin research on the transistor.\nThe logic performed by telephone switching relays was the inspiration for the digital computer.\nThe first commercially successful glass bottle-blowing machine was an automatic model introduced in 1905. The machine, operated by a two-man crew working 12-hour shifts, could produce 17,280 bottles in 24 hours, compared to 2,880 bottles made by a crew of six men and boys working in a shop for a day. The cost of making bottles by machine was 10 to 12 cents per gross compared to $1.80 per gross by the manual glassblowers and helpers.\nSectional electric drives were developed using control theory. Sectional electric drives are used on different sections of a machine where a precise differential must be maintained between the sections. In steel rolling, the metal elongates as it passes through pairs of rollers, which must run at successively faster speeds. In paper making paper, the sheet shrinks as it passes around steam-heated drying arranged in groups, which must run at successively slower speeds. The first application of a sectional electric drive was on a paper machine in 1919. One of the most important developments in the steel industry during the 20th century was continuous wide strip rolling, developed by Armco in 1928.\n\nBefore automation, many chemicals were made in batches. In 1930, with the widespread use of instruments and the emerging use of controllers, the founder of Dow Chemical Co. was advocating continuous production.\nSelf-acting machine tools that displaced hand dexterity so they could be operated by boys and unskilled laborers were developed by James Nasmyth in the 1840s. Machine tools were automated with Numerical control (NC) using punched paper tape in the 1950s. This soon evolved into computerized numerical control (CNC).\nToday extensive automation is practiced in practically every type of manufacturing and assembly process. Some of the larger processes include electrical power generation, oil refining, chemicals, steel mills, plastics, cement plants, fertilizer plants, pulp and paper mills, automobile and truck assembly, aircraft production, glass manufacturing, natural gas separation plants, food and beverage processing, canning and bottling and manufacture of various kinds of parts. Robots are especially useful in hazardous applications like automobile spray painting. Robots are also used to assemble electronic circuit boards. Automotive welding is done with robots and automatic welders are used in applications like pipelines.\n\n\n=== Space/computer age ===\nWith the advent of the space age in 1957, controls design, particularly in the United States, turned away from the frequency-domain techniques of classical control theory and backed into the differential equation techniques of the late 19th century, which were couched in the time domain. During the 1940s and 1950s, German mathematician Irmgard Flugge-Lotz developed the theory of discontinuous automatic control, which became widely used in hysteresis control systems such as navigation systems, fire-control systems, and electronics. Through Flugge-Lotz and others, the modern era saw time-domain design for nonlinear systems (1961), navigation (1960), optimal control and estimation theory (1962), nonlinear control theory (1969), digital control and filtering theory (1974), and the personal computer (1983).", "mimetype": "text/plain", "start_char_idx": 8785, "end_char_idx": 12614, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7fbcc181-b354-4e2f-a4c3-baf6f9281f95": {"__data__": {"id_": "7fbcc181-b354-4e2f-a4c3-baf6f9281f95", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b61d906-4e2e-4658-8d5b-9ff4177981c9", "node_type": "1", "metadata": {}, "hash": "ebd93b58f12565d902d915cfd4efa9fa60ce920b0704b51c14e9a5ff7569d8a6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "113ec952-36d3-49d0-af83-b94234745e6a", "node_type": "1", "metadata": {}, "hash": "3bfc6ad9fc5504b3c722e5e5364847b33f0d1f17db1d125bd298c2b103aa0a9e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Space/computer age ===\nWith the advent of the space age in 1957, controls design, particularly in the United States, turned away from the frequency-domain techniques of classical control theory and backed into the differential equation techniques of the late 19th century, which were couched in the time domain. During the 1940s and 1950s, German mathematician Irmgard Flugge-Lotz developed the theory of discontinuous automatic control, which became widely used in hysteresis control systems such as navigation systems, fire-control systems, and electronics. Through Flugge-Lotz and others, the modern era saw time-domain design for nonlinear systems (1961), navigation (1960), optimal control and estimation theory (1962), nonlinear control theory (1969), digital control and filtering theory (1974), and the personal computer (1983).\n\n\n== Advantages, disadvantages, and limitations ==\nPerhaps the most cited advantage of automation in industry is that it is associated with faster production and cheaper labor costs. Another benefit could be that it replaces hard, physical, or monotonous work. Additionally, tasks that take place in hazardous environments or that are otherwise beyond human capabilities can be done by machines, as machines can operate even under extreme temperatures or in atmospheres that are radioactive or toxic. They can also be maintained with simple quality checks. However, at the time being, not all tasks can be automated, and some tasks are more expensive to automate than others. Initial costs of installing the machinery in factory settings are high, and failure to maintain a system could result in the loss of the product itself.\nMoreover, some studies seem to indicate that industrial automation could impose ill effects beyond operational concerns, including worker displacement due to systemic loss of employment and compounded environmental damage; however, these findings are both convoluted and controversial in nature, and could potentially be circumvented.\nThe main advantages of automation are:\n\nIncreased throughput or productivity\nImproved quality\nIncreased predictability\nImproved robustness (consistency), of processes or product\nIncreased consistency of output\nReduced direct human labor costs and expenses\nReduced cycle time\nIncreased accuracy\nRelieving humans of monotonously repetitive work\nRequired work in development, deployment, maintenance, and operation of automated processes \u2014 often structured as \"jobs\"\nIncreased human freedom to do other things\nAutomation primarily describes machines replacing human action, but it is also loosely associated with mechanization, machines replacing human labor. Coupled with mechanization, extending human capabilities in terms of size, strength, speed, endurance, visual range & acuity, hearing frequency & precision, electromagnetic sensing & effecting, etc., advantages include:\n\nRelieving humans of dangerous work stresses and occupational injuries (e.g., fewer strained backs from lifting heavy objects)\nRemoving humans from dangerous environments (e.g. fire, space, volcanoes, nuclear facilities, underwater, etc.)\nThe main disadvantages of automation are:\n\nHigh initial cost\nFaster production without human intervention can mean faster unchecked production of defects where automated processes are defective.\nScaled-up capacities can mean scaled-up problems when systems fail \u2014 releasing dangerous toxins, forces, energies, etc., at scaled-up rates.\nHuman adaptiveness is often poorly understood by automation initiators. It is often difficult to anticipate every contingency and develop fully preplanned automated responses for every situation. The discoveries inherent in automating processes can require unanticipated iterations to resolve, causing unanticipated costs and delays.\nPeople anticipating employment income may be seriously disrupted by others deploying automation where no similar income is readily available.\n\n\n=== Paradox of automation ===\nThe paradox of automation says that the more efficient the automated system, the more crucial the human contribution of the operators. Humans are less involved, but their involvement becomes more critical. Lisanne Bainbridge, a cognitive psychologist, identified these issues notably in her widely cited paper \"Ironies of Automation.\" If an automated system has an error, it will multiply that error until it is fixed or shut down. This is where human operators come in. A fatal example of this was Air France Flight 447, where a failure of automation put the pilots into a manual situation they were not prepared for.\n\n\n=== Limitations ===\n\nCurrent technology is unable to automate all the desired tasks.\nMany operations using automation have large amounts of invested capital and produce high volumes of products, making malfunctions extremely costly and potentially hazardous. Therefore, some personnel is needed to ensure that the entire system functions properly and that safety and product quality are maintained.\nAs a process becomes increasingly automated, there is less and less labor to be saved or quality improvement to be gained. This is an example of both diminishing returns and the logistic function.\nAs more and more processes become automated, there are fewer remaining non-automated processes. This is an example of the exhaustion of opportunities. New technological paradigms may, however, set new limits that surpass the previous limits.", "mimetype": "text/plain", "start_char_idx": 11774, "end_char_idx": 17197, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "113ec952-36d3-49d0-af83-b94234745e6a": {"__data__": {"id_": "113ec952-36d3-49d0-af83-b94234745e6a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7fbcc181-b354-4e2f-a4c3-baf6f9281f95", "node_type": "1", "metadata": {}, "hash": "8bb3af1665891d0cb5a936450ca15f1aed3253deea73ecda5b16b6abf5ad63f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d274f457-dc3e-46d8-819a-b509dd0629ef", "node_type": "1", "metadata": {}, "hash": "410be4d996167fba7487dc17dadedb4ccb2028a1fa733495c0be69d01e16d89e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Limitations ===\n\nCurrent technology is unable to automate all the desired tasks.\nMany operations using automation have large amounts of invested capital and produce high volumes of products, making malfunctions extremely costly and potentially hazardous. Therefore, some personnel is needed to ensure that the entire system functions properly and that safety and product quality are maintained.\nAs a process becomes increasingly automated, there is less and less labor to be saved or quality improvement to be gained. This is an example of both diminishing returns and the logistic function.\nAs more and more processes become automated, there are fewer remaining non-automated processes. This is an example of the exhaustion of opportunities. New technological paradigms may, however, set new limits that surpass the previous limits.\n\n\n==== Current limitations ====\nMany roles for humans in industrial processes presently lie beyond the scope of automation. Human-level pattern recognition, language comprehension, and language production ability are well beyond the capabilities of modern mechanical and computer systems (but see Watson computer). Tasks requiring subjective assessment or synthesis of complex sensory data, such as scents and sounds, as well as high-level tasks such as strategic planning, currently require human expertise. In many cases, the use of humans is more cost-effective than mechanical approaches even where the automation of industrial tasks is possible. Therefore, algorithmic management as the digital rationalization of human labor instead of its substitution has emerged as an alternative technological strategy. Overcoming these obstacles is a theorized path to post-scarcity economics.", "mimetype": "text/plain", "start_char_idx": 16360, "end_char_idx": 18085, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d274f457-dc3e-46d8-819a-b509dd0629ef": {"__data__": {"id_": "d274f457-dc3e-46d8-819a-b509dd0629ef", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "113ec952-36d3-49d0-af83-b94234745e6a", "node_type": "1", "metadata": {}, "hash": "3bfc6ad9fc5504b3c722e5e5364847b33f0d1f17db1d125bd298c2b103aa0a9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "536c7a7e-3f3d-4bbf-96e3-bc81af8906fd", "node_type": "1", "metadata": {}, "hash": "53c49abab650cb6c6f8992eb5082f9a3d84538873fe0da15dc4ed01048028730", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Current limitations ====\nMany roles for humans in industrial processes presently lie beyond the scope of automation. Human-level pattern recognition, language comprehension, and language production ability are well beyond the capabilities of modern mechanical and computer systems (but see Watson computer). Tasks requiring subjective assessment or synthesis of complex sensory data, such as scents and sounds, as well as high-level tasks such as strategic planning, currently require human expertise. In many cases, the use of humans is more cost-effective than mechanical approaches even where the automation of industrial tasks is possible. Therefore, algorithmic management as the digital rationalization of human labor instead of its substitution has emerged as an alternative technological strategy. Overcoming these obstacles is a theorized path to post-scarcity economics.\n\n\n=== Societal impact and unemployment ===\n\nIncreased automation often causes workers to feel anxious about losing their jobs as technology renders their skills or experience unnecessary. Early in the Industrial Revolution, when inventions like the steam engine were making some job categories expendable, workers forcefully resisted these changes. Luddites, for instance, were English textile workers who protested the introduction of weaving machines by destroying them. More recently, some residents of Chandler, Arizona, have slashed tires and pelted rocks at self-driving car, in protest over the cars' perceived threat to human safety and job prospects.\nThe relative anxiety about automation reflected in opinion polls seems to correlate closely with the strength of organized labor in that region or nation. For example, while a study by the Pew Research Center indicated that 72% of Americans are worried about increasing automation in the workplace, 80% of Swedes see automation and artificial intelligence (AI) as a good thing, due to the country's still-powerful unions and a more robust national safety net.\nAccording to one estimate, 47% of all current jobs in the US have the potential to be fully automated by 2033. Furthermore, wages and educational attainment appear to be strongly negatively correlated with an occupation's risk of being automated. Erik Brynjolfsson and Andrew McAfee argue that \"there's never been a better time to be a worker with special skills or the right education, because these people can use technology to create and capture value. However, there's never been a worse time to be a worker with only 'ordinary' skills and abilities to offer, because computers, robots, and other digital technologies are acquiring these skills and abilities at an extraordinary rate.\" Others however argue that highly skilled professional jobs like a lawyer, doctor, engineer, journalist are also at risk of automation.\nAccording to a 2020 study in the Journal of Political Economy, automation has robust negative effects on employment and wages: \"One more robot per thousand workers reduces the employment-to-population ratio by 0.2 percentage points and wages by 0.42%.\" A 2025 study in the American Economic Journal found that the introduction of industrial robots reduced 1993 and 2014 led to reduced employment of men and women by 3.7 and 1.6 percentage points.\nResearch by Carl Benedikt Frey and Michael Osborne of the Oxford Martin School argued that employees engaged in \"tasks following well-defined procedures that can easily be performed by sophisticated algorithms\" are at risk of displacement, and 47% of jobs in the US were at risk. The study, released as a working paper in 2013 and published in 2017, predicted that automation would put low-paid physical occupations most at risk, by surveying a group of colleagues on their opinions. However, according to a study published in McKinsey Quarterly in 2015 the impact of computerization in most cases is not the replacement of employees but the automation of portions of the tasks they perform. The methodology of the McKinsey study has been heavily criticized for being intransparent and relying on subjective assessments. The methodology of Frey and Osborne has been subjected to criticism, as lacking evidence, historical awareness, or credible methodology. Additionally, the Organisation for Economic Co-operation and Development (OECD) found that across the 21 OECD countries, 9% of jobs are automatable.\nBased on a formula by Gilles Saint-Paul, an economist at Toulouse 1 University, the demand for unskilled human capital declines at a slower rate than the demand for skilled human capital increases. In the long run and for society as a whole it has led to cheaper products, lower average work hours, and new industries forming (i.e., robotics industries, computer industries, design industries). These new industries provide many high salary skill-based jobs to the economy. By 2030, between 3 and 14 percent of the global workforce will be forced to switch job categories due to automation eliminating jobs in an entire sector. While the number of jobs lost to automation is often offset by jobs gained from technological advances, the same type of job loss is not the same one replaced and that leading to increasing unemployment in the lower-middle class. This occurs largely in the US and developed countries where technological advances contribute to higher demand for highly skilled labor but demand for middle-wage labor continues to fall. Economists call this trend \"income polarization\" where unskilled labor wages are driven down and skilled labor is driven up and it is predicted to continue in developed economies.", "mimetype": "text/plain", "start_char_idx": 17200, "end_char_idx": 22810, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "536c7a7e-3f3d-4bbf-96e3-bc81af8906fd": {"__data__": {"id_": "536c7a7e-3f3d-4bbf-96e3-bc81af8906fd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d274f457-dc3e-46d8-819a-b509dd0629ef", "node_type": "1", "metadata": {}, "hash": "410be4d996167fba7487dc17dadedb4ccb2028a1fa733495c0be69d01e16d89e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bf4ea3bf-1285-4a56-a604-cfa6a9126b3c", "node_type": "1", "metadata": {}, "hash": "bbdcc77f85ab419bfff19a6a1f80b4b80519395679cc56cbd2e0e008567dc750", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Lights-out manufacturing ==\n\nLights-out manufacturing is a production system with no human workers, to eliminate labor costs. It grew in popularity in the U.S. when General Motors in 1982 implemented humans \"hands-off\" manufacturing to \"replace risk-averse bureaucracy with automation and robots\". However, the factory never reached full \"lights out\" status.\nThe expansion of lights out manufacturing requires:\n\nReliability of equipment\nLong-term mechanic capabilities\nPlanned preventive maintenance\nCommitment from the staff\n\n\n== Health and environment ==\n\nThe costs of automation to the environment are different depending on the technology, product or engine automated. There are automated engines that consume more energy resources from the Earth in comparison with previous engines and vice versa. Hazardous operations, such as oil refining, the manufacturing of industrial chemicals, and all forms of metal working, were always early contenders for automation.\nThe automation of vehicles could prove to have a substantial impact on the environment, although the nature of this impact could be beneficial or harmful depending on several factors. Because automated vehicles are much less likely to get into accidents compared to human-driven vehicles, some precautions built into current models (such as anti-lock brakes or laminated glass) would not be required for self-driving versions. Removal of these safety features reduces the weight of the vehicle, and coupled with more precise acceleration and braking, as well as fuel-efficient route mapping, can increase fuel economy and reduce emissions. Despite this, some researchers theorize that an increase in the production of self-driving cars could lead to a boom in vehicle ownership and usage, which could potentially negate any environmental benefits of self-driving cars if they are used more frequently.\nAutomation of homes and home appliances is also thought to impact the environment. A study of energy consumption of automated homes in Finland showed that smart homes could reduce energy consumption by monitoring levels of consumption in different areas of the home and adjusting consumption to reduce energy leaks (e.g. automatically reducing consumption during the nighttime when activity is low). This study, along with others, indicated that the smart home's ability to monitor and adjust consumption levels would reduce unnecessary energy usage. However, some research suggests that smart homes might not be as efficient as non-automated homes. A more recent study has indicated that, while monitoring and adjusting consumption levels do decrease unnecessary energy use, this process requires monitoring systems that also consume an amount of energy. The energy required to run these systems sometimes negates their benefits, resulting in little to no ecological benefit.\n\n\n== Convertibility and turnaround time ==\n\nAnother major shift in automation is the increased demand for flexibility and convertibility in manufacturing processes. Manufacturers are increasingly demanding the ability to easily switch from manufacturing Product A to manufacturing Product B without having to completely rebuild the production lines. Flexibility and distributed processes have led to the introduction of Automated Guided Vehicles with Natural Features Navigation.\nDigital electronics helped too. Former analog-based instrumentation was replaced by digital equivalents which can be more accurate and flexible, and offer greater scope for more sophisticated configuration, parametrization, and operation. This was accompanied by the fieldbus revolution which provided a networked (i.e. a single cable) means of communicating between control systems and field-level instrumentation, eliminating hard-wiring.\nDiscrete manufacturing plants adopted these technologies fast. The more conservative process industries with their longer plant life cycles have been slower to adopt and analog-based measurement and control still dominate. The growing use of Industrial Ethernet on the factory floor is pushing these trends still further, enabling manufacturing plants to be integrated more tightly within the enterprise, via the internet if necessary. Global competition has also increased demand for Reconfigurable Manufacturing Systems.", "mimetype": "text/plain", "start_char_idx": 22813, "end_char_idx": 27105, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bf4ea3bf-1285-4a56-a604-cfa6a9126b3c": {"__data__": {"id_": "bf4ea3bf-1285-4a56-a604-cfa6a9126b3c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "536c7a7e-3f3d-4bbf-96e3-bc81af8906fd", "node_type": "1", "metadata": {}, "hash": "53c49abab650cb6c6f8992eb5082f9a3d84538873fe0da15dc4ed01048028730", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2685772-7b72-4fb0-86ae-6cb293074405", "node_type": "1", "metadata": {}, "hash": "2079c047071b5c75b76fe5a6c8b6c76475814471968c01de044fa8caacc68380", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Automation tools ==\nEngineers can now have numerical control over automated devices. The result has been a rapidly expanding range of applications and human activities. Computer-aided technologies (or CAx) now serve as the basis for mathematical and organizational tools used to create complex systems. Notable examples of CAx include computer-aided design (CAD software) and computer-aided manufacturing (CAM software). The improved design, analysis, and manufacture of products enabled by CAx has been beneficial for industry.\nInformation technology, together with industrial machinery and processes, can assist in the design, implementation, and monitoring of control systems. One example of an industrial control system is a programmable logic controller (PLC). PLCs are specialized hardened computers which are frequently used to synchronize the flow of inputs from (physical) sensors and events with the flow of outputs to actuators and events.\n\nHuman-machine interfaces (HMI) or computer human interfaces (CHI), formerly known as man-machine interfaces, are usually employed to communicate with PLCs and other computers. Service personnel who monitor and control through HMIs can be called by different names. In the industrial process and manufacturing environments, they are called operators or something similar. In boiler houses and central utility departments, they are called stationary engineers.\nDifferent types of automation tools exist:\n\nANN \u2013 Artificial neural network\nDCS \u2013 Distributed control system\nHMI \u2013 Human machine interface\nRPA \u2013 Robotic process automation\nSCADA \u2013 Supervisory control and data acquisition\nPLC \u2013 Programmable logic controller\nInstrumentation\nMotion control\nRobotics\nHost simulation software (HSS) is a commonly used testing tool that is used to test the equipment software. HSS is used to test equipment performance concerning factory automation standards (timeouts, response time, processing time).\n\n\n== Cognitive automation ==\nCognitive automation, as a subset of AI, is an emerging genus of automation enabled by cognitive computing. Its primary concern is the automation of clerical tasks and workflows that consist of structuring unstructured data. Cognitive automation relies on multiple disciplines: natural language processing, real-time computing, machine learning algorithms, big data analytics, and evidence-based learning.\nAccording to Deloitte, cognitive automation enables the replication of human tasks and judgment \"at rapid speeds and considerable scale.\" Such tasks include:\n\nDocument redaction\nData extraction and document synthesis / reporting\nContract management\nNatural language search\nCustomer, employee, and stakeholder onboarding\nManual activities and verifications\nFollow-up and email communications\n\n\n== Recent and emerging applications ==\n\n\n=== CAD AI ===\nArtificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate in 3D modeling.  AI CAD libraries could also be developed using linked open data of schematics  and diagrams.  Ai CAD assistants are used as tools to help streamline workflow.\n\n\n=== Automated power production ===\nTechnologies like solar panels, wind turbines, and other renewable energy sources\u2014together with smart grids, micro-grids, battery storage\u2014can automate power production.\n\n\n=== Agricultural production ===\n\nMany agricultural operations are automated with machinery and equipment to improve their diagnosis, decision-making and/or performing. Agricultural automation can relieve the drudgery of agricultural work, improve the timeliness and precision of agricultural operations, raise productivity and resource-use efficiency, build resilience, and improve food quality and safety. Increased productivity can free up labour, allowing agricultural households to spend more time elsewhere.\nThe technological evolution in agriculture has resulted in progressive shifts to digital equipment and robotics. Motorized mechanization using engine power automates the performance of agricultural operations such as ploughing and milking. With digital automation technologies, it also becomes possible to automate diagnosis and decision-making of agricultural operations. For example, autonomous crop robots can harvest and seed crops, while drones can gather information to help automate input application. Precision agriculture often employs such automation technologies\nMotorized mechanization has generally increased in recent years. Sub-Saharan Africa is the only region where the adoption of motorized mechanization has stalled over the past decades.\nAutomation technologies are increasingly used for managing livestock, though evidence on adoption is lacking. Global automatic milking system sales have increased over recent years, but adoption is likely mostly in Northern Europe, and likely almost absent in low- and middle-income countries. Automated feeding machines for both cows and poultry also exist, but data and evidence regarding their adoption trends and drivers is likewise scarce.", "mimetype": "text/plain", "start_char_idx": 27108, "end_char_idx": 32150, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a2685772-7b72-4fb0-86ae-6cb293074405": {"__data__": {"id_": "a2685772-7b72-4fb0-86ae-6cb293074405", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf4ea3bf-1285-4a56-a604-cfa6a9126b3c", "node_type": "1", "metadata": {}, "hash": "bbdcc77f85ab419bfff19a6a1f80b4b80519395679cc56cbd2e0e008567dc750", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "22b3999a-1bc1-49da-8031-a3c242dd765c", "node_type": "1", "metadata": {}, "hash": "5b7280f985493a4e8d1a2e1a35dc9890d94e3a30d2bfbee11ddb1dc46ba4d798", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Retail ===\n\nMany supermarkets and even smaller stores are rapidly introducing self-checkout systems reducing the need for employing checkout workers. In the U.S., the retail industry employs 15.9 million people as of 2017 (around 1 in 9 Americans in the workforce). Globally, an estimated 192 million workers could be affected by automation according to research by Eurasia Group.\n\n Online shopping could be considered a form of automated retail as the payment and checkout are through an automated online transaction processing system, with the share of online retail accounting jumping from 5.1% in 2011 to 8.3% in 2016.  However, two-thirds of books, music, and films are now purchased online. In addition, automation and online shopping could reduce demands for shopping malls, and retail property, which in the United States is currently estimated to account for 31% of all commercial property or around 7 billion square feet (650 million square metres). Amazon has gained much of the growth in recent years for online shopping, accounting for half of the growth in online retail in 2016. Other forms of automation can also be an integral part of online shopping, for example, the deployment of automated warehouse robotics such as that applied by Amazon using Kiva Systems.\n\n\n=== Food and drink ===\n\nThe food retail industry has started to apply automation to the ordering process; McDonald's has introduced touch screen ordering and payment systems in many of its restaurants, reducing the need for as many cashier employees. The University of Texas at Austin has introduced fully automated cafe retail locations. Some cafes and restaurants have utilized mobile and tablet \"apps\" to make the ordering process more efficient by customers ordering and paying on their device. Some restaurants have automated food delivery to tables of customers using a conveyor belt system. The use of robots is sometimes employed to replace waiting staff.\n\n\n=== Construction ===\n\nAutomation in construction is the combination of methods, processes, and systems that allow for greater machine autonomy in construction activities. Construction automation may have multiple goals, including but not limited to, reducing jobsite injuries, decreasing activity completion times, and assisting with quality control and quality assurance.\n\n\n=== Mining ===\n Automated mining involves the removal of human labor from the mining process. The mining industry is currently in the transition towards automation. Currently, it can still require a large amount of human capital, particularly in the third world where labor costs are low so there is less incentive for increasing efficiency through automation.\n\n\n=== Video surveillance ===\nThe Defense Advanced Research Projects Agency (DARPA) started the research and development of automated visual surveillance and monitoring (VSAM) program, between 1997 and 1999, and airborne video surveillance (AVS) programs, from 1998 to 2002. Currently, there is a major effort underway in the vision community to develop a fully-automated tracking surveillance system. Automated video surveillance monitors people and vehicles in real-time within a busy environment. Existing automated surveillance systems are based on the environment they are primarily designed to observe, i.e., indoor, outdoor or airborne, the number of sensors that the automated system can handle and the mobility of sensors, i.e., stationary camera vs. mobile camera. The purpose of a surveillance system is to record properties and trajectories of objects in a given area, generate warnings or notify the designated authorities in case of occurrence of particular events.\n\n\n=== Highway systems ===\n\nAs demands for safety and mobility have grown and technological possibilities have multiplied, interest in automation has grown. Seeking to accelerate the development and introduction of fully automated vehicles and highways, the U.S. Congress authorized more than $650 million over six years for intelligent transport systems (ITS) and demonstration projects in the 1991 Intermodal Surface Transportation Efficiency Act (ISTEA). Congress legislated in ISTEA that:[T]he Secretary of Transportation shall develop an automated highway and vehicle prototype from which future fully automated intelligent vehicle-highway systems can be developed. Such development shall include research in human factors to ensure the success of the man-machine relationship. The goal of this program is to have the first fully automated highway roadway or an automated test track in operation by 1997. This system shall accommodate the installation of equipment in new and existing motor vehicles.Full automation commonly defined as requiring no control or very limited control by the driver; such automation would be accomplished through a combination of sensor, computer, and communications systems in vehicles and along the roadway. Fully automated driving would, in theory, allow closer vehicle spacing and higher speeds, which could enhance traffic capacity in places where additional road building is physically impossible, politically unacceptable, or prohibitively expensive. Automated controls also might enhance road safety by reducing the opportunity for driver error, which causes a large share of motor vehicle crashes. Other potential benefits include improved air quality (as a result of more-efficient traffic flows), increased fuel economy, and spin-off technologies generated during research and development related to automated highway systems.", "mimetype": "text/plain", "start_char_idx": 32153, "end_char_idx": 37690, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "22b3999a-1bc1-49da-8031-a3c242dd765c": {"__data__": {"id_": "22b3999a-1bc1-49da-8031-a3c242dd765c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2685772-7b72-4fb0-86ae-6cb293074405", "node_type": "1", "metadata": {}, "hash": "2079c047071b5c75b76fe5a6c8b6c76475814471968c01de044fa8caacc68380", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dd52ca4d-1e4f-4183-9aa3-8f0b8b0e444e", "node_type": "1", "metadata": {}, "hash": "feed1acf638f975defb15b77175ef9d994e8d41f193d9bc3482ef17f002bf2ec", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Waste management ===\n\nAutomated waste collection trucks prevent the need for as many workers as well as easing the level of labor required to provide the service.\n\n\n=== Business process ===\n\nBusiness process automation (BPA) is the technology-enabled automation of complex business processes. It can help to streamline a business for simplicity, achieve digital transformation, increase service quality, improve service delivery or contain costs. BPA consists of integrating applications, restructuring labor resources and using software applications throughout the organization. Robotic process automation (RPA; or RPAAI for self-guided RPA 2.0) is an emerging field within BPA and uses AI. BPAs can be implemented in a number of business areas including marketing, sales and workflow.\n\n\n=== Home ===\n\nHome automation (also called domotics) designates an emerging practice of increased automation of household appliances and features in residential dwellings, particularly through electronic means that allow for things impracticable, overly expensive or simply not possible in recent past decades. The rise in the usage of home automation solutions has taken a turn reflecting the increased dependency of people on such automation solutions. However, the increased comfort that gets added through these automation solutions is remarkable.\n\n\n=== Laboratory ===\n\nAutomation is essential for many scientific and clinical applications. Therefore, automation has been extensively employed in laboratories. From as early as 1980 fully automated laboratories have already been working. However, automation has not become widespread in laboratories due to its high cost. This may change with the ability of integrating low-cost devices with standard laboratory equipment. Autosamplers are common devices used in laboratory automation.\n\n\n=== Logistics automation ===\nLogistics automation is the application of computer software or automated machinery to improve the efficiency of logistics operations. Typically this refers to operations within a warehouse or distribution center, with broader tasks undertaken by supply chain engineering systems and enterprise resource planning systems.\n\n\n=== Industrial automation ===\nIndustrial automation deals primarily with the automation of manufacturing, quality control, and material handling processes. General-purpose controllers for industrial processes include programmable logic controllers, stand-alone I/O modules, and computers. Industrial automation is to replace the human action and manual command-response activities with the use of mechanized equipment and logical programming commands. One trend is increased use of machine vision to provide automatic inspection and robot guidance functions, another is a continuing increase in the use of robots. Industrial automation is simply required in industries.\n\n\n==== Industrial Automation and Industry 4.0 ====\nThe rise of industrial automation is directly tied to the \"Fourth Industrial Revolution\", which is better known now as Industry 4.0. Originating from Germany, Industry 4.0 encompasses numerous devices, concepts, and machines, as well as the advancement of the industrial internet of things (IIoT). An \"Internet of Things is a seamless integration of diverse physical objects in the Internet through a virtual representation.\" These new revolutionary advancements have drawn attention to the world of automation in an entirely new light and shown ways for it to grow to increase productivity and efficiency in machinery and manufacturing facilities. Industry 4.0 works with the IIoT and software/hardware to connect in a way that (through communication technologies) add enhancements and improve manufacturing processes. Being able to create smarter, safer, and more advanced manufacturing is now possible with these new technologies. It opens up a manufacturing platform that is more reliable, consistent, and efficient than before. Implementation of systems such as SCADA is an example of software that takes place in Industrial Automation today. SCADA is a supervisory data collection software, just one of the many used in Industrial Automation. Industry 4.0 vastly covers many areas in manufacturing and will continue to do so as time goes on.\n\n\n==== Industrial robotics ====\n\nIndustrial robotics is a sub-branch in industrial automation that aids in various manufacturing processes. Such manufacturing processes include machining, welding, painting, assembling and material handling to name a few. Industrial robots use various mechanical, electrical as well as software systems to allow for high precision, accuracy and speed that far exceed any human performance. The birth of industrial robots came shortly after World War II as the U.S. saw the need for a quicker way to produce industrial and consumer goods. Servos, digital logic and solid-state electronics allowed engineers to build better and faster systems and over time these systems were improved and revised to the point where a single robot is capable of running 24 hours a day with little or no maintenance. In 1997, there were 700,000 industrial robots in use, the number has risen to 1.8M in 2017 In recent years, AI with robotics is also used in creating an automatic labeling solution, using robotic arms as the automatic label applicator, and AI for learning and detecting the products to be labelled.", "mimetype": "text/plain", "start_char_idx": 37693, "end_char_idx": 43078, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd52ca4d-1e4f-4183-9aa3-8f0b8b0e444e": {"__data__": {"id_": "dd52ca4d-1e4f-4183-9aa3-8f0b8b0e444e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "22b3999a-1bc1-49da-8031-a3c242dd765c", "node_type": "1", "metadata": {}, "hash": "5b7280f985493a4e8d1a2e1a35dc9890d94e3a30d2bfbee11ddb1dc46ba4d798", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f4fe29ec-0d43-4bb1-bafa-74d0d934ee44", "node_type": "1", "metadata": {}, "hash": "08c74cbe9622d10777692be54feaeeace33dcd47834c50b0adcb76af48dcc1ba", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Programmable Logic Controllers ====\nIndustrial automation incorporates programmable logic controllers in the manufacturing process. Programmable logic controllers (PLCs) use a processing system which allows for variation of controls of inputs and outputs using simple programming. PLCs make use of programmable memory, storing instructions and functions like logic, sequencing, timing, counting, etc. Using a logic-based language, a PLC can receive a variety of inputs and return a variety of logical outputs, the input devices being sensors and output devices being motors, valves, etc. PLCs are similar to computers, however, while computers are optimized for calculations, PLCs are optimized for control tasks and use in industrial environments. They are built so that only basic logic-based programming knowledge is needed and to handle vibrations, high temperatures, humidity, and noise. The greatest advantage PLCs offer is their flexibility. With the same basic controllers, a PLC can operate a range of different control systems. PLCs make it unnecessary to rewire a system to change the control system. This flexibility leads to a cost-effective system for complex and varied control systems.\nPLCs can range from small \"building brick\" devices with tens of I/O in a housing integral with the processor, to large rack-mounted modular devices with a count of thousands of I/O, and which are often networked to other PLC and SCADA systems.\nThey can be designed for multiple arrangements of digital and analog inputs and outputs (I/O), extended temperature ranges, immunity to electrical noise, and resistance to vibration and impact. Programs to control machine operation are typically stored in battery-backed-up or non-volatile memory.\nIt was from the automotive industry in the United States that the PLC was born. Before the PLC, control, sequencing, and safety interlock logic for manufacturing automobiles was mainly composed of relays, cam timers, drum sequencers, and dedicated closed-loop controllers. Since these could number in the hundreds or even thousands, the process for updating such facilities for the yearly model change-over was very time-consuming and expensive, as electricians needed to individually rewire the relays to change their operational characteristics.\nWhen digital computers became available, being general-purpose programmable devices, they were soon applied to control sequential and combinatorial logic in industrial processes. However, these early computers required specialist programmers and stringent operating environmental control for temperature, cleanliness, and power quality. To meet these challenges, the PLC was developed with several key attributes. It would tolerate the shop-floor environment, it would support discrete (bit-form) input and output in an easily extensible manner, it would not require years of training to use, and it would permit its operation to be monitored. Since many industrial processes have timescales easily addressed by millisecond response times, modern (fast, small, reliable) electronics greatly facilitate building reliable controllers, and performance could be traded off for reliability.\n\n\n==== Agent-assisted automation ====\n\nAgent-assisted automation refers to automation used by call center agents to handle customer inquiries. The key benefit of agent-assisted automation is compliance and error-proofing. Agents are sometimes not fully trained or they forget or ignore key steps in the process. The use of automation ensures that what is supposed to happen on the call actually does, every time. There are two basic types: desktop automation and automated voice solutions.\n\n\n== Control ==\n\n\n=== Open-loop and closed-loop ===\n\n\n=== Discrete control (on/off) ===\nOne of the simplest types of control is on-off control. An example is a thermostat used on household appliances which either open or close an electrical contact. (Thermostats were originally developed as true feedback-control mechanisms rather than the on-off common household appliance thermostat.)\nSequence control, in which a programmed sequence of discrete operations is performed, often based on system logic that involves system states. An elevator control system is an example of sequence control.\n\n\n=== PID controller ===\n\nA proportional\u2013integral\u2013derivative controller (PID controller) is a control loop feedback mechanism (controller) widely used in industrial control systems.\nIn a PID loop, the controller continuously calculates an error value \n  \n    \n      \n        e\n        (\n        t\n        )\n      \n    \n    {\\displaystyle e(t)}\n  \n as the difference between a desired setpoint and a measured process variable and applies a correction based on proportional, integral, and derivative terms, respectively (sometimes denoted P, I, and D) which give their name to the controller type.\nThe theoretical understanding and application date from the 1920s, and they are implemented in nearly all analog control systems; originally in mechanical controllers, and then using discrete electronics and latterly in industrial process computers.", "mimetype": "text/plain", "start_char_idx": 43081, "end_char_idx": 48192, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4fe29ec-0d43-4bb1-bafa-74d0d934ee44": {"__data__": {"id_": "f4fe29ec-0d43-4bb1-bafa-74d0d934ee44", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dd52ca4d-1e4f-4183-9aa3-8f0b8b0e444e", "node_type": "1", "metadata": {}, "hash": "feed1acf638f975defb15b77175ef9d994e8d41f193d9bc3482ef17f002bf2ec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f11a9fcd-c26a-4109-ab06-fdb14a925544", "node_type": "1", "metadata": {}, "hash": "8aaa19230e5654f65ef3f6c6c62bc3cccdd6c9ed08b3adf37f604f23f47bc672", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== PID controller ===\n\nA proportional\u2013integral\u2013derivative controller (PID controller) is a control loop feedback mechanism (controller) widely used in industrial control systems.\nIn a PID loop, the controller continuously calculates an error value \n  \n    \n      \n        e\n        (\n        t\n        )\n      \n    \n    {\\displaystyle e(t)}\n  \n as the difference between a desired setpoint and a measured process variable and applies a correction based on proportional, integral, and derivative terms, respectively (sometimes denoted P, I, and D) which give their name to the controller type.\nThe theoretical understanding and application date from the 1920s, and they are implemented in nearly all analog control systems; originally in mechanical controllers, and then using discrete electronics and latterly in industrial process computers.\n\n\n=== Sequential control and logical sequence or system state control ===\n\nSequential control may be either to a fixed sequence or to a logical one that will perform different actions depending on various system states. An example of an adjustable but otherwise fixed sequence is a timer on a lawn sprinkler.\nStates refer to the various conditions that can occur in a use or sequence scenario of the system. An example is an elevator, which uses logic based on the system state to perform certain actions in response to its state and operator input. For example, if the operator presses the floor n button, the system will respond depending on whether the elevator is stopped or moving, going up or down, or if the door is open or closed, and other conditions.\nEarly development of sequential control was relay logic, by which electrical relays engage electrical contacts which either start or interrupt power to a device. Relays were first used in telegraph networks before being developed for controlling other devices, such as when starting and stopping industrial-sized electric motors or opening and closing solenoid valves. Using relays for control purposes allowed event-driven control, where actions could be triggered out of sequence, in response to external events. These were more flexible in their response than the rigid single-sequence cam timers. More complicated examples involved maintaining safe sequences for devices such as swing bridge controls, where a lock bolt needed to be disengaged before the bridge could be moved, and the lock bolt could not be released until the safety gates had already been closed.\nThe total number of relays and cam timers can number into the hundreds or even thousands in some factories. Early programming techniques and languages were needed to make such systems manageable, one of the first being ladder logic, where diagrams of the interconnected relays resembled the rungs of a ladder. Special computers called programmable logic controllers were later designed to replace these collections of hardware with a single, more easily re-programmed unit.\nIn a typical hard-wired motor start and stop circuit (called a control circuit) a motor is started by pushing a \"Start\" or \"Run\" button that activates a pair of electrical relays. The \"lock-in\" relay locks in contacts that keep the control circuit energized when the push-button is released. (The start button is a normally open contact and the stop button is a normally closed contact.) Another relay energizes a switch that powers the device that throws the motor starter switch (three sets of contacts for three-phase industrial power) in the main power circuit. Large motors use high voltage and experience high in-rush current, making speed important in making and breaking contact. This can be dangerous for personnel and property with manual switches. The \"lock-in\" contacts in the start circuit and the main power contacts for the motor are held engaged by their respective electromagnets until a \"stop\" or \"off\" button is pressed, which de-energizes the lock in relay.\n\nCommonly interlocks are added to a control circuit. Suppose that the motor in the example is powering machinery that has a critical need for lubrication. In this case, an interlock could be added to ensure that the oil pump is running before the motor starts. Timers, limit switches, and electric eyes are other common elements in control circuits.\nSolenoid valves are widely used on compressed air or hydraulic fluid for powering actuators on mechanical components. While motors are used to supply continuous rotary motion, actuators are typically a better choice for intermittently creating a limited range of movement for a mechanical component, such as moving various mechanical arms, opening or closing valves, raising heavy press-rolls, applying pressure to presses.", "mimetype": "text/plain", "start_char_idx": 47349, "end_char_idx": 52049, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f11a9fcd-c26a-4109-ab06-fdb14a925544": {"__data__": {"id_": "f11a9fcd-c26a-4109-ab06-fdb14a925544", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "173354", "node_type": "4", "metadata": {}, "hash": "ace41c27a01538d9103e76fd69f75451656e1fa6a9a7f23ae7c73460d32ccd2e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4fe29ec-0d43-4bb1-bafa-74d0d934ee44", "node_type": "1", "metadata": {}, "hash": "08c74cbe9622d10777692be54feaeeace33dcd47834c50b0adcb76af48dcc1ba", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Computer control ===\nComputers can perform both sequential control and feedback control, and typically a single computer will do both in an industrial application. Programmable logic controllers (PLCs) are a type of special-purpose microprocessor that replaced many hardware components such as timers and drum sequencers used in relay logic\u2013type systems. General-purpose process control computers have increasingly replaced stand-alone controllers, with a single computer able to perform the operations of hundreds of controllers. Process control computers can process data from a network of PLCs, instruments, and controllers to implement typical (such as PID) control of many individual variables or, in some cases, to implement complex control algorithms using multiple inputs and mathematical manipulations. They can also analyze data and create real-time graphical displays for operators and run reports for operators, engineers, and management.\nControl of an automated teller machine (ATM) is an example of an interactive process in which a computer will perform a logic-derived response to a user selection based on information retrieved from a networked database. The ATM process has similarities with other online transaction processes. The different logical responses are called scenarios. Such processes are typically designed with the aid of use cases and flowcharts, which guide the writing of the software code. The earliest feedback control mechanism was the water clock invented by Greek engineer Ctesibius (285\u2013222 BC).\n\n\n== See also ==\n\n\n== References ==\n\n\n=== Citations ===\n\n\n=== Sources ===\n\n This article incorporates text from a free content work. Licensed under CC BY-SA 3.0 (license statement/permission). Text taken from In Brief to The State of Food and Agriculture 2022 \u2013 Leveraging automation in agriculture for transforming agrifood systems\u200b, FAO, FAO.\n\n\n== Further reading ==", "mimetype": "text/plain", "start_char_idx": 52052, "end_char_idx": 53961, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e20ecb3d-41f6-4ed1-b276-d096926b5175": {"__data__": {"id_": "e20ecb3d-41f6-4ed1-b276-d096926b5175", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2711317", "node_type": "4", "metadata": {}, "hash": "04358b3f0fc344060e5eb79f10fee69a96a62d4d2dc5e2eb0a84bbec5a905c9e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "79b9a4bf-d6bb-4325-9259-ff923cc952c8", "node_type": "1", "metadata": {}, "hash": "e041915a83e949f0699d6c6816cecc23b79f1cbd7e2a09e5bc0f66897a00c1a7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. Leading AI textbooks define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\nA specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.\nIntelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria\u2014such as a firm, a state, or a biome.\nIntelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion. For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior. Similarly, an evolutionary algorithm's behavior is guided by a fitness function.\nIntelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\nIntelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents\u2014autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".\n\n\n== Intelligent agents as the foundation of AI ==\n\nThe concept of intelligent agents provides a foundational lens through which to define and understand artificial intelligence. For instance, the influential textbook Artificial Intelligence: A Modern Approach (Russell & Norvig) describes:\n\nAgent: Anything that perceives its environment (using sensors) and acts upon it (using actuators). E.g., a robot with cameras and wheels, or a software program that reads data and makes recommendations.\nRational Agent: An agent that strives to achieve the *best possible outcome* based on its knowledge and past experiences. \"Best\" is defined by a performance measure \u2013 a way of evaluating how well the agent is doing.\nArtificial Intelligence (as a field): The study and creation of these rational agents.\nOther researchers and definitions build upon this foundation. Padgham & Winikoff emphasize that intelligent agents should react to changes in their environment in a timely way, proactively pursue goals, and be flexible and robust (able to handle unexpected situations). Some also suggest that ideal agents should be \"rational\" in the economic sense (making optimal choices) and capable of complex reasoning, like having beliefs, desires, and intentions (BDI model). Kaplan and Haenlein offer a similar definition, focusing on a system's ability to understand external data, learn from that data, and use what is learned to achieve goals through flexible adaptation.\nDefining AI in terms of intelligent agents offers several key advantages:\n\nAvoids Philosophical Debates: It sidesteps arguments about whether AI is \"truly\" intelligent or conscious, like those raised by the Turing test or Searle's Chinese Room. It focuses on behavior and goal achievement, not on replicating human thought.\nObjective Testing: It provides a clear, scientific way to evaluate AI systems. Researchers can compare different approaches by measuring how well they maximize a specific \"goal function\" (or objective function). This allows for direct comparison and combination of techniques.\nInterdisciplinary Communication: It creates a common language for AI researchers to collaborate with other fields like mathematical optimization and economics, which also use concepts like \"goals\" and \"rational agents.\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4385, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "79b9a4bf-d6bb-4325-9259-ff923cc952c8": {"__data__": {"id_": "79b9a4bf-d6bb-4325-9259-ff923cc952c8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2711317", "node_type": "4", "metadata": {}, "hash": "04358b3f0fc344060e5eb79f10fee69a96a62d4d2dc5e2eb0a84bbec5a905c9e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e20ecb3d-41f6-4ed1-b276-d096926b5175", "node_type": "1", "metadata": {}, "hash": "f4f08db6615fd3885660cc88d21219b34a9803372c85bba5cb2bbd405468c582", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bf048a52-23c8-45bf-aed2-c664aab4dd12", "node_type": "1", "metadata": {}, "hash": "f529192abb427d3cc30b6487ec76a7c8aea97ba94f1f85e7b957fa8d6af3140b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Objective function ==\n\nAn objective function (or goal function) specifies the goals of an intelligent agent. An agent is deemed more intelligent if it consistently selects actions that yield outcomes better aligned with its objective function. In effect, the objective function serves as a measure of success.\nThe objective function may be:\n\nSimple: For example, in a game of Go, the objective function might assign a value of 1 for a win and 0 for a loss.\nComplex: It might require the agent to evaluate and learn from past actions, adapting its behavior based on patterns that have proven effective.\nThe objective function encapsulates all of the goals the agent is designed to achieve. For rational agents, it also incorporates the trade-offs between potentially conflicting goals. For instance, a self-driving car's objective function might balance factors such as safety, speed, and passenger comfort.\nDifferent terms are used to describe this concept, depending on the context.  These include:\n\nUtility function:  Often used in economics and decision theory, representing the desirability of a state.\nObjective function: A general term used in optimization.\nLoss function:  Typically used in machine learning, where the goal is to minimize the loss (error).\nReward Function: Used in reinforcement learning.\nFitness Function: Used in evolutionary systems.\nGoals, and therefore the objective function, can be:\n\nExplicitly defined: Programmed directly into the agent.\nInduced: Learned or evolved over time.\nIn reinforcement learning, a \"reward function\" provides feedback, encouraging desired behaviors and discouraging undesirable ones. The agent learns to maximize its cumulative reward.\nIn evolutionary systems, a \"fitness function\" determines which agents are more likely to reproduce. This is analogous to natural selection, where organisms evolve to maximize their chances of survival and reproduction.\nSome AI systems, such as nearest-neighbor, reason by analogy rather than being explicitly goal-driven. However, even these systems can have goals implicitly defined within their training data. Such systems can still be benchmarked by framing the non-goal system as one whose \"goal\" is to accomplish its narrow classification task.\nSystems not traditionally considered agents, like knowledge-representation systems, are sometimes included in the paradigm by framing them as agents with a goal of, for example, answering questions accurately. Here, the concept of an \"action\" is extended to encompass the \"act\" of providing an answer. As a further extension, mimicry-driven systems can be framed as agents optimizing a \"goal function\" based on how closely the IA mimics the desired behavior. In generative adversarial networks (GANs) of the 2010s, an \"encoder\"/\"generator\" component attempts to mimic and improvise human text composition. The generator tries to maximize a function representing how well it can fool an antagonistic \"predictor\"/\"discriminator\" component.\nWhile symbolic AI systems often use an explicit goal function, the paradigm also applies to neural networks and evolutionary computing. Reinforcement learning can generate intelligent agents that appear to act in ways intended to maximize a \"reward function\". Sometimes, instead of setting the reward function directly equal to the desired benchmark evaluation function, machine learning programmers use reward shaping to initially give the machine rewards for incremental progress. Yann LeCun stated in 2018, \"Most of the learning algorithms that people have come up with essentially consist of minimizing some objective function.\" AlphaZero chess had a simple objective function: +1 point for each win, and -1 point for each loss. A self-driving car's objective function would be more complex. Evolutionary computing can evolve intelligent agents that appear to act in ways intended to maximize a \"fitness function\" influencing how many descendants each agent is allowed to leave.\nThe mathematical formalism of AIXI was proposed as a maximally intelligent agent in this paradigm. However, AIXI is uncomputable. In the real world, an IA is constrained by finite time and hardware resources, and scientists compete to produce algorithms that achieve progressively higher scores on benchmark tests with existing hardware.", "mimetype": "text/plain", "start_char_idx": 4388, "end_char_idx": 8692, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bf048a52-23c8-45bf-aed2-c664aab4dd12": {"__data__": {"id_": "bf048a52-23c8-45bf-aed2-c664aab4dd12", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2711317", "node_type": "4", "metadata": {}, "hash": "04358b3f0fc344060e5eb79f10fee69a96a62d4d2dc5e2eb0a84bbec5a905c9e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "79b9a4bf-d6bb-4325-9259-ff923cc952c8", "node_type": "1", "metadata": {}, "hash": "e041915a83e949f0699d6c6816cecc23b79f1cbd7e2a09e5bc0f66897a00c1a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b67c3f51-b117-4f05-a318-616a19a9d58c", "node_type": "1", "metadata": {}, "hash": "487b026d41efcb2002d83efd98c3fcbf513ed562d92c028b032d0ab69e6ebc78", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Agent function ==\nAn intelligent agent's behavior can be described mathematically by an agent function. This function determines what the agent does based on what it has seen.\nA percept refers to the agent's sensory inputs at a single point in time. For example, a self-driving car's percepts might include camera images, lidar data, GPS coordinates, and speed readings at a specific instant. The agent uses these percepts, and potentially its history of percepts, to decide on its next action (e.g., accelerate, brake, turn).\nThe agent function, often denoted as f, maps the agent's entire history of percepts to an action.\nMathematically, this can be represented as:\n\n  \n    \n      \n        f\n        :\n        \n          P\n          \n            \u2217\n          \n        \n        \u2192\n        A\n      \n    \n    {\\displaystyle f:P^{*}\\rightarrow A}\n  \n\nWhere:\n\nP\\* represents the set of all possible percept sequences (the agent's entire perceptual history). The asterisk (*) indicates a sequence of zero or more percepts.\nA represents the set of all possible actions the agent can take.\nf is the agent function that maps a percept sequence to an action.\nIt's crucial to distinguish between the agent function (an abstract mathematical concept) and the agent program (the concrete implementation of that function).\n\nThe agent function is a theoretical description.\nThe agent program is the actual code that runs on the agent. The agent program takes the current percept as input and produces an action as output.\nThe agent function can incorporate a wide range of decision-making approaches, including:\n\nCalculating the utility (desirability) of different actions.\nUsing logical rules and deduction.\nEmploying fuzzy logic.\nOther methods.\n\n\n== Classes of intelligent agents ==\n\n\n=== Russell and Norvig's classification ===\nRussell & Norvig (2003) group agents into five classes based on their degree of perceived intelligence and capability:\n\n\n==== Simple reflex agents ====\n\nSimple reflex agents act only on the basis of the current percept, ignoring the rest of the percept history. The agent function is based on the condition-action rule: \"if condition, then action\".\nThis agent function only succeeds when the environment is fully observable. Some reflex agents can also contain information on their current state which allows them to disregard conditions whose actuators are already triggered.\nInfinite loops are often unavoidable for simple reflex agents operating in partially observable environments. If the agent can randomize its actions, it may be possible to escape from infinite loops.\nA home thermostat, which turns on or off when the temperature drops below a certain point, is an example of a simple reflex agent.\n\n\n==== Model-based reflex agents ====\n\nA model-based agent can handle partially observable environments. Its current state is stored inside the agent, maintaining a structure that describes the part of the world which cannot be seen. This knowledge about \"how the world works\" is referred to as a model of the world, hence the name \"model-based agent\".\nA model-based reflex agent should maintain some sort of internal model that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. Percept history and impact of action on the environment can be determined by using the internal model. It then chooses an action in the same way as reflex agent.\nAn agent may also use models to describe and predict the behaviors of other agents in the environment.\n\n\n==== Goal-based agents ====\n\nGoal-based agents further expand on the capabilities of the model-based agents, by using \"goal\" information. Goal information describes situations that are desirable. This provides the agent a way to choose among multiple possibilities, selecting the one which reaches a goal state. Search and planning are the subfields of artificial intelligence devoted to finding action sequences that achieve the agent's goals.\nChatGPT and the Roomba vacuum are examples of goal-based agents.\n\n\n==== Utility-based agents ====\n\nGoal-based agents only distinguish between goal states and non-goal states. It is also possible to define a measure of how desirable a particular state is. This measure can be obtained through the use of a utility function which maps a state to a measure of the utility of the state. A more general performance measure should allow a comparison of different world states according to how well they satisfied the agent's goals. The term utility can be used to describe how \"happy\" the agent is.\nA rational utility-based agent chooses the action that maximizes the expected utility of the action outcomes - that is, what the agent expects to derive, on average, given the probabilities and utilities of each outcome. A utility-based agent has to model and keep track of its environment, tasks that have involved a great deal of research on perception, representation, reasoning, and learning.", "mimetype": "text/plain", "start_char_idx": 8695, "end_char_idx": 13667, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b67c3f51-b117-4f05-a318-616a19a9d58c": {"__data__": {"id_": "b67c3f51-b117-4f05-a318-616a19a9d58c", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2711317", "node_type": "4", "metadata": {}, "hash": "04358b3f0fc344060e5eb79f10fee69a96a62d4d2dc5e2eb0a84bbec5a905c9e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf048a52-23c8-45bf-aed2-c664aab4dd12", "node_type": "1", "metadata": {}, "hash": "f529192abb427d3cc30b6487ec76a7c8aea97ba94f1f85e7b957fa8d6af3140b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9950fe6d-3155-4f75-b1f5-37fab7e529c8", "node_type": "1", "metadata": {}, "hash": "f485647aadede85ce30d51e812a078294fb7c54585b96776af7d915c27a05fa3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Utility-based agents ====\n\nGoal-based agents only distinguish between goal states and non-goal states. It is also possible to define a measure of how desirable a particular state is. This measure can be obtained through the use of a utility function which maps a state to a measure of the utility of the state. A more general performance measure should allow a comparison of different world states according to how well they satisfied the agent's goals. The term utility can be used to describe how \"happy\" the agent is.\nA rational utility-based agent chooses the action that maximizes the expected utility of the action outcomes - that is, what the agent expects to derive, on average, given the probabilities and utilities of each outcome. A utility-based agent has to model and keep track of its environment, tasks that have involved a great deal of research on perception, representation, reasoning, and learning.\n\n\n==== Learning agents ====\n\nLearning lets agents begin in unknown environments and gradually surpass the bounds of their initial knowledge. A key distinction in such agents is the separation between a \"learning element,\" responsible for improving performance, and a \"performance element,\" responsible for choosing external actions.\nThe learning element gathers feedback from a \"critic\" to assess the agent\u2019s performance and decides how the performance element\u2014also called the \"actor\"\u2014can be adjusted to yield better outcomes. The performance element, once considered the entire agent, interprets percepts and takes actions.\nThe final component, the \"problem generator,\" suggests new and informative experiences that encourage exploration and further improvement.\n\n\n=== Weiss's classification ===\nAccording to Weiss (2013), agents can be categorized into four classes:\n\nLogic-based agents, where decisions about actions are derived through logical deduction.\nReactive agents, where decisions occur through a direct mapping from situation to action.\nBelief\u2013desire\u2013intention agents, where decisions depend on manipulating data structures that represent the agent's beliefs, desires, and intentions.\nLayered architectures, where decision-making takes place across multiple software layers, each of which reasons about the environment at a different level of abstraction.\n\n\n=== Other ===\nIn 2013, Alexander Wissner-Gross published a theory exploring the relationship between Freedom and Intelligence in intelligent agents.\n\n\n== Hierarchies of agents ==\n\nIntelligent agents can be organized hierarchically into multiple \"sub-agents.\" These sub-agents handle lower-level functions, and together with the main agent, they form a complete system capable of executing complex tasks and achieving challenging goals.\nTypically, an agent is structured by dividing it into sensors and actuators. The perception system gathers input from the environment via the sensors and feeds this information to a central controller, which then issues commands to the actuators. Often, a multilayered hierarchy of controllers is necessary to balance the rapid responses required for low-level tasks with the more deliberative reasoning needed for high-level objectives.\n\n\n== Alternative definitions and uses ==\n\"Intelligent agent\" is also often used as a vague term, sometimes synonymous with \"virtual personal assistant\". Some 20th-century definitions characterize an agent as a program that aids a user or that acts on behalf of a user. These examples are known as software agents, and sometimes an \"intelligent software agent\" (that is, a software agent with intelligence) is referred to as an \"intelligent agent\".\nAccording to Nikola Kasabov, IA systems should exhibit the following characteristics:\n\nAccommodate new problem solving rules incrementally.\nAdapt online and in real time.\nAre able to analyze themselves in terms of behavior, error and success.\nLearn and improve through interaction with the environment (embodiment).\nLearn quickly from large amounts of data.\nHave memory-based exemplar storage and retrieval capacities.\nHave parameters to represent short- and long-term memory, age, forgetting, etc.", "mimetype": "text/plain", "start_char_idx": 12745, "end_char_idx": 16858, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9950fe6d-3155-4f75-b1f5-37fab7e529c8": {"__data__": {"id_": "9950fe6d-3155-4f75-b1f5-37fab7e529c8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2711317", "node_type": "4", "metadata": {}, "hash": "04358b3f0fc344060e5eb79f10fee69a96a62d4d2dc5e2eb0a84bbec5a905c9e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b67c3f51-b117-4f05-a318-616a19a9d58c", "node_type": "1", "metadata": {}, "hash": "487b026d41efcb2002d83efd98c3fcbf513ed562d92c028b032d0ab69e6ebc78", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3c8a46ef-ecda-4c7e-a615-cb15bfe2d6f0", "node_type": "1", "metadata": {}, "hash": "9fe0c1aa9b83fc7cf584269879bfb14bc2ec3d74f0dfea051bcf3968b064f5d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Alternative definitions and uses ==\n\"Intelligent agent\" is also often used as a vague term, sometimes synonymous with \"virtual personal assistant\". Some 20th-century definitions characterize an agent as a program that aids a user or that acts on behalf of a user. These examples are known as software agents, and sometimes an \"intelligent software agent\" (that is, a software agent with intelligence) is referred to as an \"intelligent agent\".\nAccording to Nikola Kasabov, IA systems should exhibit the following characteristics:\n\nAccommodate new problem solving rules incrementally.\nAdapt online and in real time.\nAre able to analyze themselves in terms of behavior, error and success.\nLearn and improve through interaction with the environment (embodiment).\nLearn quickly from large amounts of data.\nHave memory-based exemplar storage and retrieval capacities.\nHave parameters to represent short- and long-term memory, age, forgetting, etc.\n\n\n=== Agentic AI ===\nIn the context of generative artificial intelligence, AI agents (also referred to as compound AI systems) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight.\nThey possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user supervision, and the integration of software tools or planning systems. Their control flow is frequently driven by large language models (LLMs).\nA common application of AI agents is the automation of tasks\u2014for example, booking travel plans based on a user's prompted request. Prominent examples include Devin AI, AutoGPT, and SIMA. Further examples of agents released since 2025 include OpenAI Operator, ChatGPT Deep Research, and Manus. Frameworks for building AI agents include LangChain, as well as tools such as CAMEL, Microsoft AutoGen, and OpenAI Swarm.\nProposed protocols for standardizing inter-agent communication include the Agent Protocol (by LangChain), the Model Context Protocol (by Anthropic), AGNTCY, Gibberlink, and the Internet of Agents.\nIn February 2025, Hugging Face released Open Deep Research, an open source version of OpenAI Deep Research.\nGalileo published on Hugging Face a leadership board for agents, which ranks their performance based on their underlying LLMs.\nA non-peer reviewed research survey of 67 agents released by the end of 2024 found that the majority of agents are built by developers based in the United States, built by companies, purposed for coding or computer interaction, have code or documentation, and lack safety policies or evaluations.\n\n\n==== Proposed benefits ====\nProponents argue that AI agents can increase personal and economic productivity, foster greater innovation, and liberate users from monotonous tasks. A Bloomberg opinion piece by Parmy Olson argued that agents are best suited for narrow, repetitive tasks with low risk. Conversely, researchers argue that agents could be applied to web accessibility for people who have disabilities, and researchers at Hugging Face propose that agents could be used for coordinating resources such as during disaster response.\n\n\n==== Concerns ====\nPotential concerns include issues of liability, an increased risk of cybercrime, ethical challenges, as well as problems related to AI safety and AI alignment. Other issues involve data privacy. Additional challenges include weakened human oversight, algorithmic bias, and compounding software errors, as well as issues related to the explainability of agent decisions, security vulnerabilities, problems with underemployment, job displacement, and the potential for user manipulation, misinformation or malinformation. They may also complicate legal frameworks, foster hallucinations, hinder countermeasures against rogue agents, and suffer from the lack of standardized evaluation methods. They have also been criticized for being expensive and having a negative impact on internet traffic and potentially the environment.\nJournalists have described AI agents as part of a push by Big Tech companies to \"automate everything\".\nYoshua Bengio warned at the 2025 World Economic Forum that \"all of the catastrophic scenarios with AGI or superintelligence happen if we have agents\".\nIn March 2025, Scale AI signed a contract with the United States Department of Defense to work with them, in collaboration with Anduril Industries and Microsoft, to develop and deploy AI agents for the purpose of assisting the military with \"operational decision-making.\" Researchers have expressed concerns that agents and the large language models they are based on could be biased towards aggressive foreign policy decisions.\nResearch-focused agents have the risk of consensus bias and coverage bias due to collecting information available on the public Internet. NY Mag unfavorably compared the user workflow of agent-based web browsers to Amazon Alexa, which was \"software talking to software, not humans talking to software pretending to be humans to use software.\"\nAgents have been linked to the Dead Internet Theory due to their ability to both publish and engage with online content.\nAgents may get stuck in infinite loops.", "mimetype": "text/plain", "start_char_idx": 15914, "end_char_idx": 21229, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3c8a46ef-ecda-4c7e-a615-cb15bfe2d6f0": {"__data__": {"id_": "3c8a46ef-ecda-4c7e-a615-cb15bfe2d6f0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2711317", "node_type": "4", "metadata": {}, "hash": "04358b3f0fc344060e5eb79f10fee69a96a62d4d2dc5e2eb0a84bbec5a905c9e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9950fe6d-3155-4f75-b1f5-37fab7e529c8", "node_type": "1", "metadata": {}, "hash": "f485647aadede85ce30d51e812a078294fb7c54585b96776af7d915c27a05fa3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Applications ==\n\nThe concept of agent-based modeling for self-driving cars was discussed as early as 2003.\nHallerbach et al. explored the use of agent-based approaches for developing and validating automated driving systems. Their method involved a digital twin of the vehicle under test and microscopic traffic simulations using independent agents.\nWaymo has developed a multi-agent simulation environment, **Carcraft**, to test algorithms for self-driving cars. This system simulates interactions between human drivers, pedestrians, and automated vehicles. Artificial agents replicate human behavior using real-world data.\nSalesforce's Agentforce is an agentic AI platform that allows for the building of autonomous agents to perform tasks.\nThe Transport Security Administration is also integrating agentic AI into new technologies, including machines to authenticate passenger identities using biometrics and photos, and also for incident response.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== Inline references ==\n\n\n== Other references ==\nDomingos, Pedro (September 22, 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0465065707.\nRussell, Stuart J.; Norvig, Peter (2003). Artificial Intelligence: A Modern Approach (2nd ed.). Upper Saddle River, New Jersey: Prentice Hall. Chapter 2. ISBN 0-13-790395-2.\nKasabov, N. (1998). \"Introduction: Hybrid intelligent adaptive systems\". International Journal of Intelligent Systems. 13 (6): 453\u2013454. doi:10.1002/(SICI)1098-111X(199806)13:6<453::AID-INT1>3.0.CO;2-K. S2CID 120318478.\nWeiss, G. (2013). Multiagent systems (2nd ed.). Cambridge, MA: MIT Press. ISBN 978-0-262-01889-0.", "mimetype": "text/plain", "start_char_idx": 21232, "end_char_idx": 22924, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e708ff84-4768-407a-a18c-b6f0ff14df2e": {"__data__": {"id_": "e708ff84-4768-407a-a18c-b6f0ff14df2e", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "938833", "node_type": "4", "metadata": {}, "hash": "01a114ebc7a0b555e902b806eed4268110b8b08be4f4185b76b5ce3e0ed87bf9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9de43aa1-9fa4-41e5-92c8-3e28858f830b", "node_type": "1", "metadata": {}, "hash": "82c522c9bcdf17ef17b8b090cdf0355fe07c32cc96ac8e9cc058edd3dfba97ae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A multi-agent system (MAS or \"self-organized system\") is a computerized system composed of multiple interacting intelligent agents. Multi-agent systems can solve problems that are difficult or impossible for an individual agent or a monolithic system to solve. Intelligence may include methodic, functional, procedural approaches, algorithmic search or reinforcement learning. With advancements in large language models (LLMs), LLM-based multi-agent systems have emerged as a new area of research, enabling more sophisticated interactions and coordination among agents.\nDespite considerable overlap, a multi-agent system is not always the same as an agent-based model (ABM).  The goal of an ABM is to search for explanatory insight into the collective behavior of agents (which do not necessarily need to be \"intelligent\") obeying simple rules, typically in natural systems, rather than in solving specific practical or engineering problems. The terminology of ABM tends to be used more often in the science, and MAS in engineering and technology. Applications where multi-agent systems research may deliver an appropriate approach include online trading, disaster response, target surveillance and social structure modelling.\n\n\n== Concept ==\nMulti-agent systems consist of agents and their environment. Typically multi-agent systems research refers to software agents. However, the agents in a multi-agent system could equally well be robots, humans or human teams. A multi-agent system may contain combined human-agent teams.\nAgents can be divided into types spanning simple to complex. Categories include:\n\nPassive agents or \"agent without goals\" (such as obstacle, apple or key in any simple simulation)\nActive agents with simple goals (like birds in flocking, or wolf\u2013sheep in prey-predator model)\nCognitive agents (complex calculations)\nAgent environments can be divided into:\n\nVirtual\nDiscrete\nContinuous\nAgent environments can also be organized according to properties such as accessibility (whether it is possible to gather complete information about the environment), determinism (whether an action causes a definite effect), dynamics (how many entities influence the environment in the moment), discreteness (whether the number of possible actions in the environment is finite), episodicity (whether agent actions in certain time periods influence other periods), and dimensionality (whether spatial characteristics are important factors of the environment and the agent considers space in its decision making). Agent actions are typically mediated via an appropriate middleware. This middleware offers a first-class design abstraction for multi-agent systems, providing means to govern resource access and agent coordination.\n\n\n=== Characteristics ===\nThe agents in a multi-agent system have several important characteristics:\n\nAutonomy: agents at least partially independent, self-aware, autonomous\nLocal views: no agent has a full global view, or the system is too complex for an agent to exploit such knowledge\nDecentralization: no agent is designated as controlling (or the system is effectively reduced to a monolithic system)\n\n\n=== Self-organisation and self-direction ===\nMulti-agent systems can manifest self-organisation as well as self-direction and other control paradigms and related complex behaviors even when the individual strategies of all their agents are simple. When agents can share knowledge using any agreed language, within the constraints of the system's communication protocol, the approach may lead to a common improvement. Example languages are Knowledge Query Manipulation Language (KQML) or Agent Communication Language (ACL).\n\n\n=== System paradigms ===\nMany MAS are implemented in computer simulations, stepping the system through discrete \"time steps\". The MAS components communicate typically using a weighted request matrix, e.g. \n\n Speed-VERY_IMPORTANT: min=45 mph, \n Path length-MEDIUM_IMPORTANCE: max=60 expectedMax=40, \n Max-Weight-UNIMPORTANT \n Contract Priority-REGULAR \n\nand a weighted response matrix, e.g. \n\n Speed-min:50 but only if weather sunny, \n Path length:25 for sunny / 46 for rainy\n Contract Priority-REGULAR\n note \u2013 ambulance will override this priority and you'll have to wait\n\nA challenge-response-contract scheme is common in MAS systems, where \n\nFirst a \"Who can?\" question is distributed.\nOnly the relevant components respond: \"I can, at this price\".\nFinally, a contract is set up, usually in several short communication steps between sides,\nalso considering other components, evolving \"contracts\" and the restriction sets of the component algorithms.\nAnother paradigm commonly used with MAS is the \"pheromone\", where components leave information for other nearby components. These pheromones may evaporate/concentrate with time, that is their values may decrease (or increase).\n\n\n=== Properties ===\nMAS tend to find the best solution for their problems without intervention. There is high similarity here to physical phenomena, such as energy minimizing, where physical objects tend to reach the lowest energy possible within the physically constrained world. For example: many of the cars entering a metropolis in the morning will be available for leaving that same metropolis in the evening.\nThe systems also tend to prevent propagation of faults, self-recover and be fault tolerant, mainly due to the redundancy of components.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5400, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9de43aa1-9fa4-41e5-92c8-3e28858f830b": {"__data__": {"id_": "9de43aa1-9fa4-41e5-92c8-3e28858f830b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "938833", "node_type": "4", "metadata": {}, "hash": "01a114ebc7a0b555e902b806eed4268110b8b08be4f4185b76b5ce3e0ed87bf9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e708ff84-4768-407a-a18c-b6f0ff14df2e", "node_type": "1", "metadata": {}, "hash": "7210191c9ae30829e958fae349d5f4448964fc32ec9ad963a752351ae8e02b9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2e3fa510-e4d3-4bf0-b190-f73aaba40932", "node_type": "1", "metadata": {}, "hash": "3cf6ae29702d6e75626bbe61537cb82b4120512ae71284e20720a2a3b6c35e50", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Properties ===\nMAS tend to find the best solution for their problems without intervention. There is high similarity here to physical phenomena, such as energy minimizing, where physical objects tend to reach the lowest energy possible within the physically constrained world. For example: many of the cars entering a metropolis in the morning will be available for leaving that same metropolis in the evening.\nThe systems also tend to prevent propagation of faults, self-recover and be fault tolerant, mainly due to the redundancy of components.\n\n\n== Research ==\nThe study of multi-agent systems is \"concerned with the development and analysis of sophisticated AI problem-solving and control architectures for both single-agent and multiple-agent systems.\" Research topics include:\n\nagent-oriented software engineering\nbeliefs, desires, and intentions (BDI)\ncooperation and coordination\ndistributed constraint optimization (DCOPs)\norganization\ncommunication\nnegotiation\ndistributed problem solving\nmulti-agent learning\nagent mining\nscientific communities (e.g., on biological flocking, language evolution, and economics)\ndependability and fault-tolerance\nrobotics, multi-robot systems (MRS), robotic clusters\nmulti-agent systems also present possible applications in microrobotics, where the physical interaction between the agents are exploited to perform complex tasks such as manipulation and assembly of passive components.\nlanguage model-based multi-agent systems\n\n\n== Frameworks ==\nFrameworks have emerged that implement common standards (such as the FIPA and OMG MASIF standards). These frameworks e.g. JADE, save time and aid in the standardization of MAS development.\nCurrently though, no standard is actively maintained from FIPA or OMG. Efforts for further development of software agents in industrial context are carried out in IEEE IES technical committee on Industrial Agents.\nWith advancements in large language models (LLMs) such as ChatGPT, LLM-based multi-agent frameworks, such as CAMEL, have emerged as a new paradigm for developing multi-agent applications.\n\n\n== Applications ==\nMAS have not only been applied in academic research, but also in industry. MAS are applied in the real world to graphical applications such as computer games. Agent systems have been used in films. It is widely advocated for use in networking and mobile technologies, to achieve automatic and dynamic load balancing, high scalability and self-healing networks. They are being used for coordinated defence systems.\nOther applications include transportation, logistics, graphics, manufacturing, power system, smartgrids, and the GIS.\nAlso, Multi-agent Systems Artificial Intelligence (MAAI) are used for simulating societies, the purpose thereof being helpful in the fields of climate, energy, epidemiology, conflict management, child abuse, .... \nSome organisations working on using multi-agent system models include Center for Modelling Social Systems, Centre for Research in Social Simulation, Centre for Policy Modelling, Society for Modelling and Simulation International.\nVehicular traffic with controlled autonomous vehicles can be modelling as a multi-agent system involving crowd dynamics.\nHallerbach et al. discussed the application of agent-based approaches for the development and validation of automated driving systems via a digital twin of the vehicle-under-test and microscopic traffic simulation based on independent agents. Waymo has created a multi-agent simulation environment Carcraft to test algorithms for self-driving cars. It simulates traffic interactions between human drivers, pedestrians and automated vehicles. People's behavior is imitated by artificial agents based on data of real human behavior.\n\n\n== See also ==\n\n\n== References ==", "mimetype": "text/plain", "start_char_idx": 4851, "end_char_idx": 8618, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2e3fa510-e4d3-4bf0-b190-f73aaba40932": {"__data__": {"id_": "2e3fa510-e4d3-4bf0-b190-f73aaba40932", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "938833", "node_type": "4", "metadata": {}, "hash": "01a114ebc7a0b555e902b806eed4268110b8b08be4f4185b76b5ce3e0ed87bf9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9de43aa1-9fa4-41e5-92c8-3e28858f830b", "node_type": "1", "metadata": {}, "hash": "82c522c9bcdf17ef17b8b090cdf0355fe07c32cc96ac8e9cc058edd3dfba97ae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nWooldridge, Michael (2002). An Introduction to MultiAgent Systems. John Wiley & Sons. p. 366. ISBN 978-0-471-49691-5.\nShoham, Yoav; Leyton-Brown, Kevin (2008). Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations. Cambridge University Press. p. 496. ISBN 978-0-521-89943-7.\nMamadou, Tadiou Kon\u00e9; Shimazu, A.; Nakajima, T. (August 2000). \"The State of the Art in Agent Communication Languages (ACL)\". Knowledge and Information Systems. 2 (2): 1\u201326.\nHewitt, Carl; Inman, Jeff (November\u2013December 1991). \"DAI Betwixt and Between: From \"Intelligent Agents\" to Open Systems Science\" (PDF). IEEE Transactions on Systems, Man, and Cybernetics. 21 (6): 1409\u20131419. doi:10.1109/21.135685. S2CID 39080989. Archived from the original (PDF) on August 31, 2017.\nThe Journal of Autonomous Agents and Multi-Agent Systems (JAAMAS)\nWeiss, Gerhard, ed. (1999). Multiagent Systems, A Modern Approach to Distributed Artificial Intelligence. MIT Press. ISBN 978-0-262-23203-6.\nFerber, Jacques (1999). Multi-Agent Systems: An Introduction to Artificial Intelligence. Addison-Wesley. ISBN 978-0-201-36048-6.\nWeyns, Danny (2010). Architecture-Based Design of Multi-Agent Systems. Springer. ISBN 978-3-642-01063-7.\nSun, Ron (2006). Cognition and Multi-Agent Interaction. Cambridge University Press. ISBN 978-0-521-83964-8.\nKeil, David; Goldin, Dina (2006). Weyns, Danny; Parunak, Van; Michel, Fabien (eds.). Indirect Interaction in Environments for Multiagent Systems. LNCS 3830. Vol. 3830. Springer. pp. 68\u201387. doi:10.1007/11678809_5. ISBN 978-3-540-32614-4. {{cite book}}: |journal= ignored (help)\nWhitestein Series in Software Agent Technologies and Autonomic Computing, published by Springer Science+Business Media Group\nSalamon, Tomas (2011). Design of Agent-Based Models : Developing Computer Simulations for a Better Understanding of Social Processes. Bruckner Publishing. ISBN 978-80-904661-1-1.\nRussell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2\nFasli, Maria (2007). Agent-technology for E-commerce. John Wiley & Sons. p. 480. ISBN 978-0-470-03030-1.\nCao, Longbing, Gorodetsky, Vladimir, Mitkas, Pericles A. (2009). Agent Mining: The Synergy of Agents and Data Mining, IEEE Intelligent Systems, vol. 24, no. 3, 64-72.", "mimetype": "text/plain", "start_char_idx": 8585, "end_char_idx": 10973, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "617789a6-69ab-4920-8950-099df217baf8": {"__data__": {"id_": "617789a6-69ab-4920-8950-099df217baf8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08c57786-33f6-48c1-b70a-1dd6fc1836f1", "node_type": "1", "metadata": {}, "hash": "e99bc87ebf9804d68e2a8e76102b412d797ea3ff341ba3a197d066b3052dca0d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Artificial intelligence (AI) has been used in applications throughout industry and academia. In a manner analogous to electricity or computers, AI serves as a general-purpose technology. AI programs are designed to simulate human perception and understanding. These systems are capable of adapting to new information and responding to changing situations. Machine learning has been used for various scientific and commercial purposes including language translation, image recognition, decision-making, credit scoring, and e-commerce.\nArtificial Intelligence (AI) is all about creating computer systems that act like people. This means they can understand information and human language and make decisions similar to how we do.  Artificial intelligence technologies are now being used across various industries, transforming how they function and creating new opportunities. This article provides an overview of the applications of AI in fields like health care, finance, and education, while also discussing the challenges and future prospects in these areas. \n\n\n== Internet and e-commerce ==\n\n\n=== Web feeds and posts ===\nMachine learning has been used for recommendation systems in determining which posts should show up in social media feeds. Various types of social media analysis also make use of machine learning and there is research into its use for (semi-)automated tagging/enhancement/correction of online misinformation and related filter bubbles.\nAI has been used to customize shopping options and personalize offers. Online gambling companies have used AI for targeting gamblers.\n\n\n=== Virtual assistants and search ===\n\nIntelligent personal assistants use AI to understand many natural language requests in other ways than rudimentary commands. Common examples are Apple's Siri, Amazon's Alexa, and a more recent AI, ChatGPT by OpenAI.\nBing Chat has used artificial intelligence as part of its search engine.\n\n\n=== Spam filtering ===\n\nMachine learning can be used to combat spam, scams, and phishing. It can scrutinize the contents of spam and phishing attacks to attempt to identify malicious elements. Some models built via machine learning algorithms have over 90% accuracy in distinguishing between spam and legitimate emails. These models can be refined using new data and evolving spam tactics. Machine learning also analyzes traits such as sender behavior, email header information, and attachment types, potentially enhancing spam detection.\n\n\n=== Language translation ===\n\nSpeech translation technology attempts to convert one language's spoken words into another language. This potentially reduces language barriers in global commerce and cross-cultural exchange, enabling speakers of various languages to communicate with one another.\nAI has been used to automatically translate spoken language and textual content in products such as Microsoft Translator, Google Translate, and DeepL Translator. Additionally, research and development are in progress to decode and conduct animal communication.\nMeaning is conveyed not only by text, but also through usage and context (see semantics and pragmatics). As a result, the two primary categorization approaches for machine translations are statistical machine translation (SMT) and neural machine translations (NMTs). The old method of performing translation was to use statistical methodology to forecast the best probable output with specific algorithms. However, with NMT, the approach employs dynamic algorithms to achieve better translations based on context.\n\n\n=== Facial recognition and image labeling ===\n\nAI has been used in facial recognition systems. Some examples are Apple's Face ID and Android's Face Unlock, which are used to secure mobile devices.\nImage labeling has been used by Google Image Labeler to detect products in photos and to allow people to search based on a photo. Image labeling has also been demonstrated to generate speech to describe images to blind people. Facebook's DeepFace identifies human faces in digital images.\nSocial media sites and content aggregators use AI systems to make personalized news feeds by watching users' actions and engagement history.\u202fContent moderation often relies on AI to spot harmful content, though these systems have trouble with understanding the bigger picture.\nSearch engines use rules to rank results and understand what people want, while virtual helpers like Siri and Alexa use everyday language to read user queries. Email services use learning tools to find spam by checking the content and patterns.\nNeural machine translation systems have gotten much better at translating text. It works by examining complete sentences to maintain accuracy. Computer vision systems can identify people in images and videos. This assists with tasks like sorting photos and performing security checks. AI is often used for surveillance for credit systems, targeted advertising and automation we can erode privacy and concentrate power. It also led to dystopian outcomes such as autonomous systems making unaccountable decisions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5056, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "08c57786-33f6-48c1-b70a-1dd6fc1836f1": {"__data__": {"id_": "08c57786-33f6-48c1-b70a-1dd6fc1836f1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "617789a6-69ab-4920-8950-099df217baf8", "node_type": "1", "metadata": {}, "hash": "d6dd62544bcb0e6465da4fe7b46c9eb4bb226cf55a5e8259afd1bd8854474775", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bcd02966-ae82-4d7d-a0e7-0005f37e8992", "node_type": "1", "metadata": {}, "hash": "a15c5a1a8065c8215a0a7f5a35a7f80475b32e420766b81b390ddf99f3309211", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Games and entertainment ==\n\nGames have been a major application of AI's capabilities since the 1950s. In the 21st century, AIs have beaten human players in many games, including chess (Deep Blue), Jeopardy! (Watson), Go (AlphaGo), poker (Pluribus and Cepheus), E-sports (StarCraft), and general game playing (AlphaZero and MuZero).\nKuki AI is a set of chatbots and other apps which were designed for entertainment and as a marketing tool. Character.ai is another example of a chatbot being used for recreation.\nAI has changed gaming by making smart non-player characters (NPCs) that can adjust. Algorithms can now create game worlds and situations on their own, which reduces development costs and revives the excitement to play again. In digital art and music, AI tools help people express themselves in fresh, new ways using generative algorithms.\nRecommendation systems on streaming platforms check how people watch to suggest content. This greatly affects the way viewers enjoy the media.\n\n\n== Economic and social challenges ==\nAI for Good is a platform launched in 2017 by the International Telecommunication Union (ITU) agency of the United Nations (UN). The goal of the platform is to use AI to help achieve the UN's Sustainable Development Goals.\nThe University of Southern California launched the Center for Artificial Intelligence in Society, with the goal of using AI to address problems such as homelessness. Stanford researchers use AI to analyze satellite images to identify high poverty areas.\n\n\n== Agriculture ==\n\nIn agriculture, AI has been proposed as a way for farmers to identify areas that need irrigation, fertilization, or pesticide treatments to increase yields, thereby improving efficiency. AI has been used to attempt to classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and optimize irrigation.\nPrecision farming uses machine learning and data from satellites, drones and sensors to water, fertilize and manage pests. Computer vision helps keep an eye on plant health, spot diseases and even help with automated harvesting of specific crops. With predictive analytics farmers can make better decisions by predicting weather patterns and knowing when to plant.\nAI helps with livestock management by tracking animal health and production. These are the tools of \u201csmart farming\u201d. They make farming better and more sustainable.\n\n\n== Cyber security ==\nCyber security companies are adopting neural networks, machine learning, and natural language processing to improve their systems.\nApplications of AI in cyber security include:\n\nNetwork protection: Machine learning improves intrusion detection systems by broadening the search beyond previously identified threats.\nEndpoint protection: Attacks such as ransomware can be thwarted by learning typical malware behaviors.\nAI-related cyber security application cases vary in both benefit and complexity. Security features such as Security Orchestration, Automation, and Response (SOAR) and Extended Endpoint Detection and Response (XDR) offer significant benefits for businesses, but require significant integration and adaptation efforts.\nApplication security: can help counterattacks such as server-side request forgery, SQL injection, cross-site scripting, and distributed denial-of-service.\nAI technology can also be utilized to improve system security and safeguard our privacy. Randrianasolo (2012) suggested a security system based on artificial intelligence that can recognize intrusions and adapt to perform better. In order to improve cloud computing security, Sahil (2015) created a user profile system for the cloud environment with AI techniques.\nSuspect user behavior: Machine learning can identify fraud or compromised applications as they occur.\nMachine learning tools look at traffic patterns. They find an unusual activity that might be a security breach. Automated systems gather and analyze data. Their goal is to find new threats before they do significant damage. User behavior analytics establish normal patterns for users and systems that alert when there is a change that might mean a hacked account.\nAI brings new challenges to cybersecurity. Attackers are using the same tools to plan smarter attacks. This is an ongoing race to technological arms race.\n\n\n== Education ==\n\nAI elevates teaching, focusing on significant issues like the knowledge nexus and educational equality. The evolution of AI in education and technology should be used to improve human capabilities in relationships where they do not replace humans. UNESCO recognizes the future of AI in education as an instrument to reach Sustainable Development Goal 4, called \"Inclusive and Equitable Quality Education.\u201d \nThe World Economic Forum also stresses AI's contribution to students' overall improvement and transforming teaching into a more enjoyable process.\n\n\n=== Personalized Learning ===\nAI driven tutoring systems, such as Khan Academy, Duolingo and Carnegie Learning are the forefoot of delivering personalized education.\nThese platforms leverage AI algorithms to analyze individual learning patterns, strengths, and weaknesses, enabling the customization of content and Algorithm to suit each student's pace and style of learning.", "mimetype": "text/plain", "start_char_idx": 5059, "end_char_idx": 10300, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bcd02966-ae82-4d7d-a0e7-0005f37e8992": {"__data__": {"id_": "bcd02966-ae82-4d7d-a0e7-0005f37e8992", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "08c57786-33f6-48c1-b70a-1dd6fc1836f1", "node_type": "1", "metadata": {}, "hash": "e99bc87ebf9804d68e2a8e76102b412d797ea3ff341ba3a197d066b3052dca0d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8065b322-4954-4378-a3b1-8e6997e75194", "node_type": "1", "metadata": {}, "hash": "3034060bfecb3ea7456dd1f9409a7ed764c70230f156d9e932d70c0f5eca076b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Education ==\n\nAI elevates teaching, focusing on significant issues like the knowledge nexus and educational equality. The evolution of AI in education and technology should be used to improve human capabilities in relationships where they do not replace humans. UNESCO recognizes the future of AI in education as an instrument to reach Sustainable Development Goal 4, called \"Inclusive and Equitable Quality Education.\u201d \nThe World Economic Forum also stresses AI's contribution to students' overall improvement and transforming teaching into a more enjoyable process.\n\n\n=== Personalized Learning ===\nAI driven tutoring systems, such as Khan Academy, Duolingo and Carnegie Learning are the forefoot of delivering personalized education.\nThese platforms leverage AI algorithms to analyze individual learning patterns, strengths, and weaknesses, enabling the customization of content and Algorithm to suit each student's pace and style of learning.\n\n\n=== Administrative Efficiency ===\nIn educational institutions, AI is increasingly used to automate routine tasks like attendance tracking, grading and marking, which allows educators to devote more time to interactive teaching and direct student engagement.\nFurthermore, AI tools are employed to monitor student progress, analyze learning behaviors, and predict academic challenges, facilitating timely and proactive interventions for students who may be at risk of falling behind.\n\n\n=== Ethical and Privacy Concerns ===\nDespite the benefits, the integration of AI in education raises significant ethical and privacy concerns, particularly regarding the handling of sensitive student data.\nIt is imperative that AI systems in education are designed and operated with a strong emphasis on transparency, security, and respect for privacy to maintain trust and uphold the integrity of educational practices.\nMuch of the regulation will be influenced by the AI Act, the world's first comprehensive AI law.\nIntelligent tutoring systems provide personalized learning by adapting content based on how each student performs.\u202f Automated assessment tools check student work and give fast feedback which reduces the tutor workload. Learning analytics platforms can find students who might have trouble sooner. They do this by looking for patterns connected to learning issues.\nContent creation tools assist teachers in making learning materials that fit each student's needs. This includes turning text into several languages. Even though these tools offer many benefits, there are still concerns about data privacy. People worry it could also widen the current gaps in education.\n\n\n== Finance ==\nFinancial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking began in 1987 when Security Pacific National Bank launched a fraud prevention task-force to counter the unauthorized use of debit cards.\nBanks use AI to organize operations for bookkeeping, investing in stocks, and managing properties. AI can adapt to changes during non-business hours. AI is used to combat fraud and financial crimes by monitoring behavioral patterns for any abnormal changes or anomalies.\nThe use of AI in applications such as online trading and decision-making has changed major economic theories. For example, AI-based buying and selling platforms estimate personalized demand and supply curves, thus enabling individualized pricing. AI systems reduce information asymmetry in the market and thus make markets more efficient. The application of artificial intelligence in the financial industry can alleviate the financing constraints of non-state-owned enterprises, especially for smaller and more innovative enterprises.\nAlgorithmic trading systems make trades much quicker and in larger amounts than human traders. Robo-advisors provide automatic advice for investing and managing your money at a lower cost than human advisors.\u202fInsurance and lending companies use machine learning to determine risks and set prices.\nFinancial groups use AI systems to check transactions for money laundering. They do this by spotting strange patterns. Auditing gets better with detection algorithms. These algorithms find unusual financial transactions.\n\n\n=== Trading and investment ===\nAlgorithmic trading involves using AI systems to make trading decisions at speeds of magnitude greater than any human is capable of, making millions of trades in a day without human intervention. Such high-frequency trading represents a fast-growing sector. Many banks, funds, and proprietary trading firms now have AI-managed portfolios. Automated trading systems are typically used by large institutional investors but include smaller firms trading with their own AI systems.\nLarge financial institutions use AI to assist with their investment practices. BlackRock's AI engine, Aladdin, is used both within the company and by clients to help with investment decisions. Its functions include the use of natural language processing to analyze text such as news, broker reports, and social media feeds. It then gauges the sentiment on the companies mentioned and assigns a score. Banks such as UBS and Deutsche Bank use SQREEM (Sequential Quantum Reduction and Extraction Model) to mine data to develop consumer profiles and match them with wealth management products.\n\n\n=== Underwriting ===\nOnline lender Upstart uses machine learning for underwriting.\nZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting. This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories.", "mimetype": "text/plain", "start_char_idx": 9352, "end_char_idx": 15149, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8065b322-4954-4378-a3b1-8e6997e75194": {"__data__": {"id_": "8065b322-4954-4378-a3b1-8e6997e75194", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bcd02966-ae82-4d7d-a0e7-0005f37e8992", "node_type": "1", "metadata": {}, "hash": "a15c5a1a8065c8215a0a7f5a35a7f80475b32e420766b81b390ddf99f3309211", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08eb8e3f-7c51-4d98-91f6-d1a4ceab2bf2", "node_type": "1", "metadata": {}, "hash": "32ed3f0f368d297cd06d24645edf5e947349f2e61eddd7b58434d2ab4aaff6c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Underwriting ===\nOnline lender Upstart uses machine learning for underwriting.\nZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting. This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories.\n\n\n=== Audit ===\nAI makes continuous auditing possible. Potential benefits include reducing audit risk, increasing the level of assurance, and reducing audit duration.\nContinuous auditing with AI allows real-time monitoring and reporting of financial activities and provides businesses with timely insights that can lead to quick decision-making.\n\n\n=== Anti-money laundering ===\nAI software, such as LaundroGraph which uses contemporary suboptimal datasets, could be used for anti-money laundering (AML).\n\n\n=== History ===\nIn the 1980s, AI started to become prominent in finance as expert systems were commercialized. For example, Dupont created 100 expert systems, which helped them to save almost $10 million per year. One of the first systems was the Pro-trader expert system that predicted the 87-point drop in the Dow Jones Industrial Average in 1986. \"The major junctions of the system were to monitor premiums in the market, determine the optimum investment strategy, execute transactions when appropriate and modify the knowledge base through a learning mechanism.\"\nOne of the first expert systems to help with financial plans was PlanPowerm and Client Profiling System, created by Applied Expert Systems (APEX). It was launched in 1986. It helped create personal financial plans for people.\nIn the 1990s, AI was applied to fraud detection. In 1993, FinCEN Artificial Intelligence System (FAIS) was launched. It was able to review over 200,000 transactions per week, and over two years, it helped identify 400 potential cases of money laundering equal to $1 billion. These expert systems were later replaced by machine learning systems.\nAI can enhance entrepreneurial activity, and AI is one of the most dynamic areas for start-ups, with significant venture capital flowing into AI.\n\n\n== Government ==\n\nAI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.\n\n\n=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n== Health ==", "mimetype": "text/plain", "start_char_idx": 14740, "end_char_idx": 17938, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "08eb8e3f-7c51-4d98-91f6-d1a4ceab2bf2": {"__data__": {"id_": "08eb8e3f-7c51-4d98-91f6-d1a4ceab2bf2", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8065b322-4954-4378-a3b1-8e6997e75194", "node_type": "1", "metadata": {}, "hash": "3034060bfecb3ea7456dd1f9409a7ed764c70230f156d9e932d70c0f5eca076b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bfc28529-4549-480d-97a1-8fa8ef541660", "node_type": "1", "metadata": {}, "hash": "1114e387dbed719320a3b654aa22db67ec69843d4319be4ae85f3f1fefb1a829", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Government ==\n\nAI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.\n\n\n=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n== Health ==\n\n\n=== Healthcare ===\n\nAI in healthcare is often used for classification, to evaluate a CT scan or electrocardiogram or to identify high-risk patients for population health. AI is helping with the high-cost problem of dosing. One study suggested that AI could save $16 billion. In 2016, a study reported that an AI-derived formula derived the proper dose of immunosuppressant drugs to give to transplant patients. Current research has indicated that non-cardiac vascular illnesses are also being treated with artificial intelligence (AI). For certain disorders, AI algorithms can aid in diagnosis, recommended treatments, outcome prediction, and patient progress tracking. As AI technology advances, it is anticipated that it will become more significant in the healthcare industry.\nThe early detection of diseases like cancer is made possible by AI algorithms, which diagnose diseases by analyzing complex sets of medical data. For example, the IBM Watson system might be used to comb through massive data such as medical records and clinical trials to help diagnose a problem. Microsoft's AI project Hanover helps doctors choose cancer treatments from among the more than 800 medicines and vaccines. Its goal is to memorize all the relevant papers to predict which (combinations of) drugs will be most effective for each patient. Myeloid leukemia is one target. Another study reported on an AI that was as good as doctors in identifying skin cancers. Another project monitors multiple high-risk patients by asking each patient questions based on data acquired from doctor/patient interactions. In one study done with transfer learning, an AI diagnosed eye conditions similar to an ophthalmologist and recommended treatment referrals.\nAnother study demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel judged better than a surgeon.\nArtificial neural networks are used as clinical decision support systems for medical diagnosis, such as in concept processing technology in EMR software.\nOther healthcare tasks thought suitable for an AI that are in development include:\n\nScreening\nHeart sound analysis\nCompanion robots for elder care\nMedical record analysis\nTreatment plan design\nMedication management\nAssisting blind people\nConsultations\nDrug creation (e.g. by identifying candidate drugs and by using existing drug screening data such as in life extension research)\nClinical training\nOutcome prediction for surgical procedures\nHIV prognosis\nIdentifying genomic pathogen signatures of novel pathogens or identifying pathogens via physics-based fingerprints (including pandemic pathogens)\nHelping link genes to their functions, otherwise analyzing genes and identification of novel biological targets\nHelp development of biomarkers\nHelp tailor therapies to individuals in personalized medicine/precision medicine\n\n\n=== Workplace health and safety ===\n\nAI-enabled chatbots decrease the need for humans to perform basic call center tasks.\nMachine learning in sentiment analysis can spot fatigue in order to prevent overwork. Similarly, decision support systems can prevent industrial disasters and make disaster response more efficient. For manual workers in material handling, predictive analytics may be used to reduce musculoskeletal injury. Data collected from wearable sensors can improve workplace health surveillance, risk assessment, and research.\nAI can auto-code workers' compensation claims. AI-enabled virtual reality systems can enhance safety training for hazard recognition. AI can more efficiently detect accident near misses, which are important in reducing accident rates, but are often underreported.\n\n\n=== Biochemistry ===\nAlphaFold 2 can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million).\nMedical imaging analysis systems can spot patterns that indicate diseases such as cancer. They can do this just as well as human experts. Predictive analytics can help identify patients with a higher risk for specific conditions. This helps in starting treatments earlier.\nNatural language processing gets key information from electronic health records. This helps doctors make better choices. Machine learning helps find new drugs by predicting how molecules will work together. This can quicken the development of new treatments. Personalized medicine uses AI to change treatments to match each patient\u2019s needs.", "mimetype": "text/plain", "start_char_idx": 16942, "end_char_idx": 22578, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bfc28529-4549-480d-97a1-8fa8ef541660": {"__data__": {"id_": "bfc28529-4549-480d-97a1-8fa8ef541660", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "08eb8e3f-7c51-4d98-91f6-d1a4ceab2bf2", "node_type": "1", "metadata": {}, "hash": "32ed3f0f368d297cd06d24645edf5e947349f2e61eddd7b58434d2ab4aaff6c2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3192e549-ef5f-47a7-82e0-f49917e5f0db", "node_type": "1", "metadata": {}, "hash": "9e0860ab3cce3983f1d557a7579a378b73485c40d8b1e1f03da1943e79491065", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Biochemistry ===\nAlphaFold 2 can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million).\nMedical imaging analysis systems can spot patterns that indicate diseases such as cancer. They can do this just as well as human experts. Predictive analytics can help identify patients with a higher risk for specific conditions. This helps in starting treatments earlier.\nNatural language processing gets key information from electronic health records. This helps doctors make better choices. Machine learning helps find new drugs by predicting how molecules will work together. This can quicken the development of new treatments. Personalized medicine uses AI to change treatments to match each patient\u2019s needs. \n\n\n== Chemistry and biology ==\n\nMachine learning has been used for drug design. It has also been used for predicting molecular properties and exploring large chemical/reaction spaces. Computer-planned syntheses via computational reaction networks, described as a platform that combines \"computational synthesis with AI algorithms to predict molecular properties\", have been used to explore the origins of life on Earth, drug-syntheses and developing routes for recycling 200 industrial waste chemicals into important drugs and agrochemicals (chemical synthesis design). There is research about which types of computer-aided chemistry would benefit from machine learning. It can also be used for \"drug discovery and development, drug repurposing, improving pharmaceutical productivity, and clinical trials\". It has been used for the design of proteins with prespecified functional sites.\nIt has been used with databases for the development of a 46-day process to design, synthesize and test a drug which inhibits enzymes of a particular gene, DDR1. DDR1 is involved in cancers and fibrosis which is one reason for the high-quality datasets that enabled these results.\nThere are various types of applications for machine learning in decoding human biology, such as helping to map gene expression patterns to functional activation patterns or identifying functional DNA motifs. It is widely used in genetic research.\nThere also is some use of machine learning in synthetic biology, disease biology, nanotechnology (e.g. nanostructured materials and bionanotechnology), and materials science.\n\n\n=== Novel types of machine learning ===\n\nThere are also prototype robot scientists, including robot-embodied ones like the two Robot Scientists, which show a form of \"machine learning\" not commonly associated with the term.\nSimilarly, there is research and development of biological \"wetware computers\" that can learn (e.g. for use as biosensors) and/or implantation into an organism's body (e.g. for use to control prosthetics). Polymer-based artificial neurons operate directly in biological environments and define biohybrid neurons made of artificial and living components.\nMoreover, if whole brain emulation is possible via both scanning and replicating, at a minimum, the bio-chemical brain \u2013 as premised in the form of digital replication in The Age of Em, possibly using physical neural networks \u2013 that may have applications as or more extensive than e.g. valued human activities and may imply that society would face substantial moral choices, societal risks and ethical problems such as whether (and how) such are built, sent through space and used compared to potentially competing e.g. potentially more synthetic and/or less human and/or non/less-sentient types of artificial/semi-artificial intelligence. An alternative or additive approach to scanning are types of reverse engineering of the brain.\nA subcategory of artificial intelligence is embodied, some of which are mobile robotic systems that each consist of one or multiple robots that are able to learn in the physical world.\n\n\n==== Digital ghosts ====\n\n\n==== Biological computing in AI and as AI ====\nAdditionally, biological computers, even if both artificial and highly intelligent, are typically distinguishable from synthetic, predominantly silicon-based, computers.  The two technologies could, however, be combined and used for the design of either. Moreover, many tasks may be poorly carried out by AI even if it uses algorithms that are transparent, understood, bias-free, apparently effective and goal-aligned in addition to having trained data sets that are sufficiently large and cleansed.  This may occur, for instance, when the underlying data, available metrics, values or training methods are incorrect, flawed or used inappropriately. Computer-aided is a phrase used to describe human activities that make use of computing as tool in more comprehensive activities and systems such as AI for narrow tasks or making use of such without substantially relying on its results (see also: human-in-the-loop). One study described the biological component as a limitation of AI stating that \"as long as the biological system cannot be understood, formalized, and imitated, we will not be able to develop technologies that can mimic it\" and that, even if it were understood, this does not necessarily mean there will be \"a technological solution to imitate natural intelligence\". Technologies that integrate biology and AI include biorobotics.", "mimetype": "text/plain", "start_char_idx": 21655, "end_char_idx": 27092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3192e549-ef5f-47a7-82e0-f49917e5f0db": {"__data__": {"id_": "3192e549-ef5f-47a7-82e0-f49917e5f0db", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bfc28529-4549-480d-97a1-8fa8ef541660", "node_type": "1", "metadata": {}, "hash": "1114e387dbed719320a3b654aa22db67ec69843d4319be4ae85f3f1fefb1a829", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a76c50b8-f99e-4845-b34b-0fe8bd43f712", "node_type": "1", "metadata": {}, "hash": "d5d18e03da96cfd6024a343befefe41178ebd455158bc9b795836b6702cdbe37", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Astronomy, space activities and ufology ==\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\nIn the search for extraterrestrial intelligence (SETI), machine learning has been used in attempts to identify artificially generated electromagnetic waves in available data \u2013 such as real-time observations \u2013 and other technosignatures, e.g. via anomaly detection. In ufology, the SkyCAM-5 project headed by Prof. Hakan Kayal and the Galileo Project headed by Avi Loeb use machine learning to attempt to detect and classify types of UFOs. The Galileo Project also seeks to detect two further types of potential extraterrestrial technological signatures with the use of AI: 'Oumuamua-like interstellar objects, and non-manmade artificial satellites.\nMachine learning can also be used to produce datasets of spectral signatures of molecules that may be involved in the atmospheric production or consumption of particular chemicals \u2013 such as phosphine possibly detected on Venus \u2013 which could prevent miss assignments and, if accuracy is improved, be used in future detections and identifications of molecules on other planets.\n\n\n== Other fields of research ==\n\n\n=== Evidence of general impacts ===\nIn April 2024, the Scientific Advice Mechanism to the European Commission published advice including a comprehensive evidence review of the opportunities and challenges posed by artificial intelligence in scientific research.\nAs benefits, the evidence review highlighted:\n\nits role in accelerating research and innovation\nits capacity to automate workflows\nenhancing dissemination of scientific work\nAs challenges:\n\nlimitations and risks around transparency, reproducibility and interpretability\npoor performance (inaccuracy)\nrisk of harm through misuse or unintended use\nsocietal concerns including the spread of misinformation and increasing inequalities\n\n\n=== Archaeology, history and imaging of sites ===\n\nMachine learning can help to restore and attribute ancient texts. It can help to index texts for example to enable better and easier searching and classification of fragments.\n\nArtificial intelligence can also be used to investigate genomes to uncover genetic history, such as interbreeding between archaic and modern humans by which for example the past existence of a ghost population, not Neanderthal or Denisovan, was inferred. \nIt can also be used for \"non-invasive and non-destructive access to internal structures of archaeological remains\". \n\n\n=== Physics ===\n\nA deep learning system was reported to learn intuitive physics from visual data (of virtual 3D environments) based on an unpublished approach inspired by studies of visual cognition in infants. Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior. In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems.\n\n\n=== Materials science ===\nAI could be used for materials optimization and discovery such as the discovery of stable materials and the prediction of their crystal structure.\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.\n\n\n=== Reverse engineering ===\nMachine learning is used in diverse types of reverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts, and for quickly understanding the behavior of malware. It can be used to reverse engineer artificial intelligence models. It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionality or protein design for prespecified functional sites. Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels.\n\n\n== Law ==", "mimetype": "text/plain", "start_char_idx": 27095, "end_char_idx": 32831, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a76c50b8-f99e-4845-b34b-0fe8bd43f712": {"__data__": {"id_": "a76c50b8-f99e-4845-b34b-0fe8bd43f712", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3192e549-ef5f-47a7-82e0-f49917e5f0db", "node_type": "1", "metadata": {}, "hash": "9e0860ab3cce3983f1d557a7579a378b73485c40d8b1e1f03da1943e79491065", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8e726a5c-bd57-48c7-aad1-47ce2f2fe28f", "node_type": "1", "metadata": {}, "hash": "0d9a6818c18729b13cb01542389760e2635eb86622184bc88c482d6191289a56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Reverse engineering ===\nMachine learning is used in diverse types of reverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts, and for quickly understanding the behavior of malware. It can be used to reverse engineer artificial intelligence models. It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionality or protein design for prespecified functional sites. Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels.\n\n\n== Law ==\n\n\n=== Legal analysis ===\nAI is a mainstay of law-related professions. Algorithms and machine learning do some tasks previously done by entry-level lawyers. While its use is common, it is not expected to replace most work done by lawyers in the near future.\nThe electronic discovery industry uses machine learning to reduce manual searching.\n\n\n=== Law enforcement and legal proceedings ===\nLaw enforcement has begun using facial recognition systems (FRS) to identify suspects from visual data. FRS results have proven to be more accurate when compared to eyewitness results. Furthermore, FRS has shown to have much a better ability to identify individuals when video clarity and visibility are low in comparison to human participants.\nCOMPAS is a commercial system used by U.S. courts to assess the likelihood of recidivism.\nOne concern relates to algorithmic bias, AI programs may become biased after processing data that exhibits bias. ProPublica claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than that of white defendants.\nIn 2019, the city of Hangzhou, China established a pilot program artificial intelligence-based Internet Court to adjudicate disputes related to ecommerce and internet-related intellectual property claims.:\u200a124\u200a Parties appear before the court via videoconference and AI evaluates the evidence presented and applies relevant legal standards.:\u200a124\u200a\n\n\n== Services ==\n\n\n=== Human resources ===\n\nAnother application of AI is in human resources. AI can screen resumes and rank candidates based on their qualifications, predict candidate success in given roles, and automate repetitive communication tasks via chatbots.\n\n\n=== Job search ===\nAI has simplified the recruiting/job search process for both recruiters and job seekers. According to Raj Mukherjee from Indeed, 65% of job searchers search again within 91 days after hire. An AI-powered engine streamlines the complexity of job hunting by assessing information on job skills, salaries, and user tendencies, matching job seekers to the most relevant positions. Machine intelligence calculates appropriate wages and highlights resume information for recruiters using NLP, which extracts relevant words and phrases from text. Another application is an AI resume builder that compiles a CV in 5 minutes. Chatbots assist website visitors and refine workflows.\n\n\n=== Online and telephone customer service ===\n\nAI underlies avatars (automated online assistants) on web pages. It can reduce operation and training costs. Pypestream automated customer service for its mobile application to streamline communication with customers.\nA Google app analyzes language and converts speech into text. The platform can identify angry customers through their language and respond appropriately. Amazon uses a chatbot for customer service that can perform tasks like checking the status of an order, cancelling orders, offering refunds and connecting the customer with a human representative. Generative AI (GenAI), such as ChatGPT, is increasingly used in business to automate tasks and enhance decision-making.\n\n\n=== Hospitality ===\nIn the hospitality industry, AI is used to reduce repetitive tasks, analyze trends, interact with guests, and predict customer needs. AI hotel services come in the form of a chatbot, application, virtual voice assistant and service robots.\n\n\n== Media ==\n\nAI applications analyze media content such as movies, TV programs, advertisement videos or user-generated content. The solutions often involve computer vision.\nTypical scenarios include the analysis of images using object recognition or face recognition techniques, or the analysis of video for scene recognizing scenes, objects or faces. AI-based media analysis can facilitate media search, the creation of descriptive keywords for content, content policy monitoring (such as verifying the suitability of content for a particular TV viewing time), speech to text for archival or other purposes, and the detection of logos, products or celebrity faces for ad placement.\n\nMotion interpolation\nPixel-art scaling algorithms\nImage scaling\nImage restoration\nPhoto colorization\nFilm restoration and video upscaling\nPhoto tagging\nAutomated species identification (such as identifying plants, fungi and animals with an app)\nText-to-image models such as DALL-E, Midjourney and Stable Diffusion\nImage to video\nText to video such as Make-A-Video from Meta, Imagen video and Phenaki from Google\nText to music with AI models such as MusicLM\nText to speech such as ElevenLabs and 15.ai\nMotion capture\nMake image transparent", "mimetype": "text/plain", "start_char_idx": 32069, "end_char_idx": 37447, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8e726a5c-bd57-48c7-aad1-47ce2f2fe28f": {"__data__": {"id_": "8e726a5c-bd57-48c7-aad1-47ce2f2fe28f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a76c50b8-f99e-4845-b34b-0fe8bd43f712", "node_type": "1", "metadata": {}, "hash": "d5d18e03da96cfd6024a343befefe41178ebd455158bc9b795836b6702cdbe37", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "50520759-22d8-4d1d-9350-c89f0465de72", "node_type": "1", "metadata": {}, "hash": "8ed5bad237d17fb4c6bbf8833ae1949763d7f66c383c2018616f123adaf644d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Deep-fakes ===\nDeep-fakes can be used for comedic purposes but are better known for fake news and hoaxes.\nDeepfakes can portray individuals in harmful or compromising situations, causing significant reputational damage and emotional distress, especially when the content is defamatory or violates personal ethics. While defamation and false light laws offer some recourse, their focus on false statements rather than fabricated images or videos often leaves victims with limited legal protection and a challenging burden of proof.\nIn January 2016, the Horizon 2020 program financed the InVID Project to help journalists and researchers detect fake documents, made available as browser plugins.\nIn June 2016, the visual computing group of the Technical University of Munich and from Stanford University developed Face2Face, a program that animates photographs of faces, mimicking the facial expressions of another person. The technology has been demonstrated animating the faces of people including Barack Obama and Vladimir Putin. Other methods have been demonstrated based on deep neural networks, from which the name deep fake was taken.\nIn September 2018, U.S. Senator Mark Warner proposed to penalize social media companies that allow sharing of deep-fake documents on their platforms.\nIn 2018, Darius Afchar and Vincent Nozick found a way to detect faked content by analyzing the mesoscopic properties of video frames. DARPA gave 68 million dollars to work on deep-fake detection.\nAudio deepfakes and AI software capable of detecting deep-fakes and cloning human voices have been developed.\nRespeecher is a program that enables one person to speak with the voice of another.\n\n\n=== Video surveillance analysis and manipulated media detection ===\n\nAI algorithms have been used to detect deepfake videos.\n\n\n=== Video production ===\nArtificial intelligence is also starting to be used in video production, with tools and software being developed that utilize generative AI in order to create new video, or alter existing video. Some of the major tools that are being used in these processes currently are DALL-E, Mid-journey, and Runway.  Way mark Studios utilized the tools offered by both DALL-E and Mid-journey to create a fully AI generated film called The Frost in the summer of 2023. Way mark Studios is experimenting with using these AI tools to generate advertisements and commercials for companies in mere seconds.  Yves Bergquist, a director of the AI & Neuroscience in Media Project at USC's Entertainment Technology Center, says post production crews in Hollywood are already using generative AI, and predicts that in the future more companies will embrace this new technology.\n\n\n=== Music ===\n\nAI has been used to compose music of various genres.\nDavid Cope created an AI called Emily Howell that managed to become well known in the field of algorithmic computer music. The algorithm behind Emily Howell is registered as a US patent.\nIn 2012, AI Iamus created the first complete classical album.\nAIVA (Artificial Intelligence Virtual Artist), composes symphonic music, mainly classical music for film scores. It achieved a world first by becoming the first virtual composer to be recognized by a musical professional association.\nMelomics creates computer-generated music for stress and pain relief.\nAt Sony CSL Research Laboratory, the Flow Machines software creates pop songs by learning music styles from a huge database of songs. It can compose in multiple styles.\nThe Watson Beat uses reinforcement learning and deep belief networks to compose music on a simple seed input melody and a select style. The software was open sourced and musicians such as Taryn Southern collaborated with the project to create music.\nSouth Korean singer, Hayeon's, debut song, \"Eyes on You\" was composed using AI which was supervised by real composers, including NUVO.", "mimetype": "text/plain", "start_char_idx": 37450, "end_char_idx": 41321, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "50520759-22d8-4d1d-9350-c89f0465de72": {"__data__": {"id_": "50520759-22d8-4d1d-9350-c89f0465de72", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e726a5c-bd57-48c7-aad1-47ce2f2fe28f", "node_type": "1", "metadata": {}, "hash": "0d9a6818c18729b13cb01542389760e2635eb86622184bc88c482d6191289a56", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a7c4556e-aa79-4f25-9a58-d3be3d893752", "node_type": "1", "metadata": {}, "hash": "07d07fcb6a16b6eab1b6cc3770a062f2cb5d30165e97e0fcadee61f3dd025dc0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Writing and reporting ===\nNarrative Science sells computer-generated news and reports. It summarizes sporting events based on statistical data from the game. It also creates financial reports and real estate analyses. Automated Insights generates personalized recaps and previews for Yahoo Sports Fantasy Football.\nYseop, uses AI to turn structured data into natural language comments and recommendations. Yseop writes financial reports, executive summaries, personalized sales or marketing documents and more in multiple languages, including English, Spanish, French, and German.\nTALESPIN made up stories similar to the fables of Aesop. The program started with a set of characters who wanted to achieve certain goals. The story narrated their attempts to satisfy these goals. Mark Riedl and Vadim Bulitko asserted that the essence of storytelling was experience management, or \"how to balance the need for a coherent story progression with user agency, which is often at odds\".\nWhile AI storytelling focuses on story generation (character and plot), story communication also received attention. In 2002, researchers developed an architectural framework for narrative prose generation. They faithfully reproduced text variety and complexity on stories such as Little Red Riding Hood. In 2016, a Japanese AI co-wrote a short story and almost won a literary prize.\nSouth Korean company Hanteo Global uses a journalism bot to write articles.\nLiterary authors are also exploring uses of AI. An example is David Jhave Johnston's work ReRites (2017\u20132019), where the poet created a daily rite of editing the poetic output of a neural network to create a series of performances and publications.\n\n\n==== Sports writing ====\nIn 2010, artificial intelligence used baseball statistics to automatically generate news articles. This was launched by The Big Ten Network using software from Narrative Science.\nAfter being unable to cover every Minor League Baseball game with a large team, Associated Press collaborated with Automated Insights in 2016 to create game recaps that were automated by artificial intelligence.\nUOL in Brazil expanded the use of AI in its writing. Rather than just generating news stories, they programmed the AI to include commonly searched words on Google.\nEl Pais, a Spanish news site that covers many things including sports, allows users to make comments on each news article. They use the Perspective API to moderate these comments and if the software deems a comment to contain toxic language, the commenter must modify it in order to publish it.\nA local Dutch media group used AI to create automatic coverage of amateur soccer, set to cover 60,000 games in just a single season. NDC partnered with United Robots to create this algorithm and cover what would have never been possible before without an extremely large team.\nLede AI has been used in 2023 to take scores from high school football games to generate stories automatically for the local newspaper. This was met with significant criticism from readers for the very robotic diction that was published. With some descriptions of games being a \"close encounter of the athletic kind,\" readers were not pleased and let the publishing company, Gannett, know on social media. Gannett has since halted their used of Lede AI until they come up with a solution for what they call an experiment.\n\n\n=== Wikipedia ===\n Millions of its articles have been edited by bots which however are usually not artificial intelligence software. Many AI platforms use Wikipedia data, mainly for training machine learning applications. There is research and development of various artificial intelligence applications for Wikipedia such as for identifying outdated sentences, detecting covert vandalism or recommending articles and tasks to new editors.\nMachine translation (see above) has also be used for translating Wikipedia articles and could play a larger role in creating, updating, expanding, and generally improving articles in the future. A content translation tool allows editors of some Wikipedias to more easily translate articles across several select languages.\n\n\n=== Video games ===\n\nIn video games, AI is routinely used to generate behavior in non-player characters (NPCs). In addition, AI is used for pathfinding. Some researchers consider NPC AI in games to be a \"solved problem\" for most production tasks. Games with less typical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010). AI is also used in Alien Isolation (2014) as a way to control the actions the Alien will perform next.\nKinect, which provides a 3D body\u2013motion interface for the Xbox 360 and the Xbox One, uses algorithms that emerged from AI research.", "mimetype": "text/plain", "start_char_idx": 41324, "end_char_idx": 46092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a7c4556e-aa79-4f25-9a58-d3be3d893752": {"__data__": {"id_": "a7c4556e-aa79-4f25-9a58-d3be3d893752", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "50520759-22d8-4d1d-9350-c89f0465de72", "node_type": "1", "metadata": {}, "hash": "8ed5bad237d17fb4c6bbf8833ae1949763d7f66c383c2018616f123adaf644d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9e901110-1958-476b-985a-1fc91bc494af", "node_type": "1", "metadata": {}, "hash": "28dda94c5d50b30109d1a32f8445abf7e08791882f2c49e8eaea5d445f2c87cd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Video games ===\n\nIn video games, AI is routinely used to generate behavior in non-player characters (NPCs). In addition, AI is used for pathfinding. Some researchers consider NPC AI in games to be a \"solved problem\" for most production tasks. Games with less typical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010). AI is also used in Alien Isolation (2014) as a way to control the actions the Alien will perform next.\nKinect, which provides a 3D body\u2013motion interface for the Xbox 360 and the Xbox One, uses algorithms that emerged from AI research.\n\n\n=== Art ===\n\nAI has been used to produce visual art. The first AI art program, called AARON, was developed by Harold Cohen in 1968 with the goal of being able to code the act of drawing. It started by creating simple black and white drawings, and later to painting using special brushes and dyes that were chosen by the program itself without mediation from Cohen.\nAI platforms such as DALL-E, Stable Diffusion, Imagen, and Midjourney have been used for generating visual images from inputs such as text or other images. Some AI tools allow users to input images and output changed versions of that image, such as to display an object or product in different environments. AI image models can also attempt to replicate the specific styles of artists, and can add visual complexity to rough sketches.\nSince their design in 2014, generative adversarial networks (GANs) have been used by AI artists. GAN computer programming, generates technical images through machine learning frameworks that surpass the need for human operators. Examples of GAN programs that generate art include Artbreeder and DeepDream.\n\n\n==== Art analysis ====\nIn addition to the creation of original art, research methods that utilize AI have been generated to quantitatively analyze digital art collections. Although the main goal of the large-scale digitization of artwork in the past few decades was to allow for accessibility and exploration of these collections, the use of AI in analyzing them has brought about new research perspectives.\nTwo computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art. While distant viewing includes the analysis of large collections, close reading involves one piece of artwork.\n\n\n=== Computer animation ===\nAI has been in use since the early 2000s, most notably by a system designed by Pixar called \"Genesis\". It was designed to learn algorithms and create 3D models for its characters and props. Notable movies that used this technology included Up and The Good Dinosaur. AI has been used less ceremoniously in recent years. In 2023, it was revealed Netflix of Japan was using AI to generate background images for their upcoming show to be met with backlash online.  In recent years, motion capture became an easily accessible form of AI animation. For example, Move AI is a program built to capture any human movement and reanimate it in its animation program using learning AI.\n\n\n== Utilities ==\n\n\n=== Energy system ===\nPower electronics converters are used in renewable energy, energy storage, electric vehicles and high-voltage direct current transmission. These converters are failure-prone, which can interrupt service and require costly maintenance or catastrophic consequences in mission critical applications. AI can guide the design process for reliable power electronics converters, by calculating exact design parameters that ensure the required lifetime.\nThe U.S. Department of Energy underscores AI's pivotal role in realizing national climate goals. With AI, the ambitious target of achieving net-zero greenhouse gas emissions across the economy becomes feasible. AI also helps make room for wind and solar on the grid by avoiding congestion and increasing grid reliability.\nMachine learning can be used for energy consumption prediction and scheduling, e.g. to help with renewable energy intermittency management (see also: smart grid and climate change mitigation in the power grid).\n\n\n=== Telecommunications ===\nMany telecommunications companies make use of heuristic search to manage their workforces. For example, BT Group deployed heuristic search in an application that schedules 20,000 engineers. Machine learning is also used for speech recognition (SR), including of voice-controlled devices, and SR-related transcription, including of videos.\n\n\n== Manufacturing ==\n\n\n=== Sensors ===\nArtificial intelligence has been combined with digital spectrometry by IdeaCuria Inc., enable applications such as at-home water quality monitoring.\n\n\n=== Toys and games ===\nIn the 1990s, early artificial intelligence tools controlled Tamagotchis and Giga Pets, the Internet, and the first widely released robot, Furby. Aibo was a domestic robot in the form of a robotic dog with intelligent features and autonomy.\nMattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn.", "mimetype": "text/plain", "start_char_idx": 45460, "end_char_idx": 50508, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9e901110-1958-476b-985a-1fc91bc494af": {"__data__": {"id_": "9e901110-1958-476b-985a-1fc91bc494af", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a7c4556e-aa79-4f25-9a58-d3be3d893752", "node_type": "1", "metadata": {}, "hash": "07d07fcb6a16b6eab1b6cc3770a062f2cb5d30165e97e0fcadee61f3dd025dc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "31b08a90-e3a2-4d6d-85f7-f1955efd0c73", "node_type": "1", "metadata": {}, "hash": "b7bfb2f4c90510dc3941cbecdbdef934dea746b76c73dbc910fe4082130ef1ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Telecommunications ===\nMany telecommunications companies make use of heuristic search to manage their workforces. For example, BT Group deployed heuristic search in an application that schedules 20,000 engineers. Machine learning is also used for speech recognition (SR), including of voice-controlled devices, and SR-related transcription, including of videos.\n\n\n== Manufacturing ==\n\n\n=== Sensors ===\nArtificial intelligence has been combined with digital spectrometry by IdeaCuria Inc., enable applications such as at-home water quality monitoring.\n\n\n=== Toys and games ===\nIn the 1990s, early artificial intelligence tools controlled Tamagotchis and Giga Pets, the Internet, and the first widely released robot, Furby. Aibo was a domestic robot in the form of a robotic dog with intelligent features and autonomy.\nMattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn.\n\n\n=== Oil and gas ===\nOil and gas companies have used artificial intelligence tools to automate functions, foresee equipment issues, and increase oil and gas output.\n\nIndustrial sensors and AI tools work together to watch manufacturing processes and equipment in real-time. Detection programs find strange patterns. The patterns may show quality issues or issues with equipment. Supply chain management improves with better predictions of demand and managing inventory.\n\n\n== Transport ==\n\n\n=== Automotive ===\n\nAI in transport is expected to provide safe, efficient, and reliable transportation while minimizing the impact on the environment and communities. The major development challenge is the complexity of transportation systems that involves independent components and parties, with potentially conflicting objectives.\nAI-based fuzzy logic controllers operate gearboxes. For example, the 2006 Audi TT, VW Touareg  and VW Caravell feature the DSP transmission. A number of \u0160koda variants (\u0160koda Fabia) include a fuzzy logic-based controller. Cars have AI-based driver-assist features such as self-parking and adaptive cruise control.\nThere are also prototypes of autonomous automotive public transport vehicles such as electric mini-buses as well as autonomous rail transport in operation.\nThere also are prototypes of autonomous delivery vehicles, sometimes including delivery robots.\nTransportation's complexity means that in most cases training an AI in a real-world driving environment is impractical. Simulator-based testing can reduce the risks of on-road training.\nAI underpins self-driving vehicles. Companies involved with AI include Tesla, Waymo, and General Motors. AI-based systems control functions such as braking, lane changing, collision prevention, navigation and mapping.\nAutonomous trucks are in the testing phase. The UK government passed legislation to begin testing of autonomous truck platoons in 2018. A group of autonomous trucks follow closely behind each other. German corporation Daimler is testing its Freightliner Inspiration.\nAutonomous vehicles require accurate maps to be able to navigate between destinations. Some autonomous vehicles do not allow human drivers (they have no steering wheels or pedals).\n\n\n==== Traffic management ====\nAI has been used to optimize traffic management, which reduces wait times, energy use, and emissions by as much as 25 percent.\n\nSmart traffic lights have been developed at Carnegie Mellon since 2009.  Professor Stephen Smith has started a company since then Surtrac that has installed smart traffic control systems in 22 cities.  It costs about $20,000 per intersection to install. Drive time has been reduced by 25% and traffic jam waiting time has been reduced by 40% at the intersections it has been installed.", "mimetype": "text/plain", "start_char_idx": 49568, "end_char_idx": 53296, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "31b08a90-e3a2-4d6d-85f7-f1955efd0c73": {"__data__": {"id_": "31b08a90-e3a2-4d6d-85f7-f1955efd0c73", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9e901110-1958-476b-985a-1fc91bc494af", "node_type": "1", "metadata": {}, "hash": "28dda94c5d50b30109d1a32f8445abf7e08791882f2c49e8eaea5d445f2c87cd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1cde0f9a-09c0-40b9-8393-32839fb102bd", "node_type": "1", "metadata": {}, "hash": "7e384d0209dbf69bb587755afac8675c531dab5f7bdc77b6604995b6e2c25c06", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Traffic management ====\nAI has been used to optimize traffic management, which reduces wait times, energy use, and emissions by as much as 25 percent.\n\nSmart traffic lights have been developed at Carnegie Mellon since 2009.  Professor Stephen Smith has started a company since then Surtrac that has installed smart traffic control systems in 22 cities.  It costs about $20,000 per intersection to install. Drive time has been reduced by 25% and traffic jam waiting time has been reduced by 40% at the intersections it has been installed.\n\n\n=== Military ===\nThe Royal Australian Air Force (RAAF) Air Operations Division (AOD) uses AI for expert systems. AIs operate as surrogate operators for combat and training simulators, mission management aids, support systems for tactical decision making, and post processing of the simulator data into symbolic summaries.\nAircraft simulators use AI for training aviators. Flight conditions can be simulated that allow pilots to make mistakes without risking themselves or expensive aircraft. Air combat can also be simulated.\nAI can also be used to operate planes analogously to their control of ground vehicles. Autonomous drones can fly independently or in swarms.\nAOD uses the Interactive Fault Diagnosis and Isolation System, or IFDIS, which is a rule-based expert system using information from TF-30 documents and expert advice from mechanics that work on the TF-30. This system was designed to be used for the development of the TF-30 for the F-111C. The system replaced specialized workers. The system allowed regular workers to communicate with the system and avoid mistakes, miscalculations, or having to speak to one of the specialized workers.\nSpeech recognition allows traffic controllers to give verbal directions to drones.\nArtificial intelligence supported design of aircraft, or AIDA, is used to help designers in the process of creating conceptual designs of aircraft. This program allows the designers to focus more on the design itself and less on the design process. The software also allows the user to focus less on the software tools. The AIDA uses rule-based systems to compute its data. This is a diagram of the arrangement of the AIDA modules. Although simple, the program is proving effective.\n\n\n=== NASA ===\nIn 2003 a Dryden Flight Research Center project created software that could enable a damaged aircraft to continue flight until a safe landing can be achieved. The software compensated for damaged components by relying on the remaining undamaged components.\nThe 2016 Intelligent Autopilot System combined apprenticeship learning and behavioral cloning whereby the autopilot observed low-level actions required to maneuver the airplane and high-level strategy used to apply those actions.\n\n\n=== Maritime ===\nNeural networks are used by situational awareness systems in ships and boats. There also are autonomous boats.\n\nThe development of self-driving cars is progressing. Machine learning systems help use sensor data to navigate tricky areas. Advanced driver assistance systems provide features such as keeping the car in its lane and preventing accidents. City traffic management systems change traffic lights based on the current traffic conditions.\nMaritime shipping uses AI to find the best paths. It checks weather and fuel usage. Automated navigation systems help operate the ships. AI also improves loading and placing containers at ports.\n\n\n== Environmental monitoring ==\n\nAutonomous ships that monitor the ocean, AI-driven satellite data analysis, passive acoustics or remote sensing and other applications of environmental monitoring make use of machine learning.\nFor example, \"Global Plastic Watch\" is an AI-based satellite monitoring-platform for analysis/tracking of plastic waste sites to help prevention of plastic pollution \u2013 primarily ocean pollution \u2013 by helping identify who and where mismanages plastic waste, dumping it into oceans.\n\n\n=== Early-warning systems ===\nMachine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics, earthquakes, landslides, heavy rainfall, long-term water supply vulnerability, tipping-points of ecosystem collapse, cyanobacterial bloom outbreaks, and droughts.\n\nAI early warning systems can warn us about natural disasters like floods, wildfires, and earthquakes. Climate change monitoring uses machine learning to spot patterns in temperature, rainfall, and other signs in the environment. Wildlife conservation gets better when we use automatic tools to identify animals in camera trap pictures and sound recordings. Tools for monitoring the ocean look at key details that help us learn about the health of ocean ecosystems.\n\n\n== Computer science ==\n\n\n=== Programming assistance ===", "mimetype": "text/plain", "start_char_idx": 52754, "end_char_idx": 57541, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1cde0f9a-09c0-40b9-8393-32839fb102bd": {"__data__": {"id_": "1cde0f9a-09c0-40b9-8393-32839fb102bd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "31b08a90-e3a2-4d6d-85f7-f1955efd0c73", "node_type": "1", "metadata": {}, "hash": "b7bfb2f4c90510dc3941cbecdbdef934dea746b76c73dbc910fe4082130ef1ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27d31b73-af59-4aff-b145-31727c0f8c3a", "node_type": "1", "metadata": {}, "hash": "4a1901902c25f5e525e39d9f2f8c64050bceb31f7efb9c9a693811df54c73dc8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Early-warning systems ===\nMachine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics, earthquakes, landslides, heavy rainfall, long-term water supply vulnerability, tipping-points of ecosystem collapse, cyanobacterial bloom outbreaks, and droughts.\n\nAI early warning systems can warn us about natural disasters like floods, wildfires, and earthquakes. Climate change monitoring uses machine learning to spot patterns in temperature, rainfall, and other signs in the environment. Wildlife conservation gets better when we use automatic tools to identify animals in camera trap pictures and sound recordings. Tools for monitoring the ocean look at key details that help us learn about the health of ocean ecosystems.\n\n\n== Computer science ==\n\n\n=== Programming assistance ===\n\n\n==== AI-powered code assisting tools ====\nAI can be used for real-time code completion, chat, and automated test generation. These tools are typically integrated with editors and IDEs as plugins. They differ in functionality, quality, speed, and approach to privacy. Code suggestions could be incorrect, and should be carefully reviewed by software developers before accepted.\nGitHub Copilot is an artificial intelligence model developed by GitHub and OpenAI that is able to autocomplete code in multiple programming languages. Price for individuals: $10/mo or $100/yr, with one free month trial.\nTabnine was created by Jacob Jackson and was originally owned by Tabnine company. In late 2019, Tabnine was acquired by Codota. Tabnine tool is available as plugin to most popular IDEs. It offers multiple pricing options, including limited \"starter\" free version.\nCodiumAI by CodiumAI, small startup in Tel Aviv, offers automated test creation. Currently supports Python, JS, and TS.\nGhostwriter by Replit offers code completion and chat. They have multiple pricing plans, including a free one and a \"Hacker\" plan for $7/month.\nCodeWhisperer by Amazon collects individual users' content, including files open in the IDE. They claim to focus on security both during transmission and when storing. Individual plan is free, professional plan is $19/user/month.\nOther tools: SourceGraph Cody, CodeCompleteFauxPilot, Tabby\n\n\n==== Neural network design ====\nAI can be used to create other AIs. For example, around November 2017, Google's AutoML project to evolve new neural net topologies created NASNet, a system optimized for ImageNet and POCO F1. NASNet's performance exceeded all previously published performance on ImageNet.\n\n\n==== Quantum computing ====\n\nMachine learning has been used for noise-cancelling in quantum technology, including quantum sensors. Moreover, there is substantial research and development of using quantum computers with machine learning algorithms. For example, there is a prototype, photonic, quantum memristive device for neuromorphic (quantum-)computers (NC)/artificial neural networks and NC-using quantum materials with some variety of potential neuromorphic computing-related applications, and quantum machine learning is a field with some variety of applications under development. AI could be used for quantum simulators which may have the application of solving physics and chemistry problems as well as for quantum annealers for training of neural networks for AI applications. There may also be some usefulness in chemistry, e.g. for drug discovery, and in materials science, e.g. for materials optimization/discovery (with possible relevance to quantum materials manufacturing).\n\n\n=== Historical contributions ===\nAI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered AI. All of the following were originally developed in AI laboratories:\n\nTime sharing\nInteractive interpreters\nGraphical user interfaces and the computer mouse\nRapid application development environments\nThe linked list data structure\nAutomatic storage management\nSymbolic programming\nFunctional programming\nDynamic programming\nObject-oriented programming\nOptical character recognition\nConstraint satisfaction\n\n\n== Business ==\n\n\n=== Content extraction ===\nAn optical character reader is used in the extraction of data in business documents like invoices and receipts. It can also be used in business contract documents e.g. employment agreements to extract critical data like employment terms, delivery terms, termination clauses, etc.\n\n\n== Architecture ==\nAI in architecture has created a way for architects to create things beyond human understanding. AI implementation of machine learning text-to-render technologies, like DALL-E and stable Diffusion, gives power to visualization complex.\nAI allows designers to demonstrate their creativity and even invent new ideas while designing. In future, AI will not replace architects; instead, it will improve the speed of translating ideas sketching.\n\n\n== Ethical Considerations and Societal Impacts ==\nThe use of AI raises some important ethical issues like privacy, bias, and accountability. When algorithms are trained on biased data, they can end up reinforcing existing inequalities, for example consider how facial recognition technology often performs poorly or fails in certain demographics. Plus, AI's use in surveillance makes people worry about their personal rights and data privacy.", "mimetype": "text/plain", "start_char_idx": 56691, "end_char_idx": 62132, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "27d31b73-af59-4aff-b145-31727c0f8c3a": {"__data__": {"id_": "27d31b73-af59-4aff-b145-31727c0f8c3a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1cde0f9a-09c0-40b9-8393-32839fb102bd", "node_type": "1", "metadata": {}, "hash": "7e384d0209dbf69bb587755afac8675c531dab5f7bdc77b6604995b6e2c25c06", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "223acab7-1dce-40c9-a88f-0c729912ac4a", "node_type": "1", "metadata": {}, "hash": "d6dd62544bcb0e6465da4fe7b46c9eb4bb226cf55a5e8259afd1bd8854474775", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Architecture ==\nAI in architecture has created a way for architects to create things beyond human understanding. AI implementation of machine learning text-to-render technologies, like DALL-E and stable Diffusion, gives power to visualization complex.\nAI allows designers to demonstrate their creativity and even invent new ideas while designing. In future, AI will not replace architects; instead, it will improve the speed of translating ideas sketching.\n\n\n== Ethical Considerations and Societal Impacts ==\nThe use of AI raises some important ethical issues like privacy, bias, and accountability. When algorithms are trained on biased data, they can end up reinforcing existing inequalities, for example consider how facial recognition technology often performs poorly or fails in certain demographics. Plus, AI's use in surveillance makes people worry about their personal rights and data privacy. \n\n\n== Challenges and Future Directions ==\nThe integrartion of these technologies raises some issues that we need to look at. First, it's important to make sure that the data we use is accurate and fair. We also need to address issues of bias to ensure that AI systems treat everyone equally. Creating rules and guidelines for how AI is used is another important step. Data privacy and ensuring security is very essential to maintain trust. While adaptation of these technolgies can give us more efficiency in the work pattern, there might be a challenge for human workforce.\nLooking ahead, we aim to develop AI that can explain its decisions clearly so that people can understand how it works. There's also a goal to create more advanced AI that can handle a wider range of problems. Researchers are starting to emphasize the importance of working together across different fields to develop better technologies for AI so that it provides fair benefits for everyone.\n\n\n== List of applications ==\n\n\n== See also ==\nApplications of artificial intelligence to legal informatics\nApplications of deep learning\nApplications of machine learning\nArtificial intelligence and elections\nCollective intelligence \u00a7 Applications\nList of artificial intelligence projects\nList of datasets for machine-learning research\nOpen data\nProgress in artificial intelligence\nTimeline of computing 2020\u2013present\n\n\n== Footnotes ==\n\n\n== Further reading ==\nKaplan, A.M.; Haenlein, M. (2018). \"Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence\". Business Horizons. 62 (1): 15\u201325. doi:10.1016/j.bushor.2018.08.004.\nKurzweil, Ray (2005). The Singularity is Near: When Humans Transcend Biology. New York: Viking. ISBN 978-0-670-03384-3.\nNational Research Council (1999). \"Developments in Artificial Intelligence\". Funding a Revolution: Government Support for Computing Research. National Academy Press. ISBN 978-0-309-06278-7. OCLC 246584055.\nMoghaddam, M. J.; Soleymani, M. R.; Farsi, M. A. (2015). \"Sequence planning for stamping operations in progressive dies\". Journal of Intelligent Manufacturing. 26 (2): 347\u2013357. doi:10.1007/s10845-013-0788-0.\nFelten, Ed (3 May 2016). \"Preparing for the Future of Artificial Intelligence\".", "mimetype": "text/plain", "start_char_idx": 61228, "end_char_idx": 64413, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "223acab7-1dce-40c9-a88f-0c729912ac4a": {"__data__": {"id_": "223acab7-1dce-40c9-a88f-0c729912ac4a", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "27d31b73-af59-4aff-b145-31727c0f8c3a", "node_type": "1", "metadata": {}, "hash": "4a1901902c25f5e525e39d9f2f8c64050bceb31f7efb9c9a693811df54c73dc8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2a6e6966-7060-4615-a5af-cd23b6ecfdd3", "node_type": "1", "metadata": {}, "hash": "e99bc87ebf9804d68e2a8e76102b412d797ea3ff341ba3a197d066b3052dca0d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Artificial intelligence (AI) has been used in applications throughout industry and academia. In a manner analogous to electricity or computers, AI serves as a general-purpose technology. AI programs are designed to simulate human perception and understanding. These systems are capable of adapting to new information and responding to changing situations. Machine learning has been used for various scientific and commercial purposes including language translation, image recognition, decision-making, credit scoring, and e-commerce.\nArtificial Intelligence (AI) is all about creating computer systems that act like people. This means they can understand information and human language and make decisions similar to how we do.  Artificial intelligence technologies are now being used across various industries, transforming how they function and creating new opportunities. This article provides an overview of the applications of AI in fields like health care, finance, and education, while also discussing the challenges and future prospects in these areas. \n\n\n== Internet and e-commerce ==\n\n\n=== Web feeds and posts ===\nMachine learning has been used for recommendation systems in determining which posts should show up in social media feeds. Various types of social media analysis also make use of machine learning and there is research into its use for (semi-)automated tagging/enhancement/correction of online misinformation and related filter bubbles.\nAI has been used to customize shopping options and personalize offers. Online gambling companies have used AI for targeting gamblers.\n\n\n=== Virtual assistants and search ===\n\nIntelligent personal assistants use AI to understand many natural language requests in other ways than rudimentary commands. Common examples are Apple's Siri, Amazon's Alexa, and a more recent AI, ChatGPT by OpenAI.\nBing Chat has used artificial intelligence as part of its search engine.\n\n\n=== Spam filtering ===\n\nMachine learning can be used to combat spam, scams, and phishing. It can scrutinize the contents of spam and phishing attacks to attempt to identify malicious elements. Some models built via machine learning algorithms have over 90% accuracy in distinguishing between spam and legitimate emails. These models can be refined using new data and evolving spam tactics. Machine learning also analyzes traits such as sender behavior, email header information, and attachment types, potentially enhancing spam detection.\n\n\n=== Language translation ===\n\nSpeech translation technology attempts to convert one language's spoken words into another language. This potentially reduces language barriers in global commerce and cross-cultural exchange, enabling speakers of various languages to communicate with one another.\nAI has been used to automatically translate spoken language and textual content in products such as Microsoft Translator, Google Translate, and DeepL Translator. Additionally, research and development are in progress to decode and conduct animal communication.\nMeaning is conveyed not only by text, but also through usage and context (see semantics and pragmatics). As a result, the two primary categorization approaches for machine translations are statistical machine translation (SMT) and neural machine translations (NMTs). The old method of performing translation was to use statistical methodology to forecast the best probable output with specific algorithms. However, with NMT, the approach employs dynamic algorithms to achieve better translations based on context.\n\n\n=== Facial recognition and image labeling ===\n\nAI has been used in facial recognition systems. Some examples are Apple's Face ID and Android's Face Unlock, which are used to secure mobile devices.\nImage labeling has been used by Google Image Labeler to detect products in photos and to allow people to search based on a photo. Image labeling has also been demonstrated to generate speech to describe images to blind people. Facebook's DeepFace identifies human faces in digital images.\nSocial media sites and content aggregators use AI systems to make personalized news feeds by watching users' actions and engagement history.\u202fContent moderation often relies on AI to spot harmful content, though these systems have trouble with understanding the bigger picture.\nSearch engines use rules to rank results and understand what people want, while virtual helpers like Siri and Alexa use everyday language to read user queries. Email services use learning tools to find spam by checking the content and patterns.\nNeural machine translation systems have gotten much better at translating text. It works by examining complete sentences to maintain accuracy. Computer vision systems can identify people in images and videos. This assists with tasks like sorting photos and performing security checks. AI is often used for surveillance for credit systems, targeted advertising and automation we can erode privacy and concentrate power. It also led to dystopian outcomes such as autonomous systems making unaccountable decisions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5056, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2a6e6966-7060-4615-a5af-cd23b6ecfdd3": {"__data__": {"id_": "2a6e6966-7060-4615-a5af-cd23b6ecfdd3", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "223acab7-1dce-40c9-a88f-0c729912ac4a", "node_type": "1", "metadata": {}, "hash": "d6dd62544bcb0e6465da4fe7b46c9eb4bb226cf55a5e8259afd1bd8854474775", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da0c5e38-5fa7-4b66-a3dc-fa8565755add", "node_type": "1", "metadata": {}, "hash": "a15c5a1a8065c8215a0a7f5a35a7f80475b32e420766b81b390ddf99f3309211", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Games and entertainment ==\n\nGames have been a major application of AI's capabilities since the 1950s. In the 21st century, AIs have beaten human players in many games, including chess (Deep Blue), Jeopardy! (Watson), Go (AlphaGo), poker (Pluribus and Cepheus), E-sports (StarCraft), and general game playing (AlphaZero and MuZero).\nKuki AI is a set of chatbots and other apps which were designed for entertainment and as a marketing tool. Character.ai is another example of a chatbot being used for recreation.\nAI has changed gaming by making smart non-player characters (NPCs) that can adjust. Algorithms can now create game worlds and situations on their own, which reduces development costs and revives the excitement to play again. In digital art and music, AI tools help people express themselves in fresh, new ways using generative algorithms.\nRecommendation systems on streaming platforms check how people watch to suggest content. This greatly affects the way viewers enjoy the media.\n\n\n== Economic and social challenges ==\nAI for Good is a platform launched in 2017 by the International Telecommunication Union (ITU) agency of the United Nations (UN). The goal of the platform is to use AI to help achieve the UN's Sustainable Development Goals.\nThe University of Southern California launched the Center for Artificial Intelligence in Society, with the goal of using AI to address problems such as homelessness. Stanford researchers use AI to analyze satellite images to identify high poverty areas.\n\n\n== Agriculture ==\n\nIn agriculture, AI has been proposed as a way for farmers to identify areas that need irrigation, fertilization, or pesticide treatments to increase yields, thereby improving efficiency. AI has been used to attempt to classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and optimize irrigation.\nPrecision farming uses machine learning and data from satellites, drones and sensors to water, fertilize and manage pests. Computer vision helps keep an eye on plant health, spot diseases and even help with automated harvesting of specific crops. With predictive analytics farmers can make better decisions by predicting weather patterns and knowing when to plant.\nAI helps with livestock management by tracking animal health and production. These are the tools of \u201csmart farming\u201d. They make farming better and more sustainable.\n\n\n== Cyber security ==\nCyber security companies are adopting neural networks, machine learning, and natural language processing to improve their systems.\nApplications of AI in cyber security include:\n\nNetwork protection: Machine learning improves intrusion detection systems by broadening the search beyond previously identified threats.\nEndpoint protection: Attacks such as ransomware can be thwarted by learning typical malware behaviors.\nAI-related cyber security application cases vary in both benefit and complexity. Security features such as Security Orchestration, Automation, and Response (SOAR) and Extended Endpoint Detection and Response (XDR) offer significant benefits for businesses, but require significant integration and adaptation efforts.\nApplication security: can help counterattacks such as server-side request forgery, SQL injection, cross-site scripting, and distributed denial-of-service.\nAI technology can also be utilized to improve system security and safeguard our privacy. Randrianasolo (2012) suggested a security system based on artificial intelligence that can recognize intrusions and adapt to perform better. In order to improve cloud computing security, Sahil (2015) created a user profile system for the cloud environment with AI techniques.\nSuspect user behavior: Machine learning can identify fraud or compromised applications as they occur.\nMachine learning tools look at traffic patterns. They find an unusual activity that might be a security breach. Automated systems gather and analyze data. Their goal is to find new threats before they do significant damage. User behavior analytics establish normal patterns for users and systems that alert when there is a change that might mean a hacked account.\nAI brings new challenges to cybersecurity. Attackers are using the same tools to plan smarter attacks. This is an ongoing race to technological arms race.\n\n\n== Education ==\n\nAI elevates teaching, focusing on significant issues like the knowledge nexus and educational equality. The evolution of AI in education and technology should be used to improve human capabilities in relationships where they do not replace humans. UNESCO recognizes the future of AI in education as an instrument to reach Sustainable Development Goal 4, called \"Inclusive and Equitable Quality Education.\u201d \nThe World Economic Forum also stresses AI's contribution to students' overall improvement and transforming teaching into a more enjoyable process.\n\n\n=== Personalized Learning ===\nAI driven tutoring systems, such as Khan Academy, Duolingo and Carnegie Learning are the forefoot of delivering personalized education.\nThese platforms leverage AI algorithms to analyze individual learning patterns, strengths, and weaknesses, enabling the customization of content and Algorithm to suit each student's pace and style of learning.", "mimetype": "text/plain", "start_char_idx": 5059, "end_char_idx": 10300, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "da0c5e38-5fa7-4b66-a3dc-fa8565755add": {"__data__": {"id_": "da0c5e38-5fa7-4b66-a3dc-fa8565755add", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2a6e6966-7060-4615-a5af-cd23b6ecfdd3", "node_type": "1", "metadata": {}, "hash": "e99bc87ebf9804d68e2a8e76102b412d797ea3ff341ba3a197d066b3052dca0d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fa422a2d-c243-4b55-b340-201884705c09", "node_type": "1", "metadata": {}, "hash": "3034060bfecb3ea7456dd1f9409a7ed764c70230f156d9e932d70c0f5eca076b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Education ==\n\nAI elevates teaching, focusing on significant issues like the knowledge nexus and educational equality. The evolution of AI in education and technology should be used to improve human capabilities in relationships where they do not replace humans. UNESCO recognizes the future of AI in education as an instrument to reach Sustainable Development Goal 4, called \"Inclusive and Equitable Quality Education.\u201d \nThe World Economic Forum also stresses AI's contribution to students' overall improvement and transforming teaching into a more enjoyable process.\n\n\n=== Personalized Learning ===\nAI driven tutoring systems, such as Khan Academy, Duolingo and Carnegie Learning are the forefoot of delivering personalized education.\nThese platforms leverage AI algorithms to analyze individual learning patterns, strengths, and weaknesses, enabling the customization of content and Algorithm to suit each student's pace and style of learning.\n\n\n=== Administrative Efficiency ===\nIn educational institutions, AI is increasingly used to automate routine tasks like attendance tracking, grading and marking, which allows educators to devote more time to interactive teaching and direct student engagement.\nFurthermore, AI tools are employed to monitor student progress, analyze learning behaviors, and predict academic challenges, facilitating timely and proactive interventions for students who may be at risk of falling behind.\n\n\n=== Ethical and Privacy Concerns ===\nDespite the benefits, the integration of AI in education raises significant ethical and privacy concerns, particularly regarding the handling of sensitive student data.\nIt is imperative that AI systems in education are designed and operated with a strong emphasis on transparency, security, and respect for privacy to maintain trust and uphold the integrity of educational practices.\nMuch of the regulation will be influenced by the AI Act, the world's first comprehensive AI law.\nIntelligent tutoring systems provide personalized learning by adapting content based on how each student performs.\u202f Automated assessment tools check student work and give fast feedback which reduces the tutor workload. Learning analytics platforms can find students who might have trouble sooner. They do this by looking for patterns connected to learning issues.\nContent creation tools assist teachers in making learning materials that fit each student's needs. This includes turning text into several languages. Even though these tools offer many benefits, there are still concerns about data privacy. People worry it could also widen the current gaps in education.\n\n\n== Finance ==\nFinancial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking began in 1987 when Security Pacific National Bank launched a fraud prevention task-force to counter the unauthorized use of debit cards.\nBanks use AI to organize operations for bookkeeping, investing in stocks, and managing properties. AI can adapt to changes during non-business hours. AI is used to combat fraud and financial crimes by monitoring behavioral patterns for any abnormal changes or anomalies.\nThe use of AI in applications such as online trading and decision-making has changed major economic theories. For example, AI-based buying and selling platforms estimate personalized demand and supply curves, thus enabling individualized pricing. AI systems reduce information asymmetry in the market and thus make markets more efficient. The application of artificial intelligence in the financial industry can alleviate the financing constraints of non-state-owned enterprises, especially for smaller and more innovative enterprises.\nAlgorithmic trading systems make trades much quicker and in larger amounts than human traders. Robo-advisors provide automatic advice for investing and managing your money at a lower cost than human advisors.\u202fInsurance and lending companies use machine learning to determine risks and set prices.\nFinancial groups use AI systems to check transactions for money laundering. They do this by spotting strange patterns. Auditing gets better with detection algorithms. These algorithms find unusual financial transactions.\n\n\n=== Trading and investment ===\nAlgorithmic trading involves using AI systems to make trading decisions at speeds of magnitude greater than any human is capable of, making millions of trades in a day without human intervention. Such high-frequency trading represents a fast-growing sector. Many banks, funds, and proprietary trading firms now have AI-managed portfolios. Automated trading systems are typically used by large institutional investors but include smaller firms trading with their own AI systems.\nLarge financial institutions use AI to assist with their investment practices. BlackRock's AI engine, Aladdin, is used both within the company and by clients to help with investment decisions. Its functions include the use of natural language processing to analyze text such as news, broker reports, and social media feeds. It then gauges the sentiment on the companies mentioned and assigns a score. Banks such as UBS and Deutsche Bank use SQREEM (Sequential Quantum Reduction and Extraction Model) to mine data to develop consumer profiles and match them with wealth management products.\n\n\n=== Underwriting ===\nOnline lender Upstart uses machine learning for underwriting.\nZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting. This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories.", "mimetype": "text/plain", "start_char_idx": 9352, "end_char_idx": 15149, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fa422a2d-c243-4b55-b340-201884705c09": {"__data__": {"id_": "fa422a2d-c243-4b55-b340-201884705c09", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "da0c5e38-5fa7-4b66-a3dc-fa8565755add", "node_type": "1", "metadata": {}, "hash": "a15c5a1a8065c8215a0a7f5a35a7f80475b32e420766b81b390ddf99f3309211", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "96ab01fc-62c9-4a46-9764-ad68fb29167b", "node_type": "1", "metadata": {}, "hash": "32ed3f0f368d297cd06d24645edf5e947349f2e61eddd7b58434d2ab4aaff6c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Underwriting ===\nOnline lender Upstart uses machine learning for underwriting.\nZestFinance's Zest Automated Machine Learning (ZAML) platform is used for credit underwriting. This platform uses machine learning to analyze data, including purchase transactions and how a customer fills out a form, to score borrowers. The platform is handy for assigning credit scores to those with limited credit histories.\n\n\n=== Audit ===\nAI makes continuous auditing possible. Potential benefits include reducing audit risk, increasing the level of assurance, and reducing audit duration.\nContinuous auditing with AI allows real-time monitoring and reporting of financial activities and provides businesses with timely insights that can lead to quick decision-making.\n\n\n=== Anti-money laundering ===\nAI software, such as LaundroGraph which uses contemporary suboptimal datasets, could be used for anti-money laundering (AML).\n\n\n=== History ===\nIn the 1980s, AI started to become prominent in finance as expert systems were commercialized. For example, Dupont created 100 expert systems, which helped them to save almost $10 million per year. One of the first systems was the Pro-trader expert system that predicted the 87-point drop in the Dow Jones Industrial Average in 1986. \"The major junctions of the system were to monitor premiums in the market, determine the optimum investment strategy, execute transactions when appropriate and modify the knowledge base through a learning mechanism.\"\nOne of the first expert systems to help with financial plans was PlanPowerm and Client Profiling System, created by Applied Expert Systems (APEX). It was launched in 1986. It helped create personal financial plans for people.\nIn the 1990s, AI was applied to fraud detection. In 1993, FinCEN Artificial Intelligence System (FAIS) was launched. It was able to review over 200,000 transactions per week, and over two years, it helped identify 400 potential cases of money laundering equal to $1 billion. These expert systems were later replaced by machine learning systems.\nAI can enhance entrepreneurial activity, and AI is one of the most dynamic areas for start-ups, with significant venture capital flowing into AI.\n\n\n== Government ==\n\nAI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.\n\n\n=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n== Health ==", "mimetype": "text/plain", "start_char_idx": 14740, "end_char_idx": 17938, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "96ab01fc-62c9-4a46-9764-ad68fb29167b": {"__data__": {"id_": "96ab01fc-62c9-4a46-9764-ad68fb29167b", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fa422a2d-c243-4b55-b340-201884705c09", "node_type": "1", "metadata": {}, "hash": "3034060bfecb3ea7456dd1f9409a7ed764c70230f156d9e932d70c0f5eca076b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "13dc49c7-e119-46c5-941c-84ccdeba7f94", "node_type": "1", "metadata": {}, "hash": "1114e387dbed719320a3b654aa22db67ec69843d4319be4ae85f3f1fefb1a829", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Government ==\n\nAI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic.\n\n\n=== Military ===\n\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams.\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.\n\n\n== Health ==\n\n\n=== Healthcare ===\n\nAI in healthcare is often used for classification, to evaluate a CT scan or electrocardiogram or to identify high-risk patients for population health. AI is helping with the high-cost problem of dosing. One study suggested that AI could save $16 billion. In 2016, a study reported that an AI-derived formula derived the proper dose of immunosuppressant drugs to give to transplant patients. Current research has indicated that non-cardiac vascular illnesses are also being treated with artificial intelligence (AI). For certain disorders, AI algorithms can aid in diagnosis, recommended treatments, outcome prediction, and patient progress tracking. As AI technology advances, it is anticipated that it will become more significant in the healthcare industry.\nThe early detection of diseases like cancer is made possible by AI algorithms, which diagnose diseases by analyzing complex sets of medical data. For example, the IBM Watson system might be used to comb through massive data such as medical records and clinical trials to help diagnose a problem. Microsoft's AI project Hanover helps doctors choose cancer treatments from among the more than 800 medicines and vaccines. Its goal is to memorize all the relevant papers to predict which (combinations of) drugs will be most effective for each patient. Myeloid leukemia is one target. Another study reported on an AI that was as good as doctors in identifying skin cancers. Another project monitors multiple high-risk patients by asking each patient questions based on data acquired from doctor/patient interactions. In one study done with transfer learning, an AI diagnosed eye conditions similar to an ophthalmologist and recommended treatment referrals.\nAnother study demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel judged better than a surgeon.\nArtificial neural networks are used as clinical decision support systems for medical diagnosis, such as in concept processing technology in EMR software.\nOther healthcare tasks thought suitable for an AI that are in development include:\n\nScreening\nHeart sound analysis\nCompanion robots for elder care\nMedical record analysis\nTreatment plan design\nMedication management\nAssisting blind people\nConsultations\nDrug creation (e.g. by identifying candidate drugs and by using existing drug screening data such as in life extension research)\nClinical training\nOutcome prediction for surgical procedures\nHIV prognosis\nIdentifying genomic pathogen signatures of novel pathogens or identifying pathogens via physics-based fingerprints (including pandemic pathogens)\nHelping link genes to their functions, otherwise analyzing genes and identification of novel biological targets\nHelp development of biomarkers\nHelp tailor therapies to individuals in personalized medicine/precision medicine\n\n\n=== Workplace health and safety ===\n\nAI-enabled chatbots decrease the need for humans to perform basic call center tasks.\nMachine learning in sentiment analysis can spot fatigue in order to prevent overwork. Similarly, decision support systems can prevent industrial disasters and make disaster response more efficient. For manual workers in material handling, predictive analytics may be used to reduce musculoskeletal injury. Data collected from wearable sensors can improve workplace health surveillance, risk assessment, and research.\nAI can auto-code workers' compensation claims. AI-enabled virtual reality systems can enhance safety training for hazard recognition. AI can more efficiently detect accident near misses, which are important in reducing accident rates, but are often underreported.\n\n\n=== Biochemistry ===\nAlphaFold 2 can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million).\nMedical imaging analysis systems can spot patterns that indicate diseases such as cancer. They can do this just as well as human experts. Predictive analytics can help identify patients with a higher risk for specific conditions. This helps in starting treatments earlier.\nNatural language processing gets key information from electronic health records. This helps doctors make better choices. Machine learning helps find new drugs by predicting how molecules will work together. This can quicken the development of new treatments. Personalized medicine uses AI to change treatments to match each patient\u2019s needs.", "mimetype": "text/plain", "start_char_idx": 16942, "end_char_idx": 22578, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "13dc49c7-e119-46c5-941c-84ccdeba7f94": {"__data__": {"id_": "13dc49c7-e119-46c5-941c-84ccdeba7f94", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "96ab01fc-62c9-4a46-9764-ad68fb29167b", "node_type": "1", "metadata": {}, "hash": "32ed3f0f368d297cd06d24645edf5e947349f2e61eddd7b58434d2ab4aaff6c2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "423172c9-2253-41d3-93f0-1908930e5be1", "node_type": "1", "metadata": {}, "hash": "9e0860ab3cce3983f1d557a7579a378b73485c40d8b1e1f03da1943e79491065", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Biochemistry ===\nAlphaFold 2 can determine the 3D structure of a (folded) protein in hours rather than the months required by earlier automated approaches and was used to provide the likely structures of all proteins in the human body and essentially all proteins known to science (more than 200 million).\nMedical imaging analysis systems can spot patterns that indicate diseases such as cancer. They can do this just as well as human experts. Predictive analytics can help identify patients with a higher risk for specific conditions. This helps in starting treatments earlier.\nNatural language processing gets key information from electronic health records. This helps doctors make better choices. Machine learning helps find new drugs by predicting how molecules will work together. This can quicken the development of new treatments. Personalized medicine uses AI to change treatments to match each patient\u2019s needs. \n\n\n== Chemistry and biology ==\n\nMachine learning has been used for drug design. It has also been used for predicting molecular properties and exploring large chemical/reaction spaces. Computer-planned syntheses via computational reaction networks, described as a platform that combines \"computational synthesis with AI algorithms to predict molecular properties\", have been used to explore the origins of life on Earth, drug-syntheses and developing routes for recycling 200 industrial waste chemicals into important drugs and agrochemicals (chemical synthesis design). There is research about which types of computer-aided chemistry would benefit from machine learning. It can also be used for \"drug discovery and development, drug repurposing, improving pharmaceutical productivity, and clinical trials\". It has been used for the design of proteins with prespecified functional sites.\nIt has been used with databases for the development of a 46-day process to design, synthesize and test a drug which inhibits enzymes of a particular gene, DDR1. DDR1 is involved in cancers and fibrosis which is one reason for the high-quality datasets that enabled these results.\nThere are various types of applications for machine learning in decoding human biology, such as helping to map gene expression patterns to functional activation patterns or identifying functional DNA motifs. It is widely used in genetic research.\nThere also is some use of machine learning in synthetic biology, disease biology, nanotechnology (e.g. nanostructured materials and bionanotechnology), and materials science.\n\n\n=== Novel types of machine learning ===\n\nThere are also prototype robot scientists, including robot-embodied ones like the two Robot Scientists, which show a form of \"machine learning\" not commonly associated with the term.\nSimilarly, there is research and development of biological \"wetware computers\" that can learn (e.g. for use as biosensors) and/or implantation into an organism's body (e.g. for use to control prosthetics). Polymer-based artificial neurons operate directly in biological environments and define biohybrid neurons made of artificial and living components.\nMoreover, if whole brain emulation is possible via both scanning and replicating, at a minimum, the bio-chemical brain \u2013 as premised in the form of digital replication in The Age of Em, possibly using physical neural networks \u2013 that may have applications as or more extensive than e.g. valued human activities and may imply that society would face substantial moral choices, societal risks and ethical problems such as whether (and how) such are built, sent through space and used compared to potentially competing e.g. potentially more synthetic and/or less human and/or non/less-sentient types of artificial/semi-artificial intelligence. An alternative or additive approach to scanning are types of reverse engineering of the brain.\nA subcategory of artificial intelligence is embodied, some of which are mobile robotic systems that each consist of one or multiple robots that are able to learn in the physical world.\n\n\n==== Digital ghosts ====\n\n\n==== Biological computing in AI and as AI ====\nAdditionally, biological computers, even if both artificial and highly intelligent, are typically distinguishable from synthetic, predominantly silicon-based, computers.  The two technologies could, however, be combined and used for the design of either. Moreover, many tasks may be poorly carried out by AI even if it uses algorithms that are transparent, understood, bias-free, apparently effective and goal-aligned in addition to having trained data sets that are sufficiently large and cleansed.  This may occur, for instance, when the underlying data, available metrics, values or training methods are incorrect, flawed or used inappropriately. Computer-aided is a phrase used to describe human activities that make use of computing as tool in more comprehensive activities and systems such as AI for narrow tasks or making use of such without substantially relying on its results (see also: human-in-the-loop). One study described the biological component as a limitation of AI stating that \"as long as the biological system cannot be understood, formalized, and imitated, we will not be able to develop technologies that can mimic it\" and that, even if it were understood, this does not necessarily mean there will be \"a technological solution to imitate natural intelligence\". Technologies that integrate biology and AI include biorobotics.", "mimetype": "text/plain", "start_char_idx": 21655, "end_char_idx": 27092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "423172c9-2253-41d3-93f0-1908930e5be1": {"__data__": {"id_": "423172c9-2253-41d3-93f0-1908930e5be1", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13dc49c7-e119-46c5-941c-84ccdeba7f94", "node_type": "1", "metadata": {}, "hash": "1114e387dbed719320a3b654aa22db67ec69843d4319be4ae85f3f1fefb1a829", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6f381a5f-715f-4727-95c6-f5bfe957f1b8", "node_type": "1", "metadata": {}, "hash": "d5d18e03da96cfd6024a343befefe41178ebd455158bc9b795836b6702cdbe37", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Astronomy, space activities and ufology ==\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\nIn the search for extraterrestrial intelligence (SETI), machine learning has been used in attempts to identify artificially generated electromagnetic waves in available data \u2013 such as real-time observations \u2013 and other technosignatures, e.g. via anomaly detection. In ufology, the SkyCAM-5 project headed by Prof. Hakan Kayal and the Galileo Project headed by Avi Loeb use machine learning to attempt to detect and classify types of UFOs. The Galileo Project also seeks to detect two further types of potential extraterrestrial technological signatures with the use of AI: 'Oumuamua-like interstellar objects, and non-manmade artificial satellites.\nMachine learning can also be used to produce datasets of spectral signatures of molecules that may be involved in the atmospheric production or consumption of particular chemicals \u2013 such as phosphine possibly detected on Venus \u2013 which could prevent miss assignments and, if accuracy is improved, be used in future detections and identifications of molecules on other planets.\n\n\n== Other fields of research ==\n\n\n=== Evidence of general impacts ===\nIn April 2024, the Scientific Advice Mechanism to the European Commission published advice including a comprehensive evidence review of the opportunities and challenges posed by artificial intelligence in scientific research.\nAs benefits, the evidence review highlighted:\n\nits role in accelerating research and innovation\nits capacity to automate workflows\nenhancing dissemination of scientific work\nAs challenges:\n\nlimitations and risks around transparency, reproducibility and interpretability\npoor performance (inaccuracy)\nrisk of harm through misuse or unintended use\nsocietal concerns including the spread of misinformation and increasing inequalities\n\n\n=== Archaeology, history and imaging of sites ===\n\nMachine learning can help to restore and attribute ancient texts. It can help to index texts for example to enable better and easier searching and classification of fragments.\n\nArtificial intelligence can also be used to investigate genomes to uncover genetic history, such as interbreeding between archaic and modern humans by which for example the past existence of a ghost population, not Neanderthal or Denisovan, was inferred. \nIt can also be used for \"non-invasive and non-destructive access to internal structures of archaeological remains\". \n\n\n=== Physics ===\n\nA deep learning system was reported to learn intuitive physics from visual data (of virtual 3D environments) based on an unpublished approach inspired by studies of visual cognition in infants. Other researchers have developed a machine learning algorithm that could discover sets of basic variables of various physical systems and predict the systems' future dynamics from video recordings of their behavior. In the future, it may be possible that such can be used to automate the discovery of physical laws of complex systems.\n\n\n=== Materials science ===\nAI could be used for materials optimization and discovery such as the discovery of stable materials and the prediction of their crystal structure.\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system's predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.\n\n\n=== Reverse engineering ===\nMachine learning is used in diverse types of reverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts, and for quickly understanding the behavior of malware. It can be used to reverse engineer artificial intelligence models. It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionality or protein design for prespecified functional sites. Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels.\n\n\n== Law ==", "mimetype": "text/plain", "start_char_idx": 27095, "end_char_idx": 32831, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6f381a5f-715f-4727-95c6-f5bfe957f1b8": {"__data__": {"id_": "6f381a5f-715f-4727-95c6-f5bfe957f1b8", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "423172c9-2253-41d3-93f0-1908930e5be1", "node_type": "1", "metadata": {}, "hash": "9e0860ab3cce3983f1d557a7579a378b73485c40d8b1e1f03da1943e79491065", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dc1138c1-9608-46c4-ab42-70e667f6976f", "node_type": "1", "metadata": {}, "hash": "0d9a6818c18729b13cb01542389760e2635eb86622184bc88c482d6191289a56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Reverse engineering ===\nMachine learning is used in diverse types of reverse engineering. For example, machine learning has been used to reverse engineer a composite material part, enabling unauthorized production of high quality parts, and for quickly understanding the behavior of malware. It can be used to reverse engineer artificial intelligence models. It can also design components by engaging in a type of reverse engineering of not-yet existent virtual components such as inverse molecular design for particular desired functionality or protein design for prespecified functional sites. Biological network reverse engineering could model interactions in a human understandable way, e.g. bas on time series data of gene expression levels.\n\n\n== Law ==\n\n\n=== Legal analysis ===\nAI is a mainstay of law-related professions. Algorithms and machine learning do some tasks previously done by entry-level lawyers. While its use is common, it is not expected to replace most work done by lawyers in the near future.\nThe electronic discovery industry uses machine learning to reduce manual searching.\n\n\n=== Law enforcement and legal proceedings ===\nLaw enforcement has begun using facial recognition systems (FRS) to identify suspects from visual data. FRS results have proven to be more accurate when compared to eyewitness results. Furthermore, FRS has shown to have much a better ability to identify individuals when video clarity and visibility are low in comparison to human participants.\nCOMPAS is a commercial system used by U.S. courts to assess the likelihood of recidivism.\nOne concern relates to algorithmic bias, AI programs may become biased after processing data that exhibits bias. ProPublica claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than that of white defendants.\nIn 2019, the city of Hangzhou, China established a pilot program artificial intelligence-based Internet Court to adjudicate disputes related to ecommerce and internet-related intellectual property claims.:\u200a124\u200a Parties appear before the court via videoconference and AI evaluates the evidence presented and applies relevant legal standards.:\u200a124\u200a\n\n\n== Services ==\n\n\n=== Human resources ===\n\nAnother application of AI is in human resources. AI can screen resumes and rank candidates based on their qualifications, predict candidate success in given roles, and automate repetitive communication tasks via chatbots.\n\n\n=== Job search ===\nAI has simplified the recruiting/job search process for both recruiters and job seekers. According to Raj Mukherjee from Indeed, 65% of job searchers search again within 91 days after hire. An AI-powered engine streamlines the complexity of job hunting by assessing information on job skills, salaries, and user tendencies, matching job seekers to the most relevant positions. Machine intelligence calculates appropriate wages and highlights resume information for recruiters using NLP, which extracts relevant words and phrases from text. Another application is an AI resume builder that compiles a CV in 5 minutes. Chatbots assist website visitors and refine workflows.\n\n\n=== Online and telephone customer service ===\n\nAI underlies avatars (automated online assistants) on web pages. It can reduce operation and training costs. Pypestream automated customer service for its mobile application to streamline communication with customers.\nA Google app analyzes language and converts speech into text. The platform can identify angry customers through their language and respond appropriately. Amazon uses a chatbot for customer service that can perform tasks like checking the status of an order, cancelling orders, offering refunds and connecting the customer with a human representative. Generative AI (GenAI), such as ChatGPT, is increasingly used in business to automate tasks and enhance decision-making.\n\n\n=== Hospitality ===\nIn the hospitality industry, AI is used to reduce repetitive tasks, analyze trends, interact with guests, and predict customer needs. AI hotel services come in the form of a chatbot, application, virtual voice assistant and service robots.\n\n\n== Media ==\n\nAI applications analyze media content such as movies, TV programs, advertisement videos or user-generated content. The solutions often involve computer vision.\nTypical scenarios include the analysis of images using object recognition or face recognition techniques, or the analysis of video for scene recognizing scenes, objects or faces. AI-based media analysis can facilitate media search, the creation of descriptive keywords for content, content policy monitoring (such as verifying the suitability of content for a particular TV viewing time), speech to text for archival or other purposes, and the detection of logos, products or celebrity faces for ad placement.\n\nMotion interpolation\nPixel-art scaling algorithms\nImage scaling\nImage restoration\nPhoto colorization\nFilm restoration and video upscaling\nPhoto tagging\nAutomated species identification (such as identifying plants, fungi and animals with an app)\nText-to-image models such as DALL-E, Midjourney and Stable Diffusion\nImage to video\nText to video such as Make-A-Video from Meta, Imagen video and Phenaki from Google\nText to music with AI models such as MusicLM\nText to speech such as ElevenLabs and 15.ai\nMotion capture\nMake image transparent", "mimetype": "text/plain", "start_char_idx": 32069, "end_char_idx": 37447, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc1138c1-9608-46c4-ab42-70e667f6976f": {"__data__": {"id_": "dc1138c1-9608-46c4-ab42-70e667f6976f", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6f381a5f-715f-4727-95c6-f5bfe957f1b8", "node_type": "1", "metadata": {}, "hash": "d5d18e03da96cfd6024a343befefe41178ebd455158bc9b795836b6702cdbe37", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cd419a6d-658c-42ec-9906-3f9917702809", "node_type": "1", "metadata": {}, "hash": "8ed5bad237d17fb4c6bbf8833ae1949763d7f66c383c2018616f123adaf644d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Deep-fakes ===\nDeep-fakes can be used for comedic purposes but are better known for fake news and hoaxes.\nDeepfakes can portray individuals in harmful or compromising situations, causing significant reputational damage and emotional distress, especially when the content is defamatory or violates personal ethics. While defamation and false light laws offer some recourse, their focus on false statements rather than fabricated images or videos often leaves victims with limited legal protection and a challenging burden of proof.\nIn January 2016, the Horizon 2020 program financed the InVID Project to help journalists and researchers detect fake documents, made available as browser plugins.\nIn June 2016, the visual computing group of the Technical University of Munich and from Stanford University developed Face2Face, a program that animates photographs of faces, mimicking the facial expressions of another person. The technology has been demonstrated animating the faces of people including Barack Obama and Vladimir Putin. Other methods have been demonstrated based on deep neural networks, from which the name deep fake was taken.\nIn September 2018, U.S. Senator Mark Warner proposed to penalize social media companies that allow sharing of deep-fake documents on their platforms.\nIn 2018, Darius Afchar and Vincent Nozick found a way to detect faked content by analyzing the mesoscopic properties of video frames. DARPA gave 68 million dollars to work on deep-fake detection.\nAudio deepfakes and AI software capable of detecting deep-fakes and cloning human voices have been developed.\nRespeecher is a program that enables one person to speak with the voice of another.\n\n\n=== Video surveillance analysis and manipulated media detection ===\n\nAI algorithms have been used to detect deepfake videos.\n\n\n=== Video production ===\nArtificial intelligence is also starting to be used in video production, with tools and software being developed that utilize generative AI in order to create new video, or alter existing video. Some of the major tools that are being used in these processes currently are DALL-E, Mid-journey, and Runway.  Way mark Studios utilized the tools offered by both DALL-E and Mid-journey to create a fully AI generated film called The Frost in the summer of 2023. Way mark Studios is experimenting with using these AI tools to generate advertisements and commercials for companies in mere seconds.  Yves Bergquist, a director of the AI & Neuroscience in Media Project at USC's Entertainment Technology Center, says post production crews in Hollywood are already using generative AI, and predicts that in the future more companies will embrace this new technology.\n\n\n=== Music ===\n\nAI has been used to compose music of various genres.\nDavid Cope created an AI called Emily Howell that managed to become well known in the field of algorithmic computer music. The algorithm behind Emily Howell is registered as a US patent.\nIn 2012, AI Iamus created the first complete classical album.\nAIVA (Artificial Intelligence Virtual Artist), composes symphonic music, mainly classical music for film scores. It achieved a world first by becoming the first virtual composer to be recognized by a musical professional association.\nMelomics creates computer-generated music for stress and pain relief.\nAt Sony CSL Research Laboratory, the Flow Machines software creates pop songs by learning music styles from a huge database of songs. It can compose in multiple styles.\nThe Watson Beat uses reinforcement learning and deep belief networks to compose music on a simple seed input melody and a select style. The software was open sourced and musicians such as Taryn Southern collaborated with the project to create music.\nSouth Korean singer, Hayeon's, debut song, \"Eyes on You\" was composed using AI which was supervised by real composers, including NUVO.", "mimetype": "text/plain", "start_char_idx": 37450, "end_char_idx": 41321, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cd419a6d-658c-42ec-9906-3f9917702809": {"__data__": {"id_": "cd419a6d-658c-42ec-9906-3f9917702809", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc1138c1-9608-46c4-ab42-70e667f6976f", "node_type": "1", "metadata": {}, "hash": "0d9a6818c18729b13cb01542389760e2635eb86622184bc88c482d6191289a56", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7b13baca-46f1-45e3-8f32-f1d497426fbd", "node_type": "1", "metadata": {}, "hash": "07d07fcb6a16b6eab1b6cc3770a062f2cb5d30165e97e0fcadee61f3dd025dc0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Writing and reporting ===\nNarrative Science sells computer-generated news and reports. It summarizes sporting events based on statistical data from the game. It also creates financial reports and real estate analyses. Automated Insights generates personalized recaps and previews for Yahoo Sports Fantasy Football.\nYseop, uses AI to turn structured data into natural language comments and recommendations. Yseop writes financial reports, executive summaries, personalized sales or marketing documents and more in multiple languages, including English, Spanish, French, and German.\nTALESPIN made up stories similar to the fables of Aesop. The program started with a set of characters who wanted to achieve certain goals. The story narrated their attempts to satisfy these goals. Mark Riedl and Vadim Bulitko asserted that the essence of storytelling was experience management, or \"how to balance the need for a coherent story progression with user agency, which is often at odds\".\nWhile AI storytelling focuses on story generation (character and plot), story communication also received attention. In 2002, researchers developed an architectural framework for narrative prose generation. They faithfully reproduced text variety and complexity on stories such as Little Red Riding Hood. In 2016, a Japanese AI co-wrote a short story and almost won a literary prize.\nSouth Korean company Hanteo Global uses a journalism bot to write articles.\nLiterary authors are also exploring uses of AI. An example is David Jhave Johnston's work ReRites (2017\u20132019), where the poet created a daily rite of editing the poetic output of a neural network to create a series of performances and publications.\n\n\n==== Sports writing ====\nIn 2010, artificial intelligence used baseball statistics to automatically generate news articles. This was launched by The Big Ten Network using software from Narrative Science.\nAfter being unable to cover every Minor League Baseball game with a large team, Associated Press collaborated with Automated Insights in 2016 to create game recaps that were automated by artificial intelligence.\nUOL in Brazil expanded the use of AI in its writing. Rather than just generating news stories, they programmed the AI to include commonly searched words on Google.\nEl Pais, a Spanish news site that covers many things including sports, allows users to make comments on each news article. They use the Perspective API to moderate these comments and if the software deems a comment to contain toxic language, the commenter must modify it in order to publish it.\nA local Dutch media group used AI to create automatic coverage of amateur soccer, set to cover 60,000 games in just a single season. NDC partnered with United Robots to create this algorithm and cover what would have never been possible before without an extremely large team.\nLede AI has been used in 2023 to take scores from high school football games to generate stories automatically for the local newspaper. This was met with significant criticism from readers for the very robotic diction that was published. With some descriptions of games being a \"close encounter of the athletic kind,\" readers were not pleased and let the publishing company, Gannett, know on social media. Gannett has since halted their used of Lede AI until they come up with a solution for what they call an experiment.\n\n\n=== Wikipedia ===\n Millions of its articles have been edited by bots which however are usually not artificial intelligence software. Many AI platforms use Wikipedia data, mainly for training machine learning applications. There is research and development of various artificial intelligence applications for Wikipedia such as for identifying outdated sentences, detecting covert vandalism or recommending articles and tasks to new editors.\nMachine translation (see above) has also be used for translating Wikipedia articles and could play a larger role in creating, updating, expanding, and generally improving articles in the future. A content translation tool allows editors of some Wikipedias to more easily translate articles across several select languages.\n\n\n=== Video games ===\n\nIn video games, AI is routinely used to generate behavior in non-player characters (NPCs). In addition, AI is used for pathfinding. Some researchers consider NPC AI in games to be a \"solved problem\" for most production tasks. Games with less typical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010). AI is also used in Alien Isolation (2014) as a way to control the actions the Alien will perform next.\nKinect, which provides a 3D body\u2013motion interface for the Xbox 360 and the Xbox One, uses algorithms that emerged from AI research.", "mimetype": "text/plain", "start_char_idx": 41324, "end_char_idx": 46092, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7b13baca-46f1-45e3-8f32-f1d497426fbd": {"__data__": {"id_": "7b13baca-46f1-45e3-8f32-f1d497426fbd", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cd419a6d-658c-42ec-9906-3f9917702809", "node_type": "1", "metadata": {}, "hash": "8ed5bad237d17fb4c6bbf8833ae1949763d7f66c383c2018616f123adaf644d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "556f032e-9ae9-4416-925e-56ddd1690032", "node_type": "1", "metadata": {}, "hash": "28dda94c5d50b30109d1a32f8445abf7e08791882f2c49e8eaea5d445f2c87cd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Video games ===\n\nIn video games, AI is routinely used to generate behavior in non-player characters (NPCs). In addition, AI is used for pathfinding. Some researchers consider NPC AI in games to be a \"solved problem\" for most production tasks. Games with less typical AI include the AI director of Left 4 Dead (2008) and the neuroevolutionary training of platoons in Supreme Commander 2 (2010). AI is also used in Alien Isolation (2014) as a way to control the actions the Alien will perform next.\nKinect, which provides a 3D body\u2013motion interface for the Xbox 360 and the Xbox One, uses algorithms that emerged from AI research.\n\n\n=== Art ===\n\nAI has been used to produce visual art. The first AI art program, called AARON, was developed by Harold Cohen in 1968 with the goal of being able to code the act of drawing. It started by creating simple black and white drawings, and later to painting using special brushes and dyes that were chosen by the program itself without mediation from Cohen.\nAI platforms such as DALL-E, Stable Diffusion, Imagen, and Midjourney have been used for generating visual images from inputs such as text or other images. Some AI tools allow users to input images and output changed versions of that image, such as to display an object or product in different environments. AI image models can also attempt to replicate the specific styles of artists, and can add visual complexity to rough sketches.\nSince their design in 2014, generative adversarial networks (GANs) have been used by AI artists. GAN computer programming, generates technical images through machine learning frameworks that surpass the need for human operators. Examples of GAN programs that generate art include Artbreeder and DeepDream.\n\n\n==== Art analysis ====\nIn addition to the creation of original art, research methods that utilize AI have been generated to quantitatively analyze digital art collections. Although the main goal of the large-scale digitization of artwork in the past few decades was to allow for accessibility and exploration of these collections, the use of AI in analyzing them has brought about new research perspectives.\nTwo computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art. While distant viewing includes the analysis of large collections, close reading involves one piece of artwork.\n\n\n=== Computer animation ===\nAI has been in use since the early 2000s, most notably by a system designed by Pixar called \"Genesis\". It was designed to learn algorithms and create 3D models for its characters and props. Notable movies that used this technology included Up and The Good Dinosaur. AI has been used less ceremoniously in recent years. In 2023, it was revealed Netflix of Japan was using AI to generate background images for their upcoming show to be met with backlash online.  In recent years, motion capture became an easily accessible form of AI animation. For example, Move AI is a program built to capture any human movement and reanimate it in its animation program using learning AI.\n\n\n== Utilities ==\n\n\n=== Energy system ===\nPower electronics converters are used in renewable energy, energy storage, electric vehicles and high-voltage direct current transmission. These converters are failure-prone, which can interrupt service and require costly maintenance or catastrophic consequences in mission critical applications. AI can guide the design process for reliable power electronics converters, by calculating exact design parameters that ensure the required lifetime.\nThe U.S. Department of Energy underscores AI's pivotal role in realizing national climate goals. With AI, the ambitious target of achieving net-zero greenhouse gas emissions across the economy becomes feasible. AI also helps make room for wind and solar on the grid by avoiding congestion and increasing grid reliability.\nMachine learning can be used for energy consumption prediction and scheduling, e.g. to help with renewable energy intermittency management (see also: smart grid and climate change mitigation in the power grid).\n\n\n=== Telecommunications ===\nMany telecommunications companies make use of heuristic search to manage their workforces. For example, BT Group deployed heuristic search in an application that schedules 20,000 engineers. Machine learning is also used for speech recognition (SR), including of voice-controlled devices, and SR-related transcription, including of videos.\n\n\n== Manufacturing ==\n\n\n=== Sensors ===\nArtificial intelligence has been combined with digital spectrometry by IdeaCuria Inc., enable applications such as at-home water quality monitoring.\n\n\n=== Toys and games ===\nIn the 1990s, early artificial intelligence tools controlled Tamagotchis and Giga Pets, the Internet, and the first widely released robot, Furby. Aibo was a domestic robot in the form of a robotic dog with intelligent features and autonomy.\nMattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn.", "mimetype": "text/plain", "start_char_idx": 45460, "end_char_idx": 50508, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "556f032e-9ae9-4416-925e-56ddd1690032": {"__data__": {"id_": "556f032e-9ae9-4416-925e-56ddd1690032", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7b13baca-46f1-45e3-8f32-f1d497426fbd", "node_type": "1", "metadata": {}, "hash": "07d07fcb6a16b6eab1b6cc3770a062f2cb5d30165e97e0fcadee61f3dd025dc0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dabcb935-1b26-4039-b32d-b0a40161d063", "node_type": "1", "metadata": {}, "hash": "b7bfb2f4c90510dc3941cbecdbdef934dea746b76c73dbc910fe4082130ef1ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Telecommunications ===\nMany telecommunications companies make use of heuristic search to manage their workforces. For example, BT Group deployed heuristic search in an application that schedules 20,000 engineers. Machine learning is also used for speech recognition (SR), including of voice-controlled devices, and SR-related transcription, including of videos.\n\n\n== Manufacturing ==\n\n\n=== Sensors ===\nArtificial intelligence has been combined with digital spectrometry by IdeaCuria Inc., enable applications such as at-home water quality monitoring.\n\n\n=== Toys and games ===\nIn the 1990s, early artificial intelligence tools controlled Tamagotchis and Giga Pets, the Internet, and the first widely released robot, Furby. Aibo was a domestic robot in the form of a robotic dog with intelligent features and autonomy.\nMattel created an assortment of AI-enabled toys that \"understand\" conversations, give intelligent responses, and learn.\n\n\n=== Oil and gas ===\nOil and gas companies have used artificial intelligence tools to automate functions, foresee equipment issues, and increase oil and gas output.\n\nIndustrial sensors and AI tools work together to watch manufacturing processes and equipment in real-time. Detection programs find strange patterns. The patterns may show quality issues or issues with equipment. Supply chain management improves with better predictions of demand and managing inventory.\n\n\n== Transport ==\n\n\n=== Automotive ===\n\nAI in transport is expected to provide safe, efficient, and reliable transportation while minimizing the impact on the environment and communities. The major development challenge is the complexity of transportation systems that involves independent components and parties, with potentially conflicting objectives.\nAI-based fuzzy logic controllers operate gearboxes. For example, the 2006 Audi TT, VW Touareg  and VW Caravell feature the DSP transmission. A number of \u0160koda variants (\u0160koda Fabia) include a fuzzy logic-based controller. Cars have AI-based driver-assist features such as self-parking and adaptive cruise control.\nThere are also prototypes of autonomous automotive public transport vehicles such as electric mini-buses as well as autonomous rail transport in operation.\nThere also are prototypes of autonomous delivery vehicles, sometimes including delivery robots.\nTransportation's complexity means that in most cases training an AI in a real-world driving environment is impractical. Simulator-based testing can reduce the risks of on-road training.\nAI underpins self-driving vehicles. Companies involved with AI include Tesla, Waymo, and General Motors. AI-based systems control functions such as braking, lane changing, collision prevention, navigation and mapping.\nAutonomous trucks are in the testing phase. The UK government passed legislation to begin testing of autonomous truck platoons in 2018. A group of autonomous trucks follow closely behind each other. German corporation Daimler is testing its Freightliner Inspiration.\nAutonomous vehicles require accurate maps to be able to navigate between destinations. Some autonomous vehicles do not allow human drivers (they have no steering wheels or pedals).\n\n\n==== Traffic management ====\nAI has been used to optimize traffic management, which reduces wait times, energy use, and emissions by as much as 25 percent.\n\nSmart traffic lights have been developed at Carnegie Mellon since 2009.  Professor Stephen Smith has started a company since then Surtrac that has installed smart traffic control systems in 22 cities.  It costs about $20,000 per intersection to install. Drive time has been reduced by 25% and traffic jam waiting time has been reduced by 40% at the intersections it has been installed.", "mimetype": "text/plain", "start_char_idx": 49568, "end_char_idx": 53296, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dabcb935-1b26-4039-b32d-b0a40161d063": {"__data__": {"id_": "dabcb935-1b26-4039-b32d-b0a40161d063", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "556f032e-9ae9-4416-925e-56ddd1690032", "node_type": "1", "metadata": {}, "hash": "28dda94c5d50b30109d1a32f8445abf7e08791882f2c49e8eaea5d445f2c87cd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85d07d24-db3b-4f26-8099-5d9071a63b42", "node_type": "1", "metadata": {}, "hash": "7e384d0209dbf69bb587755afac8675c531dab5f7bdc77b6604995b6e2c25c06", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "==== Traffic management ====\nAI has been used to optimize traffic management, which reduces wait times, energy use, and emissions by as much as 25 percent.\n\nSmart traffic lights have been developed at Carnegie Mellon since 2009.  Professor Stephen Smith has started a company since then Surtrac that has installed smart traffic control systems in 22 cities.  It costs about $20,000 per intersection to install. Drive time has been reduced by 25% and traffic jam waiting time has been reduced by 40% at the intersections it has been installed.\n\n\n=== Military ===\nThe Royal Australian Air Force (RAAF) Air Operations Division (AOD) uses AI for expert systems. AIs operate as surrogate operators for combat and training simulators, mission management aids, support systems for tactical decision making, and post processing of the simulator data into symbolic summaries.\nAircraft simulators use AI for training aviators. Flight conditions can be simulated that allow pilots to make mistakes without risking themselves or expensive aircraft. Air combat can also be simulated.\nAI can also be used to operate planes analogously to their control of ground vehicles. Autonomous drones can fly independently or in swarms.\nAOD uses the Interactive Fault Diagnosis and Isolation System, or IFDIS, which is a rule-based expert system using information from TF-30 documents and expert advice from mechanics that work on the TF-30. This system was designed to be used for the development of the TF-30 for the F-111C. The system replaced specialized workers. The system allowed regular workers to communicate with the system and avoid mistakes, miscalculations, or having to speak to one of the specialized workers.\nSpeech recognition allows traffic controllers to give verbal directions to drones.\nArtificial intelligence supported design of aircraft, or AIDA, is used to help designers in the process of creating conceptual designs of aircraft. This program allows the designers to focus more on the design itself and less on the design process. The software also allows the user to focus less on the software tools. The AIDA uses rule-based systems to compute its data. This is a diagram of the arrangement of the AIDA modules. Although simple, the program is proving effective.\n\n\n=== NASA ===\nIn 2003 a Dryden Flight Research Center project created software that could enable a damaged aircraft to continue flight until a safe landing can be achieved. The software compensated for damaged components by relying on the remaining undamaged components.\nThe 2016 Intelligent Autopilot System combined apprenticeship learning and behavioral cloning whereby the autopilot observed low-level actions required to maneuver the airplane and high-level strategy used to apply those actions.\n\n\n=== Maritime ===\nNeural networks are used by situational awareness systems in ships and boats. There also are autonomous boats.\n\nThe development of self-driving cars is progressing. Machine learning systems help use sensor data to navigate tricky areas. Advanced driver assistance systems provide features such as keeping the car in its lane and preventing accidents. City traffic management systems change traffic lights based on the current traffic conditions.\nMaritime shipping uses AI to find the best paths. It checks weather and fuel usage. Automated navigation systems help operate the ships. AI also improves loading and placing containers at ports.\n\n\n== Environmental monitoring ==\n\nAutonomous ships that monitor the ocean, AI-driven satellite data analysis, passive acoustics or remote sensing and other applications of environmental monitoring make use of machine learning.\nFor example, \"Global Plastic Watch\" is an AI-based satellite monitoring-platform for analysis/tracking of plastic waste sites to help prevention of plastic pollution \u2013 primarily ocean pollution \u2013 by helping identify who and where mismanages plastic waste, dumping it into oceans.\n\n\n=== Early-warning systems ===\nMachine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics, earthquakes, landslides, heavy rainfall, long-term water supply vulnerability, tipping-points of ecosystem collapse, cyanobacterial bloom outbreaks, and droughts.\n\nAI early warning systems can warn us about natural disasters like floods, wildfires, and earthquakes. Climate change monitoring uses machine learning to spot patterns in temperature, rainfall, and other signs in the environment. Wildlife conservation gets better when we use automatic tools to identify animals in camera trap pictures and sound recordings. Tools for monitoring the ocean look at key details that help us learn about the health of ocean ecosystems.\n\n\n== Computer science ==\n\n\n=== Programming assistance ===", "mimetype": "text/plain", "start_char_idx": 52754, "end_char_idx": 57541, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "85d07d24-db3b-4f26-8099-5d9071a63b42": {"__data__": {"id_": "85d07d24-db3b-4f26-8099-5d9071a63b42", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dabcb935-1b26-4039-b32d-b0a40161d063", "node_type": "1", "metadata": {}, "hash": "b7bfb2f4c90510dc3941cbecdbdef934dea746b76c73dbc910fe4082130ef1ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f2b30bc5-8616-4475-afd3-9146789352f0", "node_type": "1", "metadata": {}, "hash": "4a1901902c25f5e525e39d9f2f8c64050bceb31f7efb9c9a693811df54c73dc8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "=== Early-warning systems ===\nMachine learning can be used to spot early-warning signs of disasters and environmental issues, possibly including natural pandemics, earthquakes, landslides, heavy rainfall, long-term water supply vulnerability, tipping-points of ecosystem collapse, cyanobacterial bloom outbreaks, and droughts.\n\nAI early warning systems can warn us about natural disasters like floods, wildfires, and earthquakes. Climate change monitoring uses machine learning to spot patterns in temperature, rainfall, and other signs in the environment. Wildlife conservation gets better when we use automatic tools to identify animals in camera trap pictures and sound recordings. Tools for monitoring the ocean look at key details that help us learn about the health of ocean ecosystems.\n\n\n== Computer science ==\n\n\n=== Programming assistance ===\n\n\n==== AI-powered code assisting tools ====\nAI can be used for real-time code completion, chat, and automated test generation. These tools are typically integrated with editors and IDEs as plugins. They differ in functionality, quality, speed, and approach to privacy. Code suggestions could be incorrect, and should be carefully reviewed by software developers before accepted.\nGitHub Copilot is an artificial intelligence model developed by GitHub and OpenAI that is able to autocomplete code in multiple programming languages. Price for individuals: $10/mo or $100/yr, with one free month trial.\nTabnine was created by Jacob Jackson and was originally owned by Tabnine company. In late 2019, Tabnine was acquired by Codota. Tabnine tool is available as plugin to most popular IDEs. It offers multiple pricing options, including limited \"starter\" free version.\nCodiumAI by CodiumAI, small startup in Tel Aviv, offers automated test creation. Currently supports Python, JS, and TS.\nGhostwriter by Replit offers code completion and chat. They have multiple pricing plans, including a free one and a \"Hacker\" plan for $7/month.\nCodeWhisperer by Amazon collects individual users' content, including files open in the IDE. They claim to focus on security both during transmission and when storing. Individual plan is free, professional plan is $19/user/month.\nOther tools: SourceGraph Cody, CodeCompleteFauxPilot, Tabby\n\n\n==== Neural network design ====\nAI can be used to create other AIs. For example, around November 2017, Google's AutoML project to evolve new neural net topologies created NASNet, a system optimized for ImageNet and POCO F1. NASNet's performance exceeded all previously published performance on ImageNet.\n\n\n==== Quantum computing ====\n\nMachine learning has been used for noise-cancelling in quantum technology, including quantum sensors. Moreover, there is substantial research and development of using quantum computers with machine learning algorithms. For example, there is a prototype, photonic, quantum memristive device for neuromorphic (quantum-)computers (NC)/artificial neural networks and NC-using quantum materials with some variety of potential neuromorphic computing-related applications, and quantum machine learning is a field with some variety of applications under development. AI could be used for quantum simulators which may have the application of solving physics and chemistry problems as well as for quantum annealers for training of neural networks for AI applications. There may also be some usefulness in chemistry, e.g. for drug discovery, and in materials science, e.g. for materials optimization/discovery (with possible relevance to quantum materials manufacturing).\n\n\n=== Historical contributions ===\nAI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered AI. All of the following were originally developed in AI laboratories:\n\nTime sharing\nInteractive interpreters\nGraphical user interfaces and the computer mouse\nRapid application development environments\nThe linked list data structure\nAutomatic storage management\nSymbolic programming\nFunctional programming\nDynamic programming\nObject-oriented programming\nOptical character recognition\nConstraint satisfaction\n\n\n== Business ==\n\n\n=== Content extraction ===\nAn optical character reader is used in the extraction of data in business documents like invoices and receipts. It can also be used in business contract documents e.g. employment agreements to extract critical data like employment terms, delivery terms, termination clauses, etc.\n\n\n== Architecture ==\nAI in architecture has created a way for architects to create things beyond human understanding. AI implementation of machine learning text-to-render technologies, like DALL-E and stable Diffusion, gives power to visualization complex.\nAI allows designers to demonstrate their creativity and even invent new ideas while designing. In future, AI will not replace architects; instead, it will improve the speed of translating ideas sketching.\n\n\n== Ethical Considerations and Societal Impacts ==\nThe use of AI raises some important ethical issues like privacy, bias, and accountability. When algorithms are trained on biased data, they can end up reinforcing existing inequalities, for example consider how facial recognition technology often performs poorly or fails in certain demographics. Plus, AI's use in surveillance makes people worry about their personal rights and data privacy.", "mimetype": "text/plain", "start_char_idx": 56691, "end_char_idx": 62132, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f2b30bc5-8616-4475-afd3-9146789352f0": {"__data__": {"id_": "f2b30bc5-8616-4475-afd3-9146789352f0", "embedding": null, "metadata": {}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "15893057", "node_type": "4", "metadata": {}, "hash": "2584faf453dcdb3520cc4601464ca4043f20b95ad51dca0eaecaa48b584e3882", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "85d07d24-db3b-4f26-8099-5d9071a63b42", "node_type": "1", "metadata": {}, "hash": "7e384d0209dbf69bb587755afac8675c531dab5f7bdc77b6604995b6e2c25c06", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "== Architecture ==\nAI in architecture has created a way for architects to create things beyond human understanding. AI implementation of machine learning text-to-render technologies, like DALL-E and stable Diffusion, gives power to visualization complex.\nAI allows designers to demonstrate their creativity and even invent new ideas while designing. In future, AI will not replace architects; instead, it will improve the speed of translating ideas sketching.\n\n\n== Ethical Considerations and Societal Impacts ==\nThe use of AI raises some important ethical issues like privacy, bias, and accountability. When algorithms are trained on biased data, they can end up reinforcing existing inequalities, for example consider how facial recognition technology often performs poorly or fails in certain demographics. Plus, AI's use in surveillance makes people worry about their personal rights and data privacy. \n\n\n== Challenges and Future Directions ==\nThe integrartion of these technologies raises some issues that we need to look at. First, it's important to make sure that the data we use is accurate and fair. We also need to address issues of bias to ensure that AI systems treat everyone equally. Creating rules and guidelines for how AI is used is another important step. Data privacy and ensuring security is very essential to maintain trust. While adaptation of these technolgies can give us more efficiency in the work pattern, there might be a challenge for human workforce.\nLooking ahead, we aim to develop AI that can explain its decisions clearly so that people can understand how it works. There's also a goal to create more advanced AI that can handle a wider range of problems. Researchers are starting to emphasize the importance of working together across different fields to develop better technologies for AI so that it provides fair benefits for everyone.\n\n\n== List of applications ==\n\n\n== See also ==\nApplications of artificial intelligence to legal informatics\nApplications of deep learning\nApplications of machine learning\nArtificial intelligence and elections\nCollective intelligence \u00a7 Applications\nList of artificial intelligence projects\nList of datasets for machine-learning research\nOpen data\nProgress in artificial intelligence\nTimeline of computing 2020\u2013present\n\n\n== Footnotes ==\n\n\n== Further reading ==\nKaplan, A.M.; Haenlein, M. (2018). \"Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence\". Business Horizons. 62 (1): 15\u201325. doi:10.1016/j.bushor.2018.08.004.\nKurzweil, Ray (2005). The Singularity is Near: When Humans Transcend Biology. New York: Viking. ISBN 978-0-670-03384-3.\nNational Research Council (1999). \"Developments in Artificial Intelligence\". Funding a Revolution: Government Support for Computing Research. National Academy Press. ISBN 978-0-309-06278-7. OCLC 246584055.\nMoghaddam, M. J.; Soleymani, M. R.; Farsi, M. A. (2015). \"Sequence planning for stamping operations in progressive dies\". Journal of Intelligent Manufacturing. 26 (2): 347\u2013357. doi:10.1007/s10845-013-0788-0.\nFelten, Ed (3 May 2016). \"Preparing for the Future of Artificial Intelligence\".", "mimetype": "text/plain", "start_char_idx": 61228, "end_char_idx": 64413, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"1164": {"node_ids": ["4ab039c4-7959-4845-8fe9-19d045bfa757", "b52ab66c-4e98-4ae4-b1bc-e7a041461d4a", "8b61535f-d6d1-4c4b-ac6e-ddad0ade9720", "942bd085-b5c9-420e-b579-3690a466fc11", "49df6bdf-331d-40bc-aaa2-e185f23a1355", "f7ccd07f-4b8d-4b7f-b5b5-43751fde7d2e", "eb4f047f-2d13-42f4-ba0b-6b7e9dc0694b", "15c30b0c-221a-4b81-950d-57dfe70e3fd2", "328bd4e7-eb28-4469-86bc-f80dce24c6f0", "b10d4ea0-65e0-4073-a614-55c06bfd2f9b", "aefd400a-538b-4499-a1d3-d017d70613c2", "f6747b15-d4a3-410a-88f8-e649ce76985f", "8396280b-a52d-4445-b217-efa5a1e08059", "514b7443-41bf-4c11-bfb6-debeaf5421e6", "1e55e3a8-d017-4f4f-ad9e-8fbd09786241", "449bfbce-9ec5-4336-ad08-10c4971325ad", "1374a695-2852-4d4e-b52d-ffb850d0a853", "84f828ab-1e16-4545-b622-bac519443665", "65d37f32-d07d-45a5-973f-134a15bca219", "f4c21acf-7b2d-4eed-ad56-489e7d634a7f", "c02e6d01-a5e4-4fab-b4d3-1e45bd33cfc8", "841c4567-a53f-4573-880b-d1866702a721"], "metadata": {}}, "233488": {"node_ids": ["e571a374-3eff-4770-8f33-3f464457c9b2", "07db5142-e837-4c44-82ca-66fa6f5b0a8c", "6fb7e81c-e518-4f40-afd9-851547334fe8", "2d69cae6-e450-4542-a647-c31ca069d7da", "535bd41b-2096-4dcf-8b12-7bfac5d6cbc7", "2bee5fd6-1cf2-42e4-84e4-b657973dd793", "4fa2024f-cfd6-4696-8a88-14509984b5b3", "8335c64a-35da-4cef-82ff-97340256d954", "3cfcf0d7-d3ed-4b09-b8d6-48e32d306428", "82e0490b-42aa-408b-b954-ed9f67e759c8", "355b74b3-8b63-403a-ad6e-9267d4f2a8dd", "c5d4dced-0b7e-438d-999a-1429b1c269a1", "8eb652ea-9d53-41fb-8599-340cfcba5ef8"], "metadata": {}}, "32472154": {"node_ids": ["dd4ed30e-05dc-48f1-9e00-48d947a2f6ca", "f754c521-3b6b-4476-9b94-a4a877da0a59", "91e6728e-a2f2-4654-9be7-7c0284cb6539", "4ad5b872-5b44-49b3-98f4-58af80444881", "478819ee-e4fc-42f4-9432-fbbbe150709d", "b7055dc2-6cbc-4fd1-962a-4faa6c5459ea", "550a2340-a66c-4052-b96d-c416a3724a03", "bfd2f854-7427-4153-81f9-a4ae9e862617", "58a6957f-df83-4fd3-abc8-5f7014d58b2a", "fde0c038-d905-45bf-9445-6c7407b628ce", "d2b217d1-9186-4f6b-9842-d85be4f76a6e", "25622a5b-8aa9-4568-8022-2b8af6de1eb5", "79a75544-d43e-4c53-8545-216d56255688", "5be4cf5b-cf07-4416-84e2-499b3f65c7e7"], "metadata": {}}, "76121942": {"node_ids": ["1e19a71b-dc20-4e68-8330-08c490e51d33"], "metadata": {}}, "40409788": {"node_ids": ["811bf8fe-a762-4f76-b782-979f7f567277", "160e3bca-e219-42c8-b0b6-733cb8a71b58", "0da08d6f-b6c4-4bc8-97cb-5ee9095e6ae1", "82ef047d-e8bd-4c93-b915-c27a5f027d1a", "3875a3a4-1787-456a-b028-2aae29743af1", "a2d42081-6470-4bba-9948-dee2abda04bd", "2344fc41-a542-485e-800c-fb4de34f79fd", "1142e6e0-0f91-4318-a894-2130ab3b6cb9", "84d0ad74-5b58-47db-9c0c-fd81ed88be69", "c25a7e50-10e3-46d3-88e8-f899fbb4d9fd", "f2c1ae07-686f-4f6a-9190-3efa7ef621f3", "bae32750-1e0b-4f3c-97f6-bbd3cdea4f0c", "3065e88e-5f7a-4319-aec7-964d3ea86f59", "b7a2a0e5-bb31-4765-b782-5a4df75bdbac", "36f36bc1-8a69-4bcf-a36a-3097c1952edf", "f4045224-b123-4c58-82b0-7f7b6ea1d98a", "b6780513-e950-4e89-90bd-08554676dcf9"], "metadata": {}}, "21652": {"node_ids": ["1dd41de2-bdad-4989-8ba3-16e5dce73351", "5c62f167-7dbc-4b76-8fbb-4fd35ee4263a", "55baec5d-f219-4d86-8d6d-2e6575f80bd7", "317f134a-8f9f-4c9c-b16a-82900d3fa03b", "34c6ce7a-41fd-4449-a0fb-fc3e4484c4ef", "ea5ee3ce-0629-403d-ae59-7d5b5025bdae", "c1a60dfd-2964-45a2-8bac-9b66549be437", "4723263f-2090-46e7-be96-d0b44bb72c6b", "5d5d7710-34f3-4a7d-ba46-76ac34a29038"], "metadata": {}}, "73291755": {"node_ids": ["a8e00bba-ce6c-4e7a-bdee-23ccb3369cbf", "eb06471e-7fe8-484f-aca8-418f5c0a9f2a", "788240d0-bb49-4a6e-a0cf-ddbdc62f8765", "6b187125-22ec-4c42-abab-67e0d206092d", "33307083-a862-47c2-9027-c3ac9f843895", "9c533f28-97f1-420b-896d-bd0b9afe0478", "e0d19347-bbbd-4dc5-b34c-09ba3749b867", "06d37da8-2020-4c50-856a-58f4c4595575", "52812ff0-f0bc-482c-b06e-f5998df25a36", "96028078-62c0-460a-b467-10ce5140dee0"], "metadata": {}}, "73248112": {"node_ids": ["957102fc-ecb3-4c77-b017-b0c6a13b209e", "4a4b6e99-211c-48d2-9523-4aa420d8a709", "d8b6b633-9068-4a77-8156-9a3dc2198948", "e94da11d-2325-4e76-a929-1b5304970b03", "8061e96d-1391-44f8-b8d4-de22afa68c44", "bc1354c6-c026-47db-99ef-24ee0bd02244", "ef8185ca-1b6c-42af-a491-c91870195d07", "888871dd-08b3-42cf-8f10-61fcca99fe97", "a3a135db-6b90-4bb5-b59f-6728cb7e4100", "63efa929-4aec-4f21-909a-cda2f85664aa", "7f251bf0-1193-4189-9da1-4b8632f5f19a", "ffc8cf32-ef4e-42ed-abc9-4623d393d8be", "3d8ebb20-fda2-47d2-a479-977a27d1410e"], "metadata": {}}, "173354": {"node_ids": ["da1741a2-b54c-49f3-acba-cec69b1e92ec", "c37f473e-5e04-40bd-bf6a-5ba605fb4970", "8b61d906-4e2e-4658-8d5b-9ff4177981c9", "7fbcc181-b354-4e2f-a4c3-baf6f9281f95", "113ec952-36d3-49d0-af83-b94234745e6a", "d274f457-dc3e-46d8-819a-b509dd0629ef", "536c7a7e-3f3d-4bbf-96e3-bc81af8906fd", "bf4ea3bf-1285-4a56-a604-cfa6a9126b3c", "a2685772-7b72-4fb0-86ae-6cb293074405", "22b3999a-1bc1-49da-8031-a3c242dd765c", "dd52ca4d-1e4f-4183-9aa3-8f0b8b0e444e", "f4fe29ec-0d43-4bb1-bafa-74d0d934ee44", "f11a9fcd-c26a-4109-ab06-fdb14a925544"], "metadata": {}}, "2711317": {"node_ids": ["e20ecb3d-41f6-4ed1-b276-d096926b5175", "79b9a4bf-d6bb-4325-9259-ff923cc952c8", "bf048a52-23c8-45bf-aed2-c664aab4dd12", "b67c3f51-b117-4f05-a318-616a19a9d58c", "9950fe6d-3155-4f75-b1f5-37fab7e529c8", "3c8a46ef-ecda-4c7e-a615-cb15bfe2d6f0"], "metadata": {}}, "938833": {"node_ids": ["e708ff84-4768-407a-a18c-b6f0ff14df2e", "9de43aa1-9fa4-41e5-92c8-3e28858f830b", "2e3fa510-e4d3-4bf0-b190-f73aaba40932"], "metadata": {}}, "15893057": {"node_ids": ["617789a6-69ab-4920-8950-099df217baf8", "08c57786-33f6-48c1-b70a-1dd6fc1836f1", "bcd02966-ae82-4d7d-a0e7-0005f37e8992", "8065b322-4954-4378-a3b1-8e6997e75194", "08eb8e3f-7c51-4d98-91f6-d1a4ceab2bf2", "bfc28529-4549-480d-97a1-8fa8ef541660", "3192e549-ef5f-47a7-82e0-f49917e5f0db", "a76c50b8-f99e-4845-b34b-0fe8bd43f712", "8e726a5c-bd57-48c7-aad1-47ce2f2fe28f", "50520759-22d8-4d1d-9350-c89f0465de72", "a7c4556e-aa79-4f25-9a58-d3be3d893752", "9e901110-1958-476b-985a-1fc91bc494af", "31b08a90-e3a2-4d6d-85f7-f1955efd0c73", "1cde0f9a-09c0-40b9-8393-32839fb102bd", "27d31b73-af59-4aff-b145-31727c0f8c3a", "223acab7-1dce-40c9-a88f-0c729912ac4a", "2a6e6966-7060-4615-a5af-cd23b6ecfdd3", "da0c5e38-5fa7-4b66-a3dc-fa8565755add", "fa422a2d-c243-4b55-b340-201884705c09", "96ab01fc-62c9-4a46-9764-ad68fb29167b", "13dc49c7-e119-46c5-941c-84ccdeba7f94", "423172c9-2253-41d3-93f0-1908930e5be1", "6f381a5f-715f-4727-95c6-f5bfe957f1b8", "dc1138c1-9608-46c4-ab42-70e667f6976f", "cd419a6d-658c-42ec-9906-3f9917702809", "7b13baca-46f1-45e3-8f32-f1d497426fbd", "556f032e-9ae9-4416-925e-56ddd1690032", "dabcb935-1b26-4039-b32d-b0a40161d063", "85d07d24-db3b-4f26-8099-5d9071a63b42", "f2b30bc5-8616-4475-afd3-9146789352f0"], "metadata": {}}}}